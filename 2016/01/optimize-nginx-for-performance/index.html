<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Optimize Nginx for performance | timor's site</title><meta name=keywords content="Linux,nginx"><meta name=description content="There are many possible real life cases and not all optimization technics will be suitable for you but I hope it will be a good starting place.
Also you should"><meta name=author content><link rel=canonical href=https://gagor.pl/2016/01/optimize-nginx-for-performance/><link crossorigin=anonymous href=/assets/css/stylesheet.be84a2f064c7e93ecbe786e77620b732b98cf3f8ea42d8b36e32b9e585266d79.css integrity="sha256-voSi8GTH6T7L54bndiC3MrmM8/jqQtizbjK55YUmbXk=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://gagor.pl/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://gagor.pl/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://gagor.pl/favicon-32x32.png><link rel=apple-touch-icon href=https://gagor.pl/apple-touch-icon.png><link rel=mask-icon href=https://gagor.pl/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-4F5GDSK0NP"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-4F5GDSK0NP",{anonymize_ip:!1})}</script><meta property="og:title" content="Optimize Nginx for performance"><meta property="og:description" content="There are many possible real life cases and not all optimization technics will be suitable for you but I hope it will be a good starting place.
Also you shouldn&rsquo;t copy paste examples with faith that they will make your server fly ðŸ˜ƒ You have to support your decisions with excessive tests and help of monitoring system (ex. Grafana).
Cache static and dynamic content Setting caching static and dynamic content strategy may offload your server from additional load from repetitive downloads of same, rarely updated files."><meta property="og:type" content="article"><meta property="og:url" content="https://gagor.pl/2016/01/optimize-nginx-for-performance/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2016-01-14T00:00:00+00:00"><meta property="article:modified_time" content="2016-01-14T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Optimize Nginx for performance"><meta name=twitter:description content="There are many possible real life cases and not all optimization technics will be suitable for you but I hope it will be a good starting place.
Also you shouldn&rsquo;t copy paste examples with faith that they will make your server fly ðŸ˜ƒ You have to support your decisions with excessive tests and help of monitoring system (ex. Grafana).
Cache static and dynamic content Setting caching static and dynamic content strategy may offload your server from additional load from repetitive downloads of same, rarely updated files."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://gagor.pl/posts/"},{"@type":"ListItem","position":3,"name":"Optimize Nginx for performance","item":"https://gagor.pl/2016/01/optimize-nginx-for-performance/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Optimize Nginx for performance","name":"Optimize Nginx for performance","description":"There are many possible real life cases and not all optimization technics will be suitable for you but I hope it will be a good starting place.\nAlso you shouldn\u0026rsquo;t copy paste examples with faith that they will make your server fly ðŸ˜ƒ You have to support your decisions with excessive tests and help of monitoring system (ex. Grafana).\nCache static and dynamic content Setting caching static and dynamic content strategy may offload your server from additional load from repetitive downloads of same, rarely updated files.","keywords":["Linux","nginx"],"articleBody":"There are many possible real life cases and not all optimization technics will be suitable for you but I hope it will be a good starting place.\nAlso you shouldnâ€™t copy paste examples with faith that they will make your server fly ðŸ˜ƒ You have to support your decisions with excessive tests and help of monitoring system (ex. Grafana).\nCache static and dynamic content Setting caching static and dynamic content strategy may offload your server from additional load from repetitive downloads of same, rarely updated files. This will make your site to load faster for frequent visitors.\nExample configuration:\nlocation ~* ^.+\\.(?:jpg|png|css|gif|jpeg|js|swf|m4v)$ { access_log off; log_not_found off; tcp_nodelay off; open_file_cache max=500 inactive=120s; open_file_cache_valid 45s; open_file_cache_min_uses 2; open_file_cache_errors off; expires max; } For additional performance gain, you may:\ndisable logging for static files, disable tcp_nodelay option - itâ€™s useful to send a lot of small files (ideally smaller than single TCP packet - 1,5Kb), but images are rather big files and sending them all together will gain better performance, play with open_file_cache - it will take off some IO load, add long long expires. Caching dynamic content is harder case. There are articles that are rarely updated and they may lay in cache forever but other pages are pretty dynamic and shouldnâ€™t be cached for long. Even if caching dynamic content sounds scary for you itâ€™s not. So called micro caching (caching for short period of time, like 1s) - is great solution for digg effect or slashdotting.\nLet say your page gets ten views per second and you will cache ever site for 1s, then you will be able to server 90% of requests from cache. Leaving precious CPU cycles for other tasks.\nCompress data On your page you should use filetypes that are efficiently compressed like: JPEG, PNG, MP3, etc. But all HTML, CSS, JS may be compressed too on the fly by web server, just enable options like that globally:\ngzip on; gzip_vary on; gzip_disable \"msie6\"; gzip_comp_level 1; gzip_proxied any; gzip_buffers 16 8k; gzip_min_length 50; gzip_types text/plain text/css application/json application/x-javascript application/javascript text/javascript application/atom+xml application/xml application/xml+rss text/xml image/x-icon text/x-js application/xhtml+xml image/svg+xml; You may also precompress these files stronger during build/deploy process and use gzip_static module to serve them without additional overhead for compression. Ex.:\ngzip_static on; Then use script like this to compress files:\nfind /var/www -iname *.js -print0 |xargs -0 -I'{}' sh -c 'gzip -c9 \"{}\" \u003e \"{}.gz\" \u0026\u0026 touch -r \"{}\" \"{}.gz\"' find /var/www -iname *.css -print0 |xargs -0 -I'{}' sh -c 'gzip -c9 \"{}\" \u003e \"{}.gz\" \u0026\u0026 touch -r \"{}\" \"{}.gz\"' Files have to had same timestamp like original (not compressed) file to be used by Nginx.\nOptimize SSL/TLS New optimized versions of HTTP protocols like HTTP/2 or SPDY require HTTPS configuration (at least in browsers implementation). Then SSL/TLS high cost of every new HTTPS connection became crucial case for further optimizations.\nThere are few steps required for improved SSL/TLS performance.\nEnable SSL session caching Use ssl_session_cache directive to cache parameters used when securing each new connection, ex.:\nssl_session_cache builtin:1000 shared:SSL:10m; Enable SSL session tickets Tickets store information about specific SSL/TLS connection so connection may be reused without new handshake, ex.:\nssl_session_tickets on; Configure OCSP stapling for SSL This will lower handshaking time by caching SSL/TLS certificate informations. This is per site/certificate configuration, ex.:\nssl_stapling on; ssl_stapling_verify on; ssl_certificate /etc/ssl/certs/my_site_cert.crt; ssl_certificate_key /etc/ssl/private/my_site_key.key; ssl_trusted_certificate /etc/ssl/certs/authority_cert.pem; A ssl_trusted_certificate file have to point to trusted certificate chain file - root + intermediate certificates (this can be downloaded from your certificate provider site (sometimes you have to merge by yourself those files).\nExcessive article in this topic could be found here: https://raymii.org/s/tutorials/OCSP_Stapling_on_nginx.html\nImplement HTTP/2 or SPDY If you have HTTPS configured the only thing you have to do is to add two options on listen directive, ex.:\nlisten 443 ssl http2; # currently http2 is preferred against spdy; # on SSL enabled vhost ssl on; You may also advertise for HTTP connection that you have newer protocol available, for that on HTTP connections use this header:\nadd_header Alternate-Protocol 443:npn-spdy/3; SPDY and HTTP/2 protocols use:\nheaders compression, single, multiplexed connection (carrying pieces of multiple requests and responses at the same time) rather than multiple connection for every piece of web page. After SPDY or HTTP/2 implementation you no longer need typical HTTP/1.1 optimizations like:\ndomain sharding, resource (JS/CSS) merging, image sprites. Tune other nginx performance options Access logs Disable access logs were you donâ€™t need them, ex.: for static files. You may also use buffer and flush options with access_log directive, ex.:\naccess_log /var/log/nginx/access.log buffer=1m flush=10s; With buffer Nginx will hold that much data in memory before writing it to disk. flush tells Nginx how often it should write gathered logs to disk.\nProxy buffering Turning proxy buffering may impact performance of your reverse proxy.\nNormally when buffering is disabled, Nginx will pass response directly to client synchronously.\nWhen buffering is enable it will store response in memory set by proxy_buffer_size option and if response is too big it will be stored in temporary file.\nproxy_buffering on; proxy_buffer_size 16k; Keepalive for client and upstream connections] Every new connection costs some time for handshake and will add latency to requests. By using keepalive connections will be reused without this overhead.\nFor client connections:\nkeepalive_timeout = 120s; For upstream connections:\nupstream web_backend { server 127.0.0.1:80; server 10.0.0.2:80; keepalive 32; } Limit connections to some resources Some time users/bots overload your service by querying it to fast. You may limit allowed connections to protect your service in such case, ex.:\nlimit_conn_zone $binary_remote_addr zone=owncloud:1m; server { # ... limit_conn owncloud 10; # ... } Adjust woker count Normally Nginx will start with only 1 worker process, you should adjust this variable to at the number of CPUâ€™s, in case of quad core CPU use in main section:\nworker_processes 4; Use socket sharding In latest kernel and Nginx versions (at least 1.9.1) there is new feature of sockets sharding. This will offload management of new connections to kernel. Each worker will create a socket listener and kernel will assign new connections to them as they become available.\nlisten 80 reuseport; Thread pools Thread pools are solution for mostly long blocking IO operations that may block whole Nginx event queue (ex. when used with big files or slow storage).\nlocation / { root /storage; aio threads; } This will help a lot if you see many Nginx processes in D state, with high IO wait times.\nTune Linux for performance Backlog queue If you could see on your system connection that appear to be staling then you have to increase net.core.somaxconn. This system parameter describes the maximum number of backlogged sockets. Default is 128 so setting this to 1024 should be no big deal on any decent machine.\necho \"net.core.somaxconn=1024\" \u003e\u003e /etc/sysctl.conf sysctl -p /etc/sysctl.conf File descriptors If your system is serving a lot of connections you may get reach system wide open descriptor limit. Nginx uses up to two descriptors for each connection. Then you have to increase sys.fs.fs_max.\necho \"sys.fs.fs_max=3191256\" \u003e\u003e /etc/sysctl.conf sysctl -p /etc/sysctl.conf Ephemeral ports Nginx used as a proxy creates temporary (ephemeral) ports for each upstream server. On busy proxy servers this will result in many connection in TIME_WAIT state.\nSolution for that is to increase range of available ports by setting net.ipv4.ip_local_port_range. You may also benefit from lowering net.ipv4.tcp_fin_timeout setting (connection will be released faster, but be careful with that).\nUse reverse-proxy This with microcaching technic is worth separate article, I will add link here when it will be ready.\nSource: http://www.fromdual.com/huge-amount-of-time-wait-connections https://www.nginx.com/blog/10-tips-for-10x-application-performance/ https://www.nginx.com/blog/socket-sharding-nginx-release-1-9-1/ https://www.nginx.com/blog/thread-pools-boost-performance-9x/ https://tweaked.io/guide/kernel/ https://t37.net/nginx-optimization-understanding-sendfile-tcp_nodelay-and-tcp_nopush.html ","wordCount":"1256","inLanguage":"en","datePublished":"2016-01-14T00:00:00Z","dateModified":"2016-01-14T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://gagor.pl/2016/01/optimize-nginx-for-performance/"},"publisher":{"@type":"Organization","name":"timor's site","logo":{"@type":"ImageObject","url":"https://gagor.pl/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://gagor.pl accesskey=h title="timor's site (Alt + H)"><img src=https://timor.site/favicon-72x72.png alt aria-label=logo height=36>timor's site</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://gagor.pl/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://gagor.pl/projects/ title=Projects><span>Projects</span></a></li><li><a href=https://gagor.pl/bookshelf/ title=Bookshelf><span>Bookshelf</span></a></li><li><a href=https://gagor.pl/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://gagor.pl/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://gagor.pl/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://gagor.pl>Home</a>&nbsp;Â»&nbsp;<a href=https://gagor.pl/posts/>Posts</a></div><h1 class=post-title>Optimize Nginx for performance</h1><div class=post-meta><span title='2016-01-14 00:00:00 +0000 UTC'>2016-01-14</span>&nbsp;Â·&nbsp;6 min</div></header><div class=post-content><p>There are many possible real life cases and not all optimization technics will be suitable for you but I hope it will be a good starting place.</p><p>Also you shouldn&rsquo;t copy paste examples with faith that they will make your server fly ðŸ˜ƒ You have to support your decisions with excessive tests and help of monitoring system (ex. <a href=/2016/01/grafana-installation-and-configuraton-with-influxdb-and-collectd-on-debian-ubuntu/>Grafana</a>).</p><h2 id=cache-static-and-dynamic-content>Cache static and dynamic content<a hidden class=anchor aria-hidden=true href=#cache-static-and-dynamic-content>#</a></h2><p>Setting caching static and dynamic content strategy may offload your server from additional load from repetitive downloads of same, rarely updated files. This will make your site to load faster for frequent visitors.</p><p>Example configuration:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=display:flex><span><span style=color:#66d9ef>location</span> ~<span style=color:#e6db74>*</span> <span style=color:#e6db74>^.+\.(?:jpg|png|css|gif|jpeg|js|swf|m4v)</span>$ {
</span></span><span style=display:flex><span>    <span style=color:#f92672>access_log</span> <span style=color:#66d9ef>off</span>; <span style=color:#f92672>log_not_found</span> <span style=color:#66d9ef>off</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>tcp_nodelay</span> <span style=color:#66d9ef>off</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>open_file_cache</span> <span style=color:#e6db74>max=500</span> <span style=color:#e6db74>inactive=120s</span>;
</span></span><span style=display:flex><span>    <span style=color:#f92672>open_file_cache_valid</span> <span style=color:#e6db74>45s</span>;
</span></span><span style=display:flex><span>    <span style=color:#f92672>open_file_cache_min_uses</span> <span style=color:#ae81ff>2</span>;
</span></span><span style=display:flex><span>    <span style=color:#f92672>open_file_cache_errors</span> <span style=color:#66d9ef>off</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>expires</span> <span style=color:#e6db74>max</span>;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>For additional performance gain, you may:</p><ul><li>disable logging for static files,</li><li>disable <code>tcp_nodelay</code> option - it&rsquo;s useful to send a lot of small files (ideally smaller than single TCP packet - 1,5Kb), but images are rather big files and sending them all together will gain better performance,</li><li>play with <code>open_file_cache</code> - it will take off some IO load,</li><li>add long long <code>expires</code>.</li></ul><p>Caching dynamic content is harder case. There are articles that are rarely updated and they may lay in cache forever but other pages are pretty dynamic and shouldn&rsquo;t be cached for long. Even if caching dynamic content sounds scary for you it&rsquo;s not. So called <code>micro caching</code> (caching for short period of time, like 1s) - is great solution for <a href=https://en.wikipedia.org/wiki/Slashdot_effect>digg effect</a> or <a href=https://en.wikipedia.org/wiki/Slashdot_effect>slashdotting</a>.</p><p>Let say your page gets ten views per second and you will cache ever site for 1s, then you will be able to server 90% of requests from cache. Leaving precious CPU cycles for other tasks.</p><h2 id=compress-data>Compress data<a hidden class=anchor aria-hidden=true href=#compress-data>#</a></h2><p>On your page you should use filetypes that are efficiently compressed like: JPEG, PNG, MP3, etc. But all HTML, CSS, JS may be compressed too on the fly by web server, just enable options like that globally:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=display:flex><span><span style=color:#66d9ef>gzip</span> <span style=color:#66d9ef>on</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>gzip_vary</span> <span style=color:#66d9ef>on</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>gzip_disable</span> <span style=color:#e6db74>&#34;msie6&#34;</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>gzip_comp_level</span> <span style=color:#ae81ff>1</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>gzip_proxied</span> <span style=color:#e6db74>any</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>gzip_buffers</span> <span style=color:#ae81ff>16</span> <span style=color:#ae81ff>8k</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>gzip_min_length</span> <span style=color:#ae81ff>50</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>gzip_types</span> <span style=color:#e6db74>text/plain</span> <span style=color:#e6db74>text/css</span> <span style=color:#e6db74>application/json</span> <span style=color:#e6db74>application/x-javascript</span> <span style=color:#e6db74>application/javascript</span> <span style=color:#e6db74>text/javascript</span> <span style=color:#e6db74>application/atom+xml</span> <span style=color:#e6db74>application/xml</span> <span style=color:#e6db74>application/xml+rss</span> <span style=color:#e6db74>text/xml</span> <span style=color:#e6db74>image/x-icon</span> <span style=color:#e6db74>text/x-js</span> <span style=color:#e6db74>application/xhtml+xml</span> <span style=color:#e6db74>image/svg+xml</span>;
</span></span></code></pre></div><p>You may also precompress these files stronger during build/deploy process and use <code>gzip_static</code> module to serve them without additional overhead for compression. Ex.:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=display:flex><span><span style=color:#66d9ef>gzip_static</span> <span style=color:#66d9ef>on</span>;
</span></span></code></pre></div><p>Then use script like this to compress files:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>find /var/www -iname *.js -print0 |xargs -0 -I<span style=color:#e6db74>&#39;{}&#39;</span> sh -c <span style=color:#e6db74>&#39;gzip -c9 &#34;{}&#34; &gt; &#34;{}.gz&#34; &amp;&amp; touch -r &#34;{}&#34; &#34;{}.gz&#34;&#39;</span>
</span></span><span style=display:flex><span>find /var/www -iname *.css -print0 |xargs -0 -I<span style=color:#e6db74>&#39;{}&#39;</span> sh -c <span style=color:#e6db74>&#39;gzip -c9 &#34;{}&#34; &gt; &#34;{}.gz&#34; &amp;&amp; touch -r &#34;{}&#34; &#34;{}.gz&#34;&#39;</span>
</span></span></code></pre></div><p>Files have to had same timestamp like original (not compressed) file to be used by Nginx.</p><h2 id=optimize-ssltls>Optimize SSL/TLS<a hidden class=anchor aria-hidden=true href=#optimize-ssltls>#</a></h2><p>New optimized versions of HTTP protocols like <code>HTTP/2</code> or <code>SPDY</code> require HTTPS configuration (at least in browsers implementation). Then SSL/TLS high cost of every new HTTPS connection became crucial case for further optimizations.</p><p>There are few steps required for improved SSL/TLS performance.</p><h3 id=enable-ssl-session-caching>Enable SSL session caching<a hidden class=anchor aria-hidden=true href=#enable-ssl-session-caching>#</a></h3><p>Use <code>ssl_session_cache</code> directive to cache parameters used when securing each new connection, ex.:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=display:flex><span><span style=color:#66d9ef>ssl_session_cache</span> builtin:<span style=color:#ae81ff>1000</span> <span style=color:#e6db74>shared:SSL:10m</span>;
</span></span></code></pre></div><h3 id=enable-ssl-session-tickets>Enable SSL session tickets<a hidden class=anchor aria-hidden=true href=#enable-ssl-session-tickets>#</a></h3><p>Tickets store information about specific SSL/TLS connection so connection may be reused without new handshake, ex.:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=display:flex><span><span style=color:#66d9ef>ssl_session_tickets</span> <span style=color:#66d9ef>on</span>;
</span></span></code></pre></div><h3 id=configure-ocsp-stapling-for-ssl>Configure OCSP stapling for SSL<a hidden class=anchor aria-hidden=true href=#configure-ocsp-stapling-for-ssl>#</a></h3><p>This will lower handshaking time by caching SSL/TLS certificate informations. This is per site/certificate configuration, ex.:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=display:flex><span>  <span style=color:#66d9ef>ssl_stapling</span> <span style=color:#66d9ef>on</span>;
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>ssl_stapling_verify</span> <span style=color:#66d9ef>on</span>;
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>ssl_certificate</span> <span style=color:#e6db74>/etc/ssl/certs/my_site_cert.crt</span>;
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>ssl_certificate_key</span> <span style=color:#e6db74>/etc/ssl/private/my_site_key.key</span>;
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>ssl_trusted_certificate</span> <span style=color:#e6db74>/etc/ssl/certs/authority_cert.pem</span>;
</span></span></code></pre></div><p>A <code>ssl_trusted_certificate</code> file have to point to trusted certificate chain file - root + intermediate certificates (this can be downloaded from your certificate provider site (sometimes you have to merge by yourself those files).</p><p>Excessive article in this topic could be found here: <a href=https://raymii.org/s/tutorials/OCSP_Stapling_on_nginx.html>https://raymii.org/s/tutorials/OCSP_Stapling_on_nginx.html</a></p><h2 id=implement-http2-or-spdy>Implement HTTP/2 or SPDY<a hidden class=anchor aria-hidden=true href=#implement-http2-or-spdy>#</a></h2><p>If you have HTTPS configured the only thing you have to do is to add two options on <code>listen</code> directive, ex.:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=display:flex><span><span style=color:#66d9ef>listen</span> <span style=color:#ae81ff>443</span> <span style=color:#e6db74>ssl</span> <span style=color:#e6db74>http2</span>; <span style=color:#75715e># currently http2 is preferred against spdy;
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span><span style=color:#75715e># on SSL enabled vhost
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>ssl</span> <span style=color:#66d9ef>on</span>;
</span></span></code></pre></div><p>You may also advertise for HTTP connection that you have newer protocol available, for that on HTTP connections use this header:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=display:flex><span><span style=color:#66d9ef>add_header</span> <span style=color:#e6db74>Alternate-Protocol</span> <span style=color:#ae81ff>443</span>:<span style=color:#e6db74>npn-spdy/3</span>;
</span></span></code></pre></div><p>SPDY and HTTP/2 protocols use:</p><ul><li>headers compression,</li><li>single, multiplexed connection (carrying pieces of multiple requests and responses at the same time) rather than multiple connection for every piece of web page.</li></ul><p>After SPDY or HTTP/2 implementation you no longer need typical HTTP/1.1 optimizations like:</p><ul><li>domain sharding,</li><li>resource (JS/CSS) merging,</li><li>image sprites.</li></ul><h2 id=tune-other-nginx-performance-options>Tune other nginx performance options<a hidden class=anchor aria-hidden=true href=#tune-other-nginx-performance-options>#</a></h2><h3 id=access-logs>Access logs<a hidden class=anchor aria-hidden=true href=#access-logs>#</a></h3><p>Disable access logs were you don&rsquo;t need them, ex.: for static files. You may also use <code>buffer</code> and <code>flush</code> options with <code>access_log</code> directive, ex.:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=display:flex><span><span style=color:#66d9ef>access_log</span> <span style=color:#e6db74>/var/log/nginx/access.log</span> <span style=color:#e6db74>buffer=1m</span> <span style=color:#e6db74>flush=10s</span>;
</span></span></code></pre></div><p>With <code>buffer</code> Nginx will hold that much data in memory before writing it to disk. <code>flush</code> tells Nginx how often it should write gathered logs to disk.</p><h3 id=proxy-buffering>Proxy buffering<a hidden class=anchor aria-hidden=true href=#proxy-buffering>#</a></h3><p>Turning <a href=http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_buffers>proxy buffering</a> may impact performance of your reverse proxy.</p><p>Normally when buffering is disabled, Nginx will pass response directly to client synchronously.</p><p>When buffering is enable it will store response in memory set by <code>proxy_buffer_size</code> option and if response is too big it will be stored in temporary file.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=display:flex><span><span style=color:#66d9ef>proxy_buffering</span> <span style=color:#66d9ef>on</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>proxy_buffer_size</span> <span style=color:#ae81ff>16k</span>;
</span></span></code></pre></div><h3 id=keepalive-for-client-and-upstream-connections>Keepalive for client and upstream connections]<a hidden class=anchor aria-hidden=true href=#keepalive-for-client-and-upstream-connections>#</a></h3><p>Every new connection costs some time for handshake and will add latency to requests. By using keepalive connections will be reused without this overhead.</p><p>For <a href=http://nginx.org/en/docs/http/ngx_http_core_module.html#keepalive_timeout>client connections</a>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=display:flex><span><span style=color:#66d9ef>keepalive_timeout</span> = <span style=color:#e6db74>120s</span>;
</span></span></code></pre></div><p>For <a href=http://nginx.org/en/docs/http/ngx_http_upstream_module.html#keepalive>upstream connections</a>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=display:flex><span><span style=color:#66d9ef>upstream</span> <span style=color:#e6db74>web_backend</span> {
</span></span><span style=display:flex><span>    <span style=color:#f92672>server</span> 127.0.0.1:<span style=color:#ae81ff>80</span>;
</span></span><span style=display:flex><span>    <span style=color:#f92672>server</span> 10.0.0.2:<span style=color:#ae81ff>80</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>keepalive</span> <span style=color:#ae81ff>32</span>;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h3 id=limit-connections-to-some-resources>Limit connections to some resources<a hidden class=anchor aria-hidden=true href=#limit-connections-to-some-resources>#</a></h3><p>Some time users/bots overload your service by querying it to fast. You may <a href=http://nginx.org/en/docs/http/ngx_http_limit_conn_module.html>limit allowed connections</a> to protect your service in such case, ex.:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=display:flex><span><span style=color:#66d9ef>limit_conn_zone</span> $binary_remote_addr <span style=color:#e6db74>zone=owncloud:1m</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>server</span> {
</span></span><span style=display:flex><span>    <span style=color:#75715e># ...
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#f92672>limit_conn</span> <span style=color:#e6db74>owncloud</span> <span style=color:#ae81ff>10</span>;
</span></span><span style=display:flex><span>    <span style=color:#75715e># ...
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>}
</span></span></code></pre></div><h3 id=adjust-woker-count>Adjust woker count<a hidden class=anchor aria-hidden=true href=#adjust-woker-count>#</a></h3><p><a href=http://nginx.org/en/docs/ngx_core_module.html#worker_processes>Normally Nginx will start with only 1 worker process</a>, you should adjust this variable to at the number of CPU&rsquo;s, in case of quad core CPU use in main section:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=display:flex><span><span style=color:#66d9ef>worker_processes</span> <span style=color:#ae81ff>4</span>;
</span></span></code></pre></div><h3 id=use-socket-sharding>Use socket sharding<a hidden class=anchor aria-hidden=true href=#use-socket-sharding>#</a></h3><p>In latest kernel and Nginx versions (at least 1.9.1) there is new feature of sockets sharding. This will offload management of new connections to kernel. Each worker will create a socket listener and kernel will assign new connections to them as they become available.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=display:flex><span><span style=color:#66d9ef>listen</span> <span style=color:#ae81ff>80</span> <span style=color:#e6db74>reuseport</span>;
</span></span></code></pre></div><h3 id=thread-pools>Thread pools<a hidden class=anchor aria-hidden=true href=#thread-pools>#</a></h3><p><a href=http://nginx.org/en/docs/http/ngx_http_core_module.html#aio>Thread pools</a> are solution for mostly long blocking IO operations that may block whole Nginx event queue (ex. when used with big files or slow storage).</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=display:flex><span><span style=color:#66d9ef>location</span> <span style=color:#e6db74>/</span> {
</span></span><span style=display:flex><span>    <span style=color:#f92672>root</span> <span style=color:#e6db74>/storage</span>;
</span></span><span style=display:flex><span>    <span style=color:#f92672>aio</span> <span style=color:#e6db74>threads</span>;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>This will help a lot if you see many Nginx processes in <strong>D</strong> state, with high IO wait times.</p><h2 id=tune-linux-for-performance>Tune Linux for performance<a hidden class=anchor aria-hidden=true href=#tune-linux-for-performance>#</a></h2><h3 id=backlog-queue>Backlog queue<a hidden class=anchor aria-hidden=true href=#backlog-queue>#</a></h3><p>If you could see on your system connection that appear to be staling then you have to increase <code>net.core.somaxconn</code>. This system parameter describes the maximum number of <code>backlogged sockets</code>. Default is 128 so setting this to 1024 should be no big deal on any decent machine.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>echo <span style=color:#e6db74>&#34;net.core.somaxconn=1024&#34;</span> &gt;&gt; /etc/sysctl.conf
</span></span><span style=display:flex><span>sysctl -p /etc/sysctl.conf
</span></span></code></pre></div><h3 id=file-descriptors>File descriptors<a hidden class=anchor aria-hidden=true href=#file-descriptors>#</a></h3><p>If your system is serving a lot of connections you may get reach system wide open descriptor limit. Nginx uses up to two descriptors for each connection. Then you have to increase <code>sys.fs.fs_max</code>.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>echo <span style=color:#e6db74>&#34;sys.fs.fs_max=3191256&#34;</span> &gt;&gt; /etc/sysctl.conf
</span></span><span style=display:flex><span>sysctl -p /etc/sysctl.conf
</span></span></code></pre></div><h3 id=ephemeral-ports>Ephemeral ports<a hidden class=anchor aria-hidden=true href=#ephemeral-ports>#</a></h3><p>Nginx used as a proxy creates temporary (ephemeral) ports for each upstream server. On busy proxy servers this will result in many connection in TIME_WAIT state.<br>Solution for that is to increase range of available ports by setting <code>net.ipv4.ip_local_port_range</code>. You may also benefit from lowering <code>net.ipv4.tcp_fin_timeout</code> setting (connection will be released faster, but be careful with that).</p><h2 id=use-reverse-proxy>Use reverse-proxy<a hidden class=anchor aria-hidden=true href=#use-reverse-proxy>#</a></h2><p>This with microcaching technic is worth separate article, I will add link here when it will be ready.</p><h5 id=source>Source:<a hidden class=anchor aria-hidden=true href=#source>#</a></h5><ul><li><a href=http://www.fromdual.com/huge-amount-of-time-wait-connections>http://www.fromdual.com/huge-amount-of-time-wait-connections</a></li><li><a href=https://www.nginx.com/blog/10-tips-for-10x-application-performance/>https://www.nginx.com/blog/10-tips-for-10x-application-performance/</a></li><li><a href=https://www.nginx.com/blog/socket-sharding-nginx-release-1-9-1/>https://www.nginx.com/blog/socket-sharding-nginx-release-1-9-1/</a></li><li><a href=https://www.nginx.com/blog/thread-pools-boost-performance-9x/>https://www.nginx.com/blog/thread-pools-boost-performance-9x/</a></li><li><a href=https://tweaked.io/guide/kernel/>https://tweaked.io/guide/kernel/</a></li><li><a href=https://t37.net/nginx-optimization-understanding-sendfile-tcp_nodelay-and-tcp_nopush.html>https://t37.net/nginx-optimization-understanding-sendfile-tcp_nodelay-and-tcp_nopush.html</a></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://gagor.pl/tags/linux/>Linux</a></li><li><a href=https://gagor.pl/tags/nginx/>nginx</a></li></ul><nav class=paginav><a class=prev href=https://gagor.pl/2016/02/zeitgeist-activity-sqlite-wal-getting-huge/><span class=title>Â« Prev</span><br><span>Zeitgeist activity.sqlite-wal getting huge</span></a>
<a class=next href=https://gagor.pl/2016/01/xenserver-export-vm-to-file/><span class=title>Next Â»</span><br><span>XenServer - export VM to file</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Optimize Nginx for performance on twitter" href="https://twitter.com/intent/tweet/?text=Optimize%20Nginx%20for%20performance&amp;url=https%3a%2f%2fgagor.pl%2f2016%2f01%2foptimize-nginx-for-performance%2f&amp;hashtags=Linux%2cnginx"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Optimize Nginx for performance on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fgagor.pl%2f2016%2f01%2foptimize-nginx-for-performance%2f&amp;title=Optimize%20Nginx%20for%20performance&amp;summary=Optimize%20Nginx%20for%20performance&amp;source=https%3a%2f%2fgagor.pl%2f2016%2f01%2foptimize-nginx-for-performance%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Optimize Nginx for performance on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fgagor.pl%2f2016%2f01%2foptimize-nginx-for-performance%2f&title=Optimize%20Nginx%20for%20performance"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Optimize Nginx for performance on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fgagor.pl%2f2016%2f01%2foptimize-nginx-for-performance%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Optimize Nginx for performance on whatsapp" href="https://api.whatsapp.com/send?text=Optimize%20Nginx%20for%20performance%20-%20https%3a%2f%2fgagor.pl%2f2016%2f01%2foptimize-nginx-for-performance%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Optimize Nginx for performance on telegram" href="https://telegram.me/share/url?text=Optimize%20Nginx%20for%20performance&amp;url=https%3a%2f%2fgagor.pl%2f2016%2f01%2foptimize-nginx-for-performance%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//gagor-pl.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></article></main><footer class=footer><span><a href=https://gagor.pl>timor's site</a> &copy; 2008-2023</span>
<span>Content licensed under <a rel="license noopener noreferrer" target=_blank href=http://creativecommons.org/licenses/by-sa/4.0/>(CC BY-SA 4.0)</a></span></footer><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>
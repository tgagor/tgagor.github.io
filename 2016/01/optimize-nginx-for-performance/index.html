<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="There are many possible real life cases and not all optimization technics will be suitable for you but I hope it will be a good starting place.
Also you shouldn&rsquo;t copy paste examples with faith that they will make your server fly ðŸ˜ƒ You have to support your decisions with excessive tests and help of monitoring system (ex. Grafana).
Cache static and dynamic content Setting caching static and dynamic content strategy may offload your server from additional load from repetitive downloads of same, rarely updated files."><meta name=theme-color content="#c64858"><meta property="og:title" content="Optimize Nginx for performance â€¢ TiMoR"><meta property="og:description" content="There are many possible real life cases and not all optimization technics will be suitable for you but I hope it will be a good starting place.
Also you shouldn&rsquo;t copy paste examples with faith that they will make your server fly ðŸ˜ƒ You have to support your decisions with excessive tests and help of monitoring system (ex. Grafana).
Cache static and dynamic content Setting caching static and dynamic content strategy may offload your server from additional load from repetitive downloads of same, rarely updated files."><meta property="og:url" content="https://timor.site/2016/01/optimize-nginx-for-performance/"><meta property="og:site_name" content="timor's site"><meta property="og:type" content="article"><meta property="og:image" content="https://www.gravatar.com/avatar/cfa9a17577371083824a78c303cc8ed7?s=256"><meta property="article:section" content="posts"><meta property="article:tag" content="Linux"><meta property="article:tag" content="nginx"><meta property="article:published_time" content="2016-01-14T00:00:00Z"><meta property="article:modified_time" content="2016-01-14T00:00:00Z"><meta name=twitter:card content="summary"><meta name=generator content="Hugo 0.76.5"><title>Optimize Nginx for performance â€¢ TiMoR</title><link rel=canonical href=https://timor.site/2016/01/optimize-nginx-for-performance/><link rel=icon href=/favicon.ico><link rel=stylesheet href=/assets/css/main.ab98e12b.css><style>:root{--color-accent:#c64858}</style><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-88996819-1','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script></head><body class="page type-posts layout-post has-sidebar"><div class=site><div id=sidebar class=sidebar><a class=screen-reader-text href=#main-menu>Skip to Main Menu</a><div class=container><section class="widget widget-about sep-after"><header><div class=logo><a href=/><img src=/favicon.ico></a></div><h2 class="title site-title"><a href=/>timor's site</a></h2><div class=desc>Linux configuration, Automation, Security - Sysadmin/DevOps blog</div></header></section><section class="widget widget-search sep-after"><header><h4 class="title widget-title">Search</h4></header><form action=/search id=search-form class=search-form><label><span class=screen-reader-text>Search</span>
<input id=search-term class=search-term type=search name=q placeholder=Search&mldr;></label></form></section><section class="widget widget-sidebar_menu sep-after"><nav id=sidebar-menu class="menu sidebar-menu" aria-label="Sidebar Menu"><div class=container><ul><li class=item><a href=/></a></li><li class=item><a href=/>Home</a></li><li class="item has-children"><a href=/categories/howto/>HOWTO</a><button class=sub-menu-toggler>
<span class=screen-reader-text>expand sub menu</span>
<span class=sign></span></button><ul class=sub-menu><li class=item><a href=/categories/tip/>Tips</a></li></ul></li><li class=item><a href=/categories/off-topic/>Off-topic</a></li><li class=item><a href=/categories/gotowanie/>Gotowanie</a></li><li class=item><a href=/about/>About</a></li></ul></div></nav></section></div><div class=sidebar-overlay></div></div><div class=main><a class=screen-reader-text href=#content>Skip to Content</a>
<button id=sidebar-toggler class=sidebar-toggler aria-controls=sidebar>
<span class=screen-reader-text>Toggle Sidebar</span>
<span class=open><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="18" x2="21" y2="18"/></svg></span><span class=close><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><line x1="18" y1="6" x2="6" y2="18"/><line x1="6" y1="6" x2="18" y2="18"/></svg></span></button><div class=header-widgets><div class=container><style>.widget-breadcrumbs li:after{content:'\2f '}</style><section class="widget widget-breadcrumbs sep-after"><nav id=breadcrumbs><ol><li><a href=/>Home</a></li><li><a href=/posts/>Posts</a></li><li><span>Optimize Nginx for performance</span></li></ol></nav></section></div></div><header id=header class="header site-header"><div class="container sep-after"><div class=header-info><p class="site-title title">timor's site</p><p class="desc site-desc">Linux configuration, Automation, Security - Sysadmin/DevOps blog</p></div></div></header><main id=content><article lang=en class=entry><header class="header entry-header"><div class="container sep-after"><div class=header-info><h1 class=title>Optimize Nginx for performance</h1></div><div class=entry-meta><span class=posted-on><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg><span class=screen-reader-text>Posted on</span>
<time class=entry-date datetime=2016-01-14T00:00:00Z>2016-01-14</time></span>
<span class=byline><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M21 21V20c0-2.76-4-5-9-5s-9 2.24-9 5v1"/><path d="M16 6.37A4 4 0 1112.63 3 4 4 0 0116 6.37z"/></svg><span class=screen-reader-text>by </span><a href=/authors/timor>TiMoR</a></span>
<span class=reading-time><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 15 15"/></svg>6 mins read</span></div></div></header><div class="container entry-content"><p>There are many possible real life cases and not all optimization technics will be suitable for you but I hope it will be a good starting place.</p><p>Also you shouldn&rsquo;t copy paste examples with faith that they will make your server fly ðŸ˜ƒ You have to support your decisions with excessive tests and help of monitoring system (ex. <a href=/2016/01/grafana-installation-and-configuraton-with-influxdb-and-collectd-on-debian-ubuntu/>Grafana</a>).</p><h2 id=cache-static-and-dynamic-content>Cache static and dynamic content</h2><p>Setting caching static and dynamic content strategy may offload your server from additional load from repetitive downloads of same, rarely updated files. This will make your site to load faster for frequent visitors.</p><p>Example configuration:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=color:#66d9ef>location</span> ~<span style=color:#e6db74>*</span> <span style=color:#e6db74>^.+\.(?:jpg|png|css|gif|jpeg|js|swf|m4v)</span>$ {
    <span style=color:#f92672>access_log</span> <span style=color:#66d9ef>off</span>; <span style=color:#f92672>log_not_found</span> <span style=color:#66d9ef>off</span>;

    <span style=color:#f92672>tcp_nodelay</span> <span style=color:#66d9ef>off</span>;

    <span style=color:#f92672>open_file_cache</span> <span style=color:#e6db74>max=500</span> <span style=color:#e6db74>inactive=120s</span>;
    <span style=color:#f92672>open_file_cache_valid</span> <span style=color:#e6db74>45s</span>;
    <span style=color:#f92672>open_file_cache_min_uses</span> <span style=color:#ae81ff>2</span>;
    <span style=color:#f92672>open_file_cache_errors</span> <span style=color:#66d9ef>off</span>;

    <span style=color:#f92672>expires</span> <span style=color:#e6db74>max</span>;
}
</code></pre></div><p>For additional performance gain, you may:</p><ul><li>disable logging for static files,</li><li>disable <code>tcp_nodelay</code> option - it&rsquo;s useful to send a lot of small files (ideally smaller than single TCP packet - 1,5Kb), but images are rather big files and sending them all together will gain better performance,</li><li>play with <code>open_file_cache</code> - it will take off some IO load,</li><li>add long long <code>expires</code>.</li></ul><p>Caching dynamic content is harder case. There are articles that are rarely updated and they may lay in cache forever but other pages are pretty dynamic and shouldn&rsquo;t be cached for long. Even if caching dynamic content sounds scary for you it&rsquo;s not. So called <code>micro caching</code> (caching for short period of time, like 1s) - is great solution for <a href=https://en.wikipedia.org/wiki/Slashdot_effect>digg effect</a> or <a href=https://en.wikipedia.org/wiki/Slashdot_effect>slashdotting</a>.</p><p>Let say your page gets ten views per second and you will cache ever site for 1s, then you will be able to server 90% of requests from cache. Leaving precious CPU cycles for other tasks.</p><h2 id=compress-data>Compress data</h2><p>On your page you should use filetypes that are efficiently compressed like: JPEG, PNG, MP3, etc. But all HTML, CSS, JS may be compressed too on the fly by web server, just enable options like that globally:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=color:#66d9ef>gzip</span> <span style=color:#66d9ef>on</span>;
<span style=color:#66d9ef>gzip_vary</span> <span style=color:#66d9ef>on</span>;
<span style=color:#66d9ef>gzip_disable</span> <span style=color:#e6db74>&#34;msie6&#34;</span>;
<span style=color:#66d9ef>gzip_comp_level</span> <span style=color:#ae81ff>1</span>;
<span style=color:#66d9ef>gzip_proxied</span> <span style=color:#e6db74>any</span>;
<span style=color:#66d9ef>gzip_buffers</span> <span style=color:#ae81ff>16</span> <span style=color:#ae81ff>8k</span>;
<span style=color:#66d9ef>gzip_min_length</span> <span style=color:#ae81ff>50</span>;
<span style=color:#66d9ef>gzip_types</span> <span style=color:#e6db74>text/plain</span> <span style=color:#e6db74>text/css</span> <span style=color:#e6db74>application/json</span> <span style=color:#e6db74>application/x-javascript</span> <span style=color:#e6db74>application/javascript</span> <span style=color:#e6db74>text/javascript</span> <span style=color:#e6db74>application/atom+xml</span> <span style=color:#e6db74>application/xml</span> <span style=color:#e6db74>application/xml+rss</span> <span style=color:#e6db74>text/xml</span> <span style=color:#e6db74>image/x-icon</span> <span style=color:#e6db74>text/x-js</span> <span style=color:#e6db74>application/xhtml+xml</span> <span style=color:#e6db74>image/svg+xml</span>;
</code></pre></div><p>You may also precompress these files stronger during build/deploy process and use <code>gzip_static</code> module to serve them without additional overhead for compression. Ex.:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=color:#66d9ef>gzip_static</span> <span style=color:#66d9ef>on</span>;
</code></pre></div><p>Then use script like this to compress files:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>find /var/www -iname *.js -print0 |xargs -0 -I<span style=color:#e6db74>&#39;{}&#39;</span> sh -c <span style=color:#e6db74>&#39;gzip -c9 &#34;{}&#34; &gt; &#34;{}.gz&#34; &amp;&amp; touch -r &#34;{}&#34; &#34;{}.gz&#34;&#39;</span>
find /var/www -iname *.css -print0 |xargs -0 -I<span style=color:#e6db74>&#39;{}&#39;</span> sh -c <span style=color:#e6db74>&#39;gzip -c9 &#34;{}&#34; &gt; &#34;{}.gz&#34; &amp;&amp; touch -r &#34;{}&#34; &#34;{}.gz&#34;&#39;</span>
</code></pre></div><p>Files have to had same timestamp like original (not compressed) file to be used by Nginx.</p><h2 id=optimize-ssltls>Optimize SSL/TLS</h2><p>New optimized versions of HTTP protocols like <code>HTTP/2</code> or <code>SPDY</code> require HTTPS configuration (at least in browsers implementation). Then SSL/TLS high cost of every new HTTPS connection became crucial case for further optimizations.</p><p>There are few steps required for improved SSL/TLS performance.</p><h3 id=enable-ssl-session-caching>Enable SSL session caching</h3><p>Use <code>ssl_session_cache</code> directive to cache parameters used when securing each new connection, ex.:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=color:#66d9ef>ssl_session_cache</span> builtin:<span style=color:#ae81ff>1000</span> <span style=color:#e6db74>shared:SSL:10m</span>;
</code></pre></div><h3 id=enable-ssl-session-tickets>Enable SSL session tickets</h3><p>Tickets store information about specific SSL/TLS connection so connection may be reused without new handshake, ex.:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=color:#66d9ef>ssl_session_tickets</span> <span style=color:#66d9ef>on</span>;
</code></pre></div><h3 id=configure-ocsp-stapling-for-ssl>Configure OCSP stapling for SSL</h3><p>This will lower handshaking time by caching SSL/TLS certificate informations. This is per site/certificate configuration, ex.:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx>  <span style=color:#66d9ef>ssl_stapling</span> <span style=color:#66d9ef>on</span>;
  <span style=color:#66d9ef>ssl_stapling_verify</span> <span style=color:#66d9ef>on</span>;
  <span style=color:#66d9ef>ssl_certificate</span> <span style=color:#e6db74>/etc/ssl/certs/my_site_cert.crt</span>;
  <span style=color:#66d9ef>ssl_certificate_key</span> <span style=color:#e6db74>/etc/ssl/private/my_site_key.key</span>;
  <span style=color:#66d9ef>ssl_trusted_certificate</span> <span style=color:#e6db74>/etc/ssl/certs/authority_cert.pem</span>;
</code></pre></div><p>A <code>ssl_trusted_certificate</code> file have to point to trusted certificate chain file - root + intermediate certificates (this can be downloaded from your certificate provider site (sometimes you have to merge by yourself those files).</p><p>Excessive article in this topic could be found here: <a href=https://raymii.org/s/tutorials/OCSP_Stapling_on_nginx.html>https://raymii.org/s/tutorials/OCSP_Stapling_on_nginx.html</a></p><h2 id=implement-http2-or-spdy>Implement HTTP/2 or SPDY</h2><p>If you have HTTPS configured the only thing you have to do is to add two options on <code>listen</code> directive, ex.:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=color:#66d9ef>listen</span> <span style=color:#ae81ff>443</span> <span style=color:#e6db74>ssl</span> <span style=color:#e6db74>http2</span>; <span style=color:#75715e># currently http2 is preferred against spdy;
</span><span style=color:#75715e></span>
<span style=color:#75715e># on SSL enabled vhost
</span><span style=color:#75715e></span><span style=color:#66d9ef>ssl</span> <span style=color:#66d9ef>on</span>;
</code></pre></div><p>You may also advertise for HTTP connection that you have newer protocol available, for that on HTTP connections use this header:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=color:#66d9ef>add_header</span> <span style=color:#e6db74>Alternate-Protocol</span> <span style=color:#ae81ff>443</span>:<span style=color:#e6db74>npn-spdy/3</span>;
</code></pre></div><p>SPDY and HTTP/2 protocols use:</p><ul><li>headers compression,</li><li>single, multiplexed connection (carrying pieces of multiple requests and responses at the same time) rather than multiple connection for every piece of web page.</li></ul><p>After SPDY or HTTP/2 implementation you no longer need typical HTTP/1.1 optimizations like:</p><ul><li>domain sharding,</li><li>resource (JS/CSS) merging,</li><li>image sprites.</li></ul><h2 id=tune-other-nginx-performance-options>Tune other nginx performance options</h2><h3 id=access-logs>Access logs</h3><p>Disable access logs were you don&rsquo;t need them, ex.: for static files. You may also use <code>buffer</code> and <code>flush</code> options with <code>access_log</code> directive, ex.:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=color:#66d9ef>access_log</span> <span style=color:#e6db74>/var/log/nginx/access.log</span> <span style=color:#e6db74>buffer=1m</span> <span style=color:#e6db74>flush=10s</span>;
</code></pre></div><p>With <code>buffer</code> Nginx will hold that much data in memory before writing it to disk. <code>flush</code> tells Nginx how often it should write gathered logs to disk.</p><h3 id=proxy-buffering>Proxy buffering</h3><p>Turning <a href=http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_buffers>proxy buffering</a> may impact performance of your reverse proxy.</p><p>Normally when buffering is disabled, Nginx will pass response directly to client synchronously.</p><p>When buffering is enable it will store response in memory set by <code>proxy_buffer_size</code> option and if response is too big it will be stored in temporary file.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=color:#66d9ef>proxy_buffering</span> <span style=color:#66d9ef>on</span>;
<span style=color:#66d9ef>proxy_buffer_size</span> <span style=color:#ae81ff>16k</span>;
</code></pre></div><h3 id=keepalive-for-client-and-upstream-connections>Keepalive for client and upstream connections]</h3><p>Every new connection costs some time for handshake and will add latency to requests. By using keepalive connections will be reused without this overhead.</p><p>For <a href=http://nginx.org/en/docs/http/ngx_http_core_module.html#keepalive_timeout>client connections</a>:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=color:#66d9ef>keepalive_timeout</span> = <span style=color:#e6db74>120s</span>;
</code></pre></div><p>For <a href=http://nginx.org/en/docs/http/ngx_http_upstream_module.html#keepalive>upstream connections</a>:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=color:#66d9ef>upstream</span> <span style=color:#e6db74>web_backend</span> {
    <span style=color:#f92672>server</span> 127.0.0.1:<span style=color:#ae81ff>80</span>;
    <span style=color:#f92672>server</span> 10.0.0.2:<span style=color:#ae81ff>80</span>;

    <span style=color:#f92672>keepalive</span> <span style=color:#ae81ff>32</span>;
}
</code></pre></div><h3 id=limit-connections-to-some-resources>Limit connections to some resources</h3><p>Some time users/bots overload your service by querying it to fast. You may <a href=http://nginx.org/en/docs/http/ngx_http_limit_conn_module.html>limit allowed connections</a> to protect your service in such case, ex.:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=color:#66d9ef>limit_conn_zone</span> $binary_remote_addr <span style=color:#e6db74>zone=owncloud:1m</span>;

<span style=color:#66d9ef>server</span> {
    <span style=color:#75715e># ...
</span><span style=color:#75715e></span>    <span style=color:#f92672>limit_conn</span> <span style=color:#e6db74>owncloud</span> <span style=color:#ae81ff>10</span>;
    <span style=color:#75715e># ...
</span><span style=color:#75715e></span>}
</code></pre></div><h3 id=adjust-woker-count>Adjust woker count</h3><p><a href=http://nginx.org/en/docs/ngx_core_module.html#worker_processes>Normally Nginx will start with only 1 worker process</a>, you should adjust this variable to at the number of CPU&rsquo;s, in case of quad core CPU use in main section:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=color:#66d9ef>worker_processes</span> <span style=color:#ae81ff>4</span>;
</code></pre></div><h3 id=use-socket-sharding>Use socket sharding</h3><p>In latest kernel and Nginx versions (at least 1.9.1) there is new feature of sockets sharding. This will offload management of new connections to kernel. Each worker will create a socket listener and kernel will assign new connections to them as they become available.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=color:#66d9ef>listen</span> <span style=color:#ae81ff>80</span> <span style=color:#e6db74>reuseport</span>;
</code></pre></div><h3 id=thread-pools>Thread pools</h3><p><a href=http://nginx.org/en/docs/http/ngx_http_core_module.html#aio>Thread pools</a> are solution for mostly long blocking IO operations that may block whole Nginx event queue (ex. when used with big files or slow storage).</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-nginx data-lang=nginx><span style=color:#66d9ef>location</span> <span style=color:#e6db74>/</span> {
    <span style=color:#f92672>root</span> <span style=color:#e6db74>/storage</span>;
    <span style=color:#f92672>aio</span> <span style=color:#e6db74>threads</span>;
}
</code></pre></div><p>This will help a lot if you see many Nginx processes in <strong>D</strong> state, with high IO wait times.</p><h2 id=tune-linux-for-performance>Tune Linux for performance</h2><h3 id=backlog-queue>Backlog queue</h3><p>If you could see on your system connection that appear to be staling then you have to increase <code>net.core.somaxconn</code>. This system parameter describes the maximum number of <code>backlogged sockets</code>. Default is 128 so setting this to 1024 should be no big deal on any decent machine.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>echo <span style=color:#e6db74>&#34;net.core.somaxconn=1024&#34;</span> &gt;&gt; /etc/sysctl.conf
sysctl -p /etc/sysctl.conf
</code></pre></div><h3 id=file-descriptors>File descriptors</h3><p>If your system is serving a lot of connections you may get reach system wide open descriptor limit. Nginx uses up to two descriptors for each connection. Then you have to increase <code>sys.fs.fs_max</code>.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>echo <span style=color:#e6db74>&#34;sys.fs.fs_max=3191256&#34;</span> &gt;&gt; /etc/sysctl.conf
sysctl -p /etc/sysctl.conf
</code></pre></div><h3 id=ephemeral-ports>Ephemeral ports</h3><p>Nginx used as a proxy creates temporary (ephemeral) ports for each upstream server. On busy proxy servers this will result in many connection in TIME_WAIT state.<br>Solution for that is to increase range of available ports by setting <code>net.ipv4.ip_local_port_range</code>. You may also benefit from lowering <code>net.ipv4.tcp_fin_timeout</code> setting (connection will be released faster, but be careful with that).</p><h2 id=use-reverse-proxy>Use reverse-proxy</h2><p>This with microcaching technic is worth separate article, I will add link here when it will be ready.</p><h5 id=source>Source:</h5><ul><li><a href=http://www.fromdual.com/huge-amount-of-time-wait-connections>http://www.fromdual.com/huge-amount-of-time-wait-connections</a></li><li><a href=https://www.nginx.com/blog/10-tips-for-10x-application-performance/>https://www.nginx.com/blog/10-tips-for-10x-application-performance/</a></li><li><a href=https://www.nginx.com/blog/socket-sharding-nginx-release-1-9-1/>https://www.nginx.com/blog/socket-sharding-nginx-release-1-9-1/</a></li><li><a href=https://www.nginx.com/blog/thread-pools-boost-performance-9x/>https://www.nginx.com/blog/thread-pools-boost-performance-9x/</a></li><li><a href=https://tweaked.io/guide/kernel/>https://tweaked.io/guide/kernel/</a></li><li><a href=https://t37.net/nginx-optimization-understanding-sendfile-tcp_nodelay-and-tcp_nopush.html>https://t37.net/nginx-optimization-understanding-sendfile-tcp_nodelay-and-tcp_nopush.html</a></li></ul></div><footer class=entry-footer><div class="container sep-before"><div class=categories><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M22 19a2 2 0 01-2 2H4a2 2 0 01-2-2V5A2 2 0 014 3H9l2 3h9a2 2 0 012 2z"/></svg><span class=screen-reader-text>Categories: </span><a class=category href=/categories/howto/>HOWTO</a></div><div class=tags><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M20.59 13.41l-7.17 7.17a2 2 0 01-2.83.0L2 12V2H12l8.59 8.59A2 2 0 0120.59 13.41z"/><line x1="7" y1="7" x2="7" y2="7"/></svg><span class=screen-reader-text>Tags: </span><a class=tag href=/tags/linux/>Linux</a>, <a class=tag href=/tags/nginx/>nginx</a></div></div></footer></article><nav class=entry-nav><div class=container><div class="prev-entry sep-before"><a href=/2016/01/xenserver-export-vm-to-file/><span aria-hidden=true><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><line x1="20" y1="12" x2="4" y2="12"/><polyline points="10 18 4 12 10 6"/></svg>Previous</span>
<span class=screen-reader-text>Previous post: </span>XenServer - export VM to file</a></div><div class="next-entry sep-before"><a href=/2016/02/zeitgeist-activity-sqlite-wal-getting-huge/><span class=screen-reader-text>Next post: </span>Zeitgeist activity.sqlite-wal getting huge<span aria-hidden=true>Next<svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><line x1="4" y1="12" x2="20" y2="12"/><polyline points="14 6 20 12 14 18"/></svg></span></a></div></div></nav></main><footer id=footer class=footer><div class="container sep-before"><section class="widget widget-social_menu sep-after"><nav aria-label="Social Menu"><ul><li><a href=https://github.com/tgagor target=_blank rel="noopener me"><span class=screen-reader-text>Open Github account in new tab</span><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77a5.44 5.44.0 00-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></li><li><a href=https://linkedin.com/in/tgagor target=_blank rel="noopener me"><span class=screen-reader-text>Open Linkedin account in new tab</span><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M16 8a6 6 0 016 6v7h-4v-7a2 2 0 00-2-2 2 2 0 00-2 2v7h-4v-7a6 6 0 016-6z"/><rect x="2" y="9" width="4" height="12"/><circle cx="4" cy="4" r="2"/></svg></a></li><li><a href=https://timor.site/index.xml target=_blank rel="noopener me"><span class=screen-reader-text>Open Rss account in new tab</span><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></li></ul></nav></section><div class=copyright><p>&copy; 2011-2021 TiMoR Licensed under <a rel=license href="https://creativecommons.org/licenses/by-sa/4.0?ref=chooser-v1" target=_blank rel="license noopener noreferrer" style=display:inline-block>CC BY-SA 4.0<img style=height:22px!important;margin-left:3px;vertical-align:text-bottom src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style=height:22px!important;margin-left:3px;vertical-align:text-bottom src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><img style=height:22px!important;margin-left:3px;vertical-align:text-bottom src="https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1"></a></p></div></div></footer></div></div><script>window.__assets_js_src="/assets/js/"</script><script src=/assets/js/main.c3bcf2df.js></script></body></html>
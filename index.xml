<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>timor&#39;s site</title>
    <link>https://timor.site/</link>
    <description>Recent content on timor&#39;s site</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>Content licensed under &lt;a rel=&#34;license noopener noreferrer&#34; target=&#34;_blank&#34; href=&#34;http://creativecommons.org/licenses/by-sa/4.0/&#34;&gt;(CC BY-SA 4.0)&lt;/a&gt;
</copyright>
    <lastBuildDate>Sun, 11 Sep 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://timor.site/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Best practices for writing Dockerfiles - Use .dockerignore</title>
      <link>https://timor.site/2022/09/best-practices-for-writing-dockerfiles-use-dockerignore/</link>
      <pubDate>Sun, 11 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2022/09/best-practices-for-writing-dockerfiles-use-dockerignore/</guid>
      <description>People often complain, that building Docker image takes a long time but they&amp;rsquo;re just adding single jar package. Really?
They often don&amp;rsquo;t remember that whole &amp;ldquo;build context&amp;rdquo;1 is uploaded to Docker daemon during build, which often means they&amp;rsquo;re not only adding &amp;ldquo;single jar&amp;rdquo;, but also all sources, test results and whatever you have in your context directory.
Solution is simple - use .dockerignore file2 dropped in the directory where you build the image.</description>
    </item>
    
    <item>
      <title>Best practices for writing Dockerfiles - Use VOLUME for all mutable, temporary file locations</title>
      <link>https://timor.site/2022/09/best-practices-for-writing-dockerfiles-use-volume-for-all-mutable-temporary-file-locations/</link>
      <pubDate>Sun, 11 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2022/09/best-practices-for-writing-dockerfiles-use-volume-for-all-mutable-temporary-file-locations/</guid>
      <description>IMO people don&amp;rsquo;t understand how VOLUME1 works so they don&amp;rsquo;t use it. It&amp;rsquo;s generally used far too rarely!
In short VOLUME means two things:
Whatever is left in directory marked as VOLUME, stays there and can&amp;rsquo;t be changed in later layers (actually it can be changed but changes won&amp;rsquo;t be persistent). Volumes are not part of layered image FS. They&amp;rsquo;re mounted as anonymous volumes located on standard file system. This means they&amp;rsquo;re working much faster.</description>
    </item>
    
    <item>
      <title>Dockerfile writing best practices</title>
      <link>https://timor.site/2022/09/dockerfile-writing-best-practices/</link>
      <pubDate>Sat, 10 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2022/09/dockerfile-writing-best-practices/</guid>
      <description>I&amp;rsquo;ve been thinking for a long time about writing set of articles on the topic of: &amp;ldquo;Dockerfile writing best practices&amp;rdquo;.
As it&amp;rsquo;s often my daily job to prepare best in class containers, that are later used by thousands of company&amp;rsquo;s applications, I have quite good insights on the topic. Some experience and knowledge gathered is often against intuition and building it took me a while. I want to share it, with a hope that feedback I get will allow me to excel on the topic even further.</description>
    </item>
    
    <item>
      <title>Ford S-MAX - kasowanie ostrzeżenia wymiany oleju</title>
      <link>https://timor.site/2022/09/ford-s-max-kasowanie-ostrzezenia-wymiany-oleju/</link>
      <pubDate>Sat, 03 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2022/09/ford-s-max-kasowanie-ostrzezenia-wymiany-oleju/</guid>
      <description>Auta się zmieniają a problemy z nimi pozostają te same :)
Kasowanie ostrzeżenia wymiany oleju 1 Przekręcić kluczyk w stacyjce do drugiej pozycji, gdy zapalają się wszystkie kontrolki (nie uruchamiamy silnika). Wciskamy równocześnie pedały hamulca i gazu do oporu, trzymamy do zakończenia procesu. Pojawi komunikat o rozpoczęciu resetowania inspekcji. Możemy zatwierdzić OK. Czekamy aż pojawi się komunikat: Zatwierdzamy OK. Dopiero teraz zwalniamy pedały. https://forum.fordclubpolska.org/showthread.php?t=108532&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>Back on the big stage!</title>
      <link>https://timor.site/2022/06/back-on-the-big-stage/</link>
      <pubDate>Mon, 13 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2022/06/back-on-the-big-stage/</guid>
      <description>I&amp;rsquo;m back on the big stage!
I haven&amp;rsquo;t attend any big conferences as presenter for some time, but this year will change it. I&amp;rsquo;m starting big, with a talk: Docker base images - Ideas how to manage them on scale on Devoxx conference in Kraków, that will take place on 22-24th June 2022.
Want to meet? Meet there 😄
Update I uploaded slides from presentation to my Github account.</description>
    </item>
    
    <item>
      <title>Creating fully encrypted ZFS pool</title>
      <link>https://timor.site/2021/11/creating-fully-encrypted-zfs-pool/</link>
      <pubDate>Mon, 22 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2021/11/creating-fully-encrypted-zfs-pool/</guid>
      <description>What I want to do? I use my pool to securely store backups, archive my old documents and keep huge family&amp;rsquo;s photo library.
I have new disks. They were tortured with badblocks, so they&amp;rsquo;re ready to create ZFS pool.
I&amp;rsquo;ve read few documents about different approaches 1 2 3. I wanted to be sure if anything changed during past years. One of articles recommends mirroring over RAIDZ. Resilvering is faster, at the same time putting IO less stress on whole pool.</description>
    </item>
    
    <item>
      <title>Shucking WD Elements 14TB</title>
      <link>https://timor.site/2021/11/shucking-wd-elements-14tb/</link>
      <pubDate>Fri, 12 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2021/11/shucking-wd-elements-14tb/</guid>
      <description>I used to have RAID (or at least some variation of it) for my main storage. For redundancy, in case of disk failure. I started with some crazy LVM mirrors done on two disks of different size. Sync job was starting on every boot 😄
Then came time for RAID5 on mdadm + LVM for volume management. It was working nice until the moment when disks became bigger. Long array rebuilds or checks, required my PC to stay turned on overnight just to validate if stuff works still.</description>
    </item>
    
    <item>
      <title>Automatically add ticket ID to every commit message in Git</title>
      <link>https://timor.site/2021/11/automatically-add-ticket-id-to-every-commit-message-in-git/</link>
      <pubDate>Tue, 09 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2021/11/automatically-add-ticket-id-to-every-commit-message-in-git/</guid>
      <description>I don&amp;rsquo;t know how it is in your company, but in mine it&amp;rsquo;s considered a good practice to add ticket numbers to commit messages. It allows to easily determine why something was changed, etc. Makes sense, but this also means, that I should be adding this ticket to every message&amp;hellip; And this doesn&amp;rsquo;t make sense for me. I will accidentally avoid it from time to time or make a lot of typos.</description>
    </item>
    
    <item>
      <title>Resize images from command line on MacOS</title>
      <link>https://timor.site/2021/11/resize-images-from-command-line-on-macos/</link>
      <pubDate>Sun, 07 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2021/11/resize-images-from-command-line-on-macos/</guid>
      <description>I was updating my blog and needed to generate few variants of images, in different resolution.
Option 1 - sips There&amp;rsquo;s simple, builtin tool sips, that can be used for simple resizing 1:
Resize single image sips -Z 36 orig.png --out static/favicon36x36.png -Z - maintain image aspect ratio 36 - maximum height and width It can be also used for batch image processing:
Warning
Beware, without &amp;ndash;out param, it will overwrite images in place!</description>
    </item>
    
    <item>
      <title>Homebrew - uninstall formula with dependencies</title>
      <link>https://timor.site/2021/11/homebrew-uninstall-formula-with-dependencies/</link>
      <pubDate>Fri, 05 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2021/11/homebrew-uninstall-formula-with-dependencies/</guid>
      <description>I use brew extensively on MacOS. It&amp;rsquo;s just as convenient as many Linux package managers. What I don&amp;rsquo;t like, it leaves dependencies after removal of formula. There&amp;rsquo;s simple way to clean it up by running one command 1.
Uninstall with dependencies brew uninstall FORMULA brew autoremove Info
In my case running brew autoremove actually removed few packages I really wanted to have. Check the output carefully!
https://stackoverflow.com/questions/7323261/uninstall-remove-a-homebrew-package-including-all-its-dependencies&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>Asus ROG STRIX Z590-E GAMING WIFI - my UEFI BIOS settings</title>
      <link>https://timor.site/2021/10/asus-rog-strix-z590-e-gaming-wifi-my-uefi-bios-settings/</link>
      <pubDate>Sat, 30 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2021/10/asus-rog-strix-z590-e-gaming-wifi-my-uefi-bios-settings/</guid>
      <description>I&amp;rsquo;ve build new PC - it&amp;rsquo;s based on Asus ROG STRIX Z590-E GAMING WIFI motherboard. Generally, I&amp;rsquo;m quite satisfied, but it have one irritating downside - after each UEFI BIOS upgrade, it&amp;rsquo;s silently resetting some of settings.
Let me note, what I want to have there:
Ai Tweaker (use my RAM capabilities) AI Overcloack Tuner -&amp;gt; [XMP I] DRAM Frequency -&amp;gt; [DDR4-3600MHz] DRAM CAS# Latency -&amp;gt; [16] DRAM RAS# to CAS# Delay -&amp;gt; [19] DRAM RAS# ACT Time -&amp;gt; [39] DRAM Voltage -&amp;gt; [1.</description>
    </item>
    
    <item>
      <title>Official CentOS 8 Stream Docker image finally available!</title>
      <link>https://timor.site/2021/07/official-centos-8-stream-docker-image-finally-available/</link>
      <pubDate>Sun, 25 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2021/07/official-centos-8-stream-docker-image-finally-available/</guid>
      <description>Finally, they&amp;rsquo;re available! Wait a moment.. Actually they&amp;rsquo;re available for few months, just nobody published information about moving them to quay.io and dropped poor guys using hub.docker.com without any updates! Yes, that how they did!
I found new place accidentally, reading some news about CentOS Stream 9 on their blog. There was reference to CentOS 9 Stream dev builds of Docker images and I found &amp;ldquo;missing&amp;rdquo; stream and stream8 tags too.</description>
    </item>
    
    <item>
      <title>My projects</title>
      <link>https://timor.site/projects/</link>
      <pubDate>Fri, 09 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/projects/</guid>
      <description>Github repositories tgagor/ansible-role-docker - Installs Docker service on Ubuntu/Debian/RHEL tgagor/ansible-role-docker-compose - Simple Ansible role that will install Docker Compose tgagor/ansible-role-spotify tgagor/ansible-role-template-with-molecule-tests - Template for Ansible role with Molecule and Testinfra for testing tgagor/conferences - Presentations and materials from conferences where I attended as a speaker tgagor/docker-centos - CentOS docker images, build weekly with latest security updates tgagor/docker-clamav - Simple Docker image that might be used in CI/CD tgagor/docker-grype - Docker image with anchore/grype tgagor/docker-jpegtran - Simple Docker image with jpegtran executable.</description>
    </item>
    
    <item>
      <title>How to remove geo-localization/EXIF data from photos</title>
      <link>https://timor.site/2021/03/how-to-remove-geo-localization/exif-data-from-photos/</link>
      <pubDate>Fri, 05 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2021/03/how-to-remove-geo-localization/exif-data-from-photos/</guid>
      <description>I wanted to share publicly some photos, but I performed them with navigation enabled so they contained accurate localisation of my house. I wanted to remove EXIF data GPS tags, my phone type and other irrelevant stuff.
TL;DR You will need imagemagick installed (use apt/yum/dnf of whatever you have there):
Install imagemagick sudo apt install -y imagemagick To remove them just use: Strip EXIF data mogrify -strip image.jpg How to check if it&amp;rsquo;s working?</description>
    </item>
    
    <item>
      <title>How to run JMX monitoring in Docker image?</title>
      <link>https://timor.site/2021/02/how-to-run-jmx-monitoring-in-docker-image/</link>
      <pubDate>Fri, 19 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2021/02/how-to-run-jmx-monitoring-in-docker-image/</guid>
      <description>It&amp;rsquo;s sometimes useful to quickly connect to JMX console, to checkout what&amp;rsquo;s going on in your application, but the whole thing get&amp;rsquo;s tricky if you&amp;rsquo;re running your app in a container. I need it from time to time and I keep myself few times searching for set of params below:
~/2021/02/how-to-run-jmx-monitoring-in-docker-image/ java \ ... -Dcom.sun.management.jmxremote \ -Dcom.sun.management.jmxremote.rmi.port=${PORT1} \ -Dcom.sun.management.jmxremote.port=${PORT1} \ -Dcom.sun.management.jmxremote.local.only=false \ -Dcom.sun.management.jmxremote.authenticate=false \ -Dcom.sun.management.jmxremote.ssl=false \ -Djava.rmi.server.hostname=${HOST} The whole magic here is that PORT1 in container is app&amp;rsquo;s second port.</description>
    </item>
    
    <item>
      <title>CentOS 8 Stream Docker image</title>
      <link>https://timor.site/2021/02/centos-8-stream-docker-image/</link>
      <pubDate>Thu, 11 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2021/02/centos-8-stream-docker-image/</guid>
      <description>We&amp;rsquo;re all divided with recent decision to focus on CentOS Stream, which essentially means that stable, professional distro will turn into rolling release now. Also CentOS board members don&amp;rsquo;t gave us more confidence for the future.
I don&amp;rsquo;t want to be totally sceptic, I would like to test it on my own and only then, decide if it&amp;rsquo;s stable enough. But I work mostly with Docker containers and there are no official Docker images with Stream variant.</description>
    </item>
    
    <item>
      <title>How old are Official Docker images?</title>
      <link>https://timor.site/2021/01/how-old-are-official-docker-images/</link>
      <pubDate>Thu, 28 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2021/01/how-old-are-official-docker-images/</guid>
      <description>TL;DR
CentOS base images sucks! They&amp;rsquo;re old, not updated for months!
As a professional DevOps I concern about a lot of things&amp;hellip; but security is always close to the top of the list. With Docker build environments and deployments became much more stable, which often is a result of just being stale ;/
I&amp;rsquo;ve been talking about this for long time but it&amp;rsquo;s still hard for people to believe it.</description>
    </item>
    
    <item>
      <title>Bye Bye Wordpress!</title>
      <link>https://timor.site/2020/10/bye-bye-wordpress/</link>
      <pubDate>Sat, 24 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2020/10/bye-bye-wordpress/</guid>
      <description>I started my blog on custom (written by my) engine, but as I didn&amp;rsquo;t had enough time to enhance it I switched to Wordpress. I&amp;rsquo;ve been using Wordpress as an engine of my blog for past 8~9 years. I have small VPS with PHP + Nginx and you can find a lot of configuration examples from my config on this site 😄
There was a time, when I was really satisfied by what it provides.</description>
    </item>
    
    <item>
      <title>Moving from Linux to MacOS – first steps</title>
      <link>https://timor.site/2020/01/moving-from-linux-to-macos-first-steps/</link>
      <pubDate>Sat, 04 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2020/01/moving-from-linux-to-macos-first-steps/</guid>
      <description>Few years ago I moved from Linux desktop to MacOS for my business, day to day work. There were 2 main reasons for that:
Corporations don&amp;rsquo;t like Linux - they can&amp;rsquo;t manage it, they can&amp;rsquo;t support it, so they blocked it with &amp;ldquo;Security policy&amp;rdquo;, ISO20001, or other nonsense. Actually they&amp;rsquo;re partially right but in different place - many business collaboration applications don&amp;rsquo;t work well on LInux (or they don&amp;rsquo;t work at all) Skype for Business - there&amp;rsquo;s open source alternative but to get full support you have to pay for additional codecs (as far as I remember) - it&amp;rsquo;s not working stable even in paid version Outlook and calendar support - I love Thunderbird and I use it for years, but calendar invitations didn&amp;rsquo;t work nice (honestly, they didn&amp;rsquo;t work nice even between different Outlook versions&amp;hellip;) Corporate VPN apps - Christ, I always was able to get it working eventually, but&amp;hellip; why bother I&amp;rsquo;m older, maybe lazier, maybe smarter - I don&amp;rsquo;t like to spend my time resolving problems that don&amp;rsquo;t give me any value.</description>
    </item>
    
    <item>
      <title>Debuging commands running on memcached</title>
      <link>https://timor.site/2016/07/debuging-commands-running-on-memcached/</link>
      <pubDate>Wed, 13 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2016/07/debuging-commands-running-on-memcached/</guid>
      <description>I had stragne statistics on one memcached servers. I had to look what it&amp;rsquo;s doing there. I found such commands that may be used to sniff, extract and make statistics from running memcached server.
Debug GET commands tcpflow -c dst port 11211 | cut -b46- | grep ^get cut command will remove 46 bytes at beginning of every string (src, dst, port). You may need to adjust numeric parameter for cut to leave commands only.</description>
    </item>
    
    <item>
      <title>How to stole ssh session when you’re root</title>
      <link>https://timor.site/2016/04/how-to-stole-ssh-session-when-youre-root/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2016/04/how-to-stole-ssh-session-when-youre-root/</guid>
      <description>It happen to me all the time that one of developers notifies me about some kind of problem that I can&amp;rsquo;t confirm from my account. Sometimes it was because of bad ssh keys configuration, other times file permissions, mostly such stuff. It&amp;rsquo;s sometimes convenient to &amp;ldquo;enter into someone&amp;rsquo;s shoes&amp;rdquo; to see what&amp;rsquo;s going on there.
If you&amp;rsquo;re root on machine you may do that like this:
su developer - Easy one but that&amp;rsquo;s not enough for all cases.</description>
    </item>
    
    <item>
      <title>pip - uninstall package with dependencies</title>
      <link>https://timor.site/2016/04/pip-uninstall-package-with-dependencies/</link>
      <pubDate>Tue, 26 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2016/04/pip-uninstall-package-with-dependencies/</guid>
      <description>Virtualenvs in python are cheap but from time to time you will install something with pip on your system and when time comes removing all this crap could be difficult. I found this bash snippet that will uninstall package with all dependencies:
for dep in $(pip show python-neutronclient | grep Requires | sed &amp;#39;s/Requires: //g; s/,//g&amp;#39;) ; do sudo pip uninstall -y $dep ; done pip uninstall -y python-neutronclient Source: http://stackoverflow.</description>
    </item>
    
    <item>
      <title>Daily MySQL backups with xtrabackup</title>
      <link>https://timor.site/2016/04/daily-mysql-backups-with-xtrabackup/</link>
      <pubDate>Sat, 23 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2016/04/daily-mysql-backups-with-xtrabackup/</guid>
      <description>I&amp;rsquo;ve been using standard MySQL dumps as backup technique on my VPS for few years. It works fine and backups were usable few times when I needed them. But in other places I&amp;rsquo;m using xtrabackup. It&amp;rsquo;s faster when crating backups and a lot faster when restoring them - they&amp;rsquo;re binary so there is no need to reevaluate all SQL create tables/inserts/etc. Backups also include my.cnf config file so restoring on other machine should be easy.</description>
    </item>
    
    <item>
      <title>Use bastion host with Ansible</title>
      <link>https://timor.site/2016/04/use-bastion-host-with-ansible/</link>
      <pubDate>Fri, 22 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2016/04/use-bastion-host-with-ansible/</guid>
      <description>When you deploy your application in cloud you don&amp;rsquo;t need and don&amp;rsquo;t want your hosts exposed via SSH to the world. Malware scans whole network for easy SSH access and when find something will try some brute force attacks, overloading such machines. It&amp;rsquo;s easier to have one exposed, but secured host, that doesn&amp;rsquo;t host anything and is used as proxy/gateway to access our infrastructure- it&amp;rsquo;s called bastion host.
Ansible is quite easy to integrate with bastion host configuration.</description>
    </item>
    
    <item>
      <title>Tweaking ASUS Zenbook UX305CA on Linux</title>
      <link>https://timor.site/2016/04/tweaking-asus-zenbook-ux305ca-on-linux/</link>
      <pubDate>Thu, 21 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2016/04/tweaking-asus-zenbook-ux305ca-on-linux/</guid>
      <description>Lately I was searching for mobile notebook that I could use for remote work. I checked f ThinkPad series but they were huge bricks that have nothing in common with &amp;lsquo;mobile&amp;rsquo; word. Then I saw ASUS Zenbook that I didn&amp;rsquo;t take into account before and it was exactly what I was searching for.
Configuration of Skylake based notebook right now is not straightforward - there are still glitches and small bugs that are waiting to be fixed.</description>
    </item>
    
    <item>
      <title>Prefer IPv4 over IPv6</title>
      <link>https://timor.site/2016/03/prefer-ipv4-over-ipv6/</link>
      <pubDate>Tue, 29 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2016/03/prefer-ipv4-over-ipv6/</guid>
      <description>I try to use IPv6 where it&amp;rsquo;s available but it&amp;rsquo;s sometimes so hard&amp;hellip; It happen quite often that I can&amp;rsquo;t download packages from repos because they weren&amp;rsquo;t configured on IPv6 vhosts even when host is available via IPv6 address. For APT you may use this trick to force IPv4 connections only:
echo &amp;#39;Acquire::ForceIPv4 &amp;#34;true&amp;#34;;&amp;#39; &amp;gt; /etc/apt/apt.conf.d/99force-ipv4 If you need more than that, then gai.conf will allow you to filter where you will be connecting via IPv4 and where via IPv6 - in example bellow you will prefer IPv4 whenever it&amp;rsquo;s available:</description>
    </item>
    
    <item>
      <title>List octal file permissions in bash</title>
      <link>https://timor.site/2016/02/list-octal-file-permissions-in-bash/</link>
      <pubDate>Wed, 24 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2016/02/list-octal-file-permissions-in-bash/</guid>
      <description>Sometimes it&amp;rsquo;s easier to use octal file permissions but they&amp;rsquo;re not so easy to list. I caught myself few times that I didn&amp;rsquo;t remember how to list them - so this is a reason for that note.
stat -c &amp;#34;%a %n&amp;#34; * 755 bin 755 games 755 include Yes, it&amp;rsquo;s that easy 😃
And here also with human readable attributes:
stat -c &amp;#39;%A %a %n&amp;#39; * drwxr-xr-x 755 bin drwxr-xr-x 755 games drwxr-xr-x 755 include </description>
    </item>
    
    <item>
      <title>WordPress with HyperDB on PHP 7.0</title>
      <link>https://timor.site/2016/02/wordpress-with-hyperdb-on-php-7-0/</link>
      <pubDate>Wed, 24 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2016/02/wordpress-with-hyperdb-on-php-7-0/</guid>
      <description>I was configuring WordPress with HyperDB plugin on PHP 7.0 but the only I get were constant 500 errors. As I found here PHP 7.0 is not supported by HyperDB for now - it&amp;rsquo;s rely on mysql php extension but in PHP 7.0 there is only mysqli extension. But few folks fixed it and it&amp;rsquo;s possible to use it.
curl -O https://raw.githubusercontent.com/soulseekah/hyperdb-mysqli/master/db.php mv db.php /var/www/wordpress/wp-content/ And configure it ex. like this:</description>
    </item>
    
    <item>
      <title>Automatically build after file change</title>
      <link>https://timor.site/2016/02/automatically-build-after-file-change/</link>
      <pubDate>Tue, 23 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2016/02/automatically-build-after-file-change/</guid>
      <description>I&amp;rsquo;m playing a lot with Docker lately. Building images, and then rebuilding, and then building again&amp;hellip; It&amp;rsquo;s pretty boring. To automate this task a little I used inotify to build automatically after I changed any file. This trick could be used in many different situations.
You will need inotify-tools package:
sudo apt-get install -y inotify-tools Then run something like this:
while inotifywait -e modify -r .; do docker-compose build; done This commands will rebuild my Docker images after any file change in current directory.</description>
    </item>
    
    <item>
      <title>Install WordPress from command-line</title>
      <link>https://timor.site/2016/02/install-wordpress-from-command-line/</link>
      <pubDate>Mon, 15 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2016/02/install-wordpress-from-command-line/</guid>
      <description>I never tried it before but today I needed to install WordPress&amp;hellip; From command line only. And there is a way to do this with wp-cli.
WP-CLI installation First some requirements (as root):
apt-get install php5-cli php5-mysql mysql-client curl And now installation of wp-cli (as root too):
curl -O https://raw.githubusercontent.com/wp-cli/builds/gh-pages/phar/wp-cli.phar chmod +x wp-cli.phar mv wp-cli.phar /usr/local/bin/wp Check if it&amp;rsquo;s working:
$ wp --version WP-CLI 0.22.0 WordPress installation Now you should switch to user of your web application, ex.</description>
    </item>
    
    <item>
      <title>Install Docker Compose</title>
      <link>https://timor.site/2016/02/install-docker-compose/</link>
      <pubDate>Fri, 12 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2016/02/install-docker-compose/</guid>
      <description>When I started playing with Docker I was running a lot of commands to build image, delete containers running on old image, run containers based on new image, etc&amp;hellip; A lot of log commands with links, volumes, etc&amp;hellip;
Then I started searching for something to automate this task and here I get to docker-compse command, this is how you may install it:
pip install docker-compose And install additional bash completions (run as root):</description>
    </item>
    
    <item>
      <title>Manual installation of Docker on Debian/Ubuntu</title>
      <link>https://timor.site/2016/02/manual-installation-of-docker-on-debian-ubuntu/</link>
      <pubDate>Thu, 11 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2016/02/manual-installation-of-docker-on-debian-ubuntu/</guid>
      <description>I&amp;rsquo;ve played with Docker a little in it early days but didn&amp;rsquo;t stick for longer with it. It&amp;rsquo;s stable now so I wanted to check how it&amp;rsquo;s running now.
I really can&amp;rsquo;t accept this method of installation:
curl -fsSL https://get.docker.com/ | sh I think that world is going to it&amp;rsquo;s end when I see such scritps&amp;hellip; I prefer to do this manually, knowing exactly what I have to do.
Install prerequisites:</description>
    </item>
    
    <item>
      <title>Some useful commands in Docker</title>
      <link>https://timor.site/2016/02/some-useful-commands-in-docker/</link>
      <pubDate>Thu, 11 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2016/02/some-useful-commands-in-docker/</guid>
      <description>I started playing with Docker and here I will write some commands that where not so obvious at beginning 😃
List running containers:
docker ps List also not running containers:
docker ps -a Remove all containers (be careful with that):
docker rm $(docker ps -a -q) Remove all images:
docker rmi $(docker images -q) Docker won&amp;rsquo;t remove any old volumes used by containers, so after some time you may be interested in deleting them all:</description>
    </item>
    
    <item>
      <title>Mass replace in WordPress posts via MySQL query</title>
      <link>https://timor.site/2016/02/mass-replace-in-wordpress-posts-via-mysql-query/</link>
      <pubDate>Tue, 09 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2016/02/mass-replace-in-wordpress-posts-via-mysql-query/</guid>
      <description>&lt;p&gt;I was doing a lot of changes to my old posts, switched to HTTPS, etc. Sometimes it was useful to change some particular text in all my old posts at a time, but there is no such feature in WordPress. But WordPress runs on MySQL and I could use SQL query to update such posts.&lt;/p&gt;
&lt;p&gt;Make backup - it&amp;rsquo;s not required but strongly advised 😃&lt;/p&gt;
&lt;p&gt;Now use this query as template to replace in place whatever you need:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;</description>
    </item>
    
    <item>
      <title>Use www.horizon.tv with Pipelight/Silverlight on Linux/Ubuntu</title>
      <link>https://timor.site/2016/02/use-www-horizon-tv-with-pipelight-silverlight-on-linux-ubuntu/</link>
      <pubDate>Tue, 09 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2016/02/use-www-horizon-tv-with-pipelight-silverlight-on-linux-ubuntu/</guid>
      <description>From few days I have access to UPC&amp;rsquo;s www.horizon.tv platform - until now it was useless on Linux. But there is Pipelight that will use Wine to emulate Silverlight on Linux and it&amp;rsquo;s working pretty well - you&amp;rsquo;re just few commands away from achieving that:
# stop browser killall firefox # remove old version if you have it sudo apt-get remove pipelight Now configure repos and install packages:
sudo apt-add-repository ppa:pipelight/stable sudo apt-get update sudo apt-get install --install-recommends pipelight-multi sudo pipelight-plugin --update Enable plugin (run it with sudo for system wide installation):</description>
    </item>
    
    <item>
      <title>Intel Dual Band Wireless-AC 7260 for Desktop on Linux</title>
      <link>https://timor.site/2016/02/intel-dual-band-wireless-ac-7260-for-desktop-on-linux/</link>
      <pubDate>Sat, 06 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2016/02/intel-dual-band-wireless-ac-7260-for-desktop-on-linux/</guid>
      <description>I just bought new wifi card for my desktop computer. Like in topic, it&amp;rsquo;s Intel Dual Band Wireless-AC 7260 for Desktop.
I was searching for card that:
support AC standard have 5GHz network support (2,4GHz channels are cluttered heavily in my neighborhood have PCI/PCIx or USB3 connector is Linux friendly (no modules compilation by hand, support for aircrack-ng, kismet) This one is the only I found that comply my expectations.</description>
    </item>
    
    <item>
      <title>Prepare for DoS like Cloudflare do</title>
      <link>https://timor.site/2016/02/prepare-for-dos-like-cloudflare-do/</link>
      <pubDate>Fri, 05 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2016/02/prepare-for-dos-like-cloudflare-do/</guid>
      <description>I watched nice presentation about how Cloudflare protects itself against DoS. Most of us are not able to do that exactly like them but some of tips were general enough to be used on typical web front server.
I took notes from this presentation and presented here. Thanks to Marek agreement I also reposted all examples (in easier to copy paste way).
Howto prepare against ACK/FIN/RST/X-mas flood Use conntrack rule:</description>
    </item>
    
    <item>
      <title>Zeitgeist activity.sqlite-wal getting huge</title>
      <link>https://timor.site/2016/02/zeitgeist-activity-sqlite-wal-getting-huge/</link>
      <pubDate>Thu, 04 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2016/02/zeitgeist-activity-sqlite-wal-getting-huge/</guid>
      <description>I was looking at backup task running on my desk and saw that it&amp;rsquo;s spending a lot of time on ~/.local/share/zeitgeist directory. I checked and it had 4.6GB:
du -sh ~/.local/share/zeitgeist/* 118M activity.sqlite 44M activity.sqlite.bck 32K activity.sqlite-shm 4,4G activity.sqlite-wal 311M fts.index WTF? Fortunately I found here that I could easily delete some of this:
zeitgeist-daemon --quit Now check that it&amp;rsquo;s not running:
ps axu | grep zeitgeist-daemon timor 9105 0.0 0.</description>
    </item>
    
    <item>
      <title>Optimize Nginx for performance</title>
      <link>https://timor.site/2016/01/optimize-nginx-for-performance/</link>
      <pubDate>Thu, 14 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2016/01/optimize-nginx-for-performance/</guid>
      <description>There are many possible real life cases and not all optimization technics will be suitable for you but I hope it will be a good starting place.
Also you shouldn&amp;rsquo;t copy paste examples with faith that they will make your server fly 😃 You have to support your decisions with excessive tests and help of monitoring system (ex. Grafana).
Cache static and dynamic content Setting caching static and dynamic content strategy may offload your server from additional load from repetitive downloads of same, rarely updated files.</description>
    </item>
    
    <item>
      <title>XenServer - export VM to file</title>
      <link>https://timor.site/2016/01/xenserver-export-vm-to-file/</link>
      <pubDate>Tue, 12 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2016/01/xenserver-export-vm-to-file/</guid>
      <description>Sometime you need to make quick and dirty image backup of VM running on XenServer and this post is about such case 😃
List machines:
xl list Name ID Mem VCPUs State Time(s) Domain-0 0 4066 8 r----- 3526567.3 webfront1.example.com 1 4096 4 r----- 3186487.2 webfront2.example.com 2 2048 2 -b---- 920408.2 Now you may export one:
xe vm-export vm=webfront1.example.com filename=/srv/backup/webfront.xva Export succeeded You may also use uuid for that - list machines with xe vm-list (best with less) and then:</description>
    </item>
    
    <item>
      <title>Nagios - downtime on host/service from command line with curl</title>
      <link>https://timor.site/2016/01/nagios-downtime-on-hostservice-from-command-line-with-curl/</link>
      <pubDate>Mon, 11 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2016/01/nagios-downtime-on-hostservice-from-command-line-with-curl/</guid>
      <description>Sometimes deployment process or other havy task may cause some Nagios checks to rise below normal levels and bother admin. If this is expected and you want to add downtime on host/service during this task you may use this script:
#!/bin/bash function die { echo $1; exit 1; } if [[ $# -eq 0 ]] ; then die &amp;#34;Give hostname and time in minutes as parameter!&amp;#34; fi if [[ $# -eq 1 ]] ; then MINUTES=15 else MINUTES=$2 fi HOST=$1 NAGURL=http://nagios.</description>
    </item>
    
    <item>
      <title>Grafana - installation and configuraton with InfluxDB and CollectD on Debian/Ubuntu</title>
      <link>https://timor.site/2016/01/grafana-installation-and-configuraton-with-influxdb-and-collectd-on-debian-ubuntu/</link>
      <pubDate>Sun, 10 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2016/01/grafana-installation-and-configuraton-with-influxdb-and-collectd-on-debian-ubuntu/</guid>
      <description>Now when you have CollectD and InfluxDB installed you may configure Grafana 😃
First configure repo with current Grafana version (select your distro):
curl https://packagecloud.io/gpg.key | sudo apt-key add - deb https://packagecloud.io/grafana/testing/debian/ wheezy main Now install package (on wheezy I needed to install apt-transport-https to allow installation of packages from repo via HTTPS):
apt-get update apt-get install -y apt-transport-https apt-get install -y grafana By default Grafana will use sqlite database to keep information about users, etc:</description>
    </item>
    
    <item>
      <title>InfluxDB - installation and configuration on Debian/Ubuntu</title>
      <link>https://timor.site/2016/01/influxdb-installation-and-configuration-on-debianubuntu/</link>
      <pubDate>Sat, 09 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2016/01/influxdb-installation-and-configuration-on-debianubuntu/</guid>
      <description>I wanted/needed some statistics on few my machines. I saw earlier grafana and was impressed so this was starting point. Then I started reading about graphite, carbon and whisper, and then… I found InfluxDB. Project is young but looks promising.
Let&amp;rsquo;s start! On project page there is no info about repo but it&amp;rsquo;s available, configure it:
curl -sL https://repos.influxdata.com/influxdb.key | apt-key add - echo &amp;#34;deb https://repos.influxdata.com/debian wheezy stable&amp;#34; &amp;gt; /etc/apt.sources.list.d/influxdb.conf for Ubuntu use url like (of course selecting your version):</description>
    </item>
    
    <item>
      <title>CollectD - installation and configuration with InfluxDB on Debian/Ubuntu</title>
      <link>https://timor.site/2016/01/collectd-installation-and-configuration-with-influxdb-on-debianubuntu/</link>
      <pubDate>Fri, 08 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2016/01/collectd-installation-and-configuration-with-influxdb-on-debianubuntu/</guid>
      <description>I wanted/needed some statistics on few my machines. I saw earlier grafana and was impressed so this was starting point. Then I started reading about graphite, carbon and whisper, and then… I found InfluxDB. Project is young but looks promising.
Installation of collectd is easy on Debian because packages are in default repo. One problem is that packages may be old, ex. on wheezy it version 5.1. But in backports/backports-sloppy you may find current 5.</description>
    </item>
    
    <item>
      <title>Let’s Encrypt - without auto configuration</title>
      <link>https://timor.site/2016/01/lets-encrypt-without-auto-configuration/</link>
      <pubDate>Mon, 04 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2016/01/lets-encrypt-without-auto-configuration/</guid>
      <description>From the first moment I heard about Let&amp;rsquo;s Encrypt I liked it and wanted to use it as fast as possible. But the more I read how they want to implement it, the more I dislike it.
Current project with automatic configuration is not what I want to use at all. I have many very complicated configs and I do not trust such tools enough to use them. I like UNIX&amp;rsquo;s single purpose principle, tools should do one thing and do it well - nothing more.</description>
    </item>
    
    <item>
      <title>fail2ban - block wp-login.php brute force attacks</title>
      <link>https://timor.site/2015/12/fail2ban-block-wp-login-php-brute-force-attacks/</link>
      <pubDate>Thu, 31 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2015/12/fail2ban-block-wp-login-php-brute-force-attacks/</guid>
      <description>Lately I had a lot of brute force attacks on my WordPress blog. I used basic auth to /wp-admin part in nginx configuration to block this and as a better solution I wan&amp;rsquo;t to block source IPs at all on firewall.
To do this, place this filter code in /etc/fail2ban/filter.d/wp-login.conf:
# WordPress brute force wp-login.php filter: # # Block IPs trying to authenticate in WordPress blog # # Matches e.g. # 178.</description>
    </item>
    
    <item>
      <title>Ansible on Vagrant - skipping: no hosts matched</title>
      <link>https://timor.site/2015/12/ansible-on-vagrant-skipping-no-hosts-matched/</link>
      <pubDate>Tue, 29 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2015/12/ansible-on-vagrant-skipping-no-hosts-matched/</guid>
      <description>I have some Ansible roles to configure my vps, Raspberry Pi, etc. I like to test them before I broke something on my real, not clustered machines - I use Vagrant for that.
But with it I had one problem - in playbooks I define hosts as groups of severs ex. web for my vps:
Example Ansible playbook - hosts: web gather_facts: True sudo: True ... But testing machine wasn&amp;rsquo;t in this group and when I run vagrant I could only see:</description>
    </item>
    
    <item>
      <title>Apache - Force caching dynamic PHP content with mod_headers</title>
      <link>https://timor.site/2015/12/apache-force-caching-dynamic-php-content-with-mod_headers/</link>
      <pubDate>Tue, 29 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2015/12/apache-force-caching-dynamic-php-content-with-mod_headers/</guid>
      <description>Normally you want dynamic content to be fresh and not catchable. But sometimes it may be useful to cache it, like when you have website behind reverse proxy. To do this try something like this:
&amp;lt;filesmatch &amp;#34;\.(php|cgi|pl)$&amp;#34;&amp;gt; Header unset Pragma Header unset Expires Header set Cache-Control &amp;#34;max-age=3600, public&amp;#34; &amp;lt;/filesmatch&amp;gt; Sources http://www.askapache.com/htaccess/speed-up-your-site-with-caching-and-cache-control.html</description>
    </item>
    
    <item>
      <title>MySQL - reset root password</title>
      <link>https://timor.site/2015/12/mysql-reset-root-password/</link>
      <pubDate>Mon, 28 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2015/12/mysql-reset-root-password/</guid>
      <description>It will happen from time to time, that you&amp;rsquo;re on alien machine and have to brutally update things in db without knowing credentials. Example is for root (quite secure candidate to change because it shouldn&amp;rsquo;t be used in app 😃 ) but will work for any user.
shutdown db service mysql stop create text file with command like this (update user accordingly) ex. in /tmp/pwchange.txt SET PASSWORD FOR &amp;#34;root&amp;#34;@&amp;#34;localhost&amp;#34; = PASSWORD(&amp;#34;HereYourNewPassword&amp;#34;); start mysqld with --init-file param mysqld_safe --init-file=/tmp/pwchange.</description>
    </item>
    
    <item>
      <title>Rotate movies</title>
      <link>https://timor.site/2015/12/rotate-movies/</link>
      <pubDate>Mon, 28 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2015/12/rotate-movies/</guid>
      <description>I hate movies recorded on phone in vertical position. This just short tip how I dealt with with it last time:
for m in *.mp4 do avconv -i $m -vf &amp;#34;transpose=1&amp;#34; -codec:a copy -codec:v libx264 -preset slow -crf 23 rotated-$m done Other examples:
http://stackoverflow.com/questions/3937387/rotating-videos-with-ffmpeg
http://superuser.com/questions/578321/how-to-flip-a-video-180°-vertical-upside-down-with-ffmpeg</description>
    </item>
    
    <item>
      <title>Extract password saved in remmina</title>
      <link>https://timor.site/2015/12/extract-password-saved-in-remmina/</link>
      <pubDate>Fri, 25 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2015/12/extract-password-saved-in-remmina/</guid>
      <description>I had some passwords saved in remmina but like it always happen, I wasn&amp;rsquo;t been able to remember them when needed. Trying to restore them I found that they&amp;rsquo;re encrypted in .remmina directory.
Then I used this script to the decrypt them 1:
Extract script import base64 from Crypto.Cipher import DES3 secret = base64.decodestring(&amp;#34;&amp;lt;STRING FROM remmina.prefs&amp;gt;&amp;#34;) password = base64.decodestring(&amp;#34;&amp;lt;STRING FROM XXXXXXX.remmina&amp;gt;&amp;#34;) print DES3.new(secret[:24], DES3.MODE_CBC, secret[24:]).decrypt(password) http://askubuntu.com/questions/290824/how-to-extract-saved-password-from-remmina&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>I’m back</title>
      <link>https://timor.site/2015/12/im-back/</link>
      <pubDate>Fri, 25 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2015/12/im-back/</guid>
      <description>After long break I&amp;rsquo;m thinking about writing more on my blog. I was reviewing my favorites/bookmarks and half of them was broken, so I can&amp;rsquo;t rely on them in case of knowledge management.
I think I will write shorter, less descriptive articles just to be pointers to useful solutions from past.</description>
    </item>
    
    <item>
      <title>Apache AuthBasic but excluding IP</title>
      <link>https://timor.site/2015/12/apache-authbasic-but-excluding-ip/</link>
      <pubDate>Wed, 23 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2015/12/apache-authbasic-but-excluding-ip/</guid>
      <description>Allow from IP without password prompt, and also allow from any address with password prompt
Order deny,allow Deny from all AuthName &amp;#34;htaccess password prompt&amp;#34; AuthUserFile /web/askapache.com/.htpasswd AuthType Basic Require valid-user Allow from 172.17.10.1 Satisfy Any Sources http://www.askapache.com/htaccess/apache-authentication-in-htaccess.html</description>
    </item>
    
    <item>
      <title>Copy GTP partiotion table between disks</title>
      <link>https://timor.site/2014/07/copy-gtp-partiotion-table-between-disks/</link>
      <pubDate>Mon, 28 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2014/07/copy-gtp-partiotion-table-between-disks/</guid>
      <description>When configuring RAID it&amp;rsquo;s quite important to have the same partition tables on every disk. I&amp;rsquo;v done this many times on msdos partition tables like this:
sfdisk -d /dev/sda | sfdisk /dev/sdb but it&amp;rsquo;s not working any more on GPT partition tables. Hopefully it still can be done but with different toolstack 😄
Install gdisk:
apt-get install -y gdisk Then use sgdisk like this:
sgdisk -R /dev/sd_dest /dev/sd_src sgdisk -G /dev/sd_dest First command will copy partition from /dev/sd_src to /dev/sd_dest.</description>
    </item>
    
    <item>
      <title>Quickly setup SQL query logging on console in Django</title>
      <link>https://timor.site/2014/05/quickly-setup-sql-query-logging-on-console-in-django/</link>
      <pubDate>Wed, 28 May 2014 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2014/05/quickly-setup-sql-query-logging-on-console-in-django/</guid>
      <description>There is need plugin for Django, named django-debug-toolbar but it needs some time to configure. So when I need simple way to debug SQL queries I use small hack. Add to your settings.py:
LOGGING = { &amp;#39;version&amp;#39;: 1, &amp;#39;disable_existing_loggers&amp;#39;: False, &amp;#39;handlers&amp;#39;: { &amp;#39;console&amp;#39;: { &amp;#39;level&amp;#39;: &amp;#39;DEBUG&amp;#39;, &amp;#39;class&amp;#39;: &amp;#39;logging.StreamHandler&amp;#39;, } }, &amp;#39;loggers&amp;#39;: { &amp;#39;django.db.backends&amp;#39;: { &amp;#39;handlers&amp;#39;: [&amp;#39;console&amp;#39;], &amp;#39;level&amp;#39;: &amp;#39;DEBUG&amp;#39;, }, } } To get this working DEBUG option have to be set to True:</description>
    </item>
    
    <item>
      <title>Changing default php.ini file for PHP-CLI on CentOS</title>
      <link>https://timor.site/2014/05/changing-default-php-ini-file-for-php-cli-on-centos/</link>
      <pubDate>Thu, 08 May 2014 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2014/05/changing-default-php-ini-file-for-php-cli-on-centos/</guid>
      <description>On Debian in default installation you have different configuration files for PHP in Apache, FPM, CLI, etc. But on CentOS you have only one php.ini for all of them. In case I have, I need to have different configuration file for scripts running in CLI mode (more memory, etc). I could run it like this:
php -c /etc/php-cli.ini script.php But this a little burdensome. So I do it like this:</description>
    </item>
    
    <item>
      <title>Command to change root password</title>
      <link>https://timor.site/2014/05/command-to-change-root-password/</link>
      <pubDate>Thu, 08 May 2014 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2014/05/command-to-change-root-password/</guid>
      <description>Everybody knows passwd command but it&amp;rsquo;s useless when you need to change ex. root password from command line without waiting for input. In such case oneliner below could help:
echo &amp;#34;root:new_password&amp;#34; | chpasswd </description>
    </item>
    
    <item>
      <title>Install Steam on Debian/Ubuntu</title>
      <link>https://timor.site/2014/04/install-steam-on-debian-ubuntu/</link>
      <pubDate>Tue, 22 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2014/04/install-steam-on-debian-ubuntu/</guid>
      <description>These are few steps to get Steam running on Ubuntu:
wget -c media.steampowered.com/client/installer/steam.deb dpkg -i steam.deb apt-get install -f apt-get update Solutions for some issues Some time ago I needed 32 bit flash even on 64 bit system - I don&amp;rsquo;t need it currently but I&amp;rsquo;m living this as a tip.
apt-get install adobe-flashplugin:i386 After Ubuntu upgrade I was unable to run Steam anymore - It shouted on me with strange &amp;ldquo;networking problem&amp;rdquo;.</description>
    </item>
    
    <item>
      <title>Rebuild yum/rpm database</title>
      <link>https://timor.site/2014/04/rebuild-yum-rpm-database/</link>
      <pubDate>Fri, 04 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2014/04/rebuild-yum-rpm-database/</guid>
      <description>When I was trying to update packages on one host I&amp;rsquo;ve stuck with yum hung on update. I run strace and see:
strace -p 43734 Process 43734 attached - interrupt to quit futex(0x807c938, FUTEX_WAIT, 1, NULL &amp;lt;unfinished ...&amp;gt; Process 43734 detached It looks like yum database was corrupted, to repair this run:
rm -f /var/lib/rpm/__db* rpm --rebuilddb yum clean all yum update Instead rm on db-files you could use gzip to have backup of these files.</description>
    </item>
    
    <item>
      <title>Nagios - run checks as root with NRPE</title>
      <link>https://timor.site/2014/03/nagios-run-checks-as-root-with-nrpe/</link>
      <pubDate>Sat, 29 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2014/03/nagios-run-checks-as-root-with-nrpe/</guid>
      <description>I&amp;rsquo;ve few Nagios checks that require root privileges but running nrpe as root user is not acceptable. I prefer to use sudo for only these few commands.
Run visudo and coment out this line:
#Defaults requiretty This change is crucial to get scripts working.
Then add at the end of file:
%nrpe ALL=(ALL) NOPASSWD: /usr/lib64/nagios/plugins/ I&amp;rsquo;ve used nrpe group, but you have to add exactly group that your nrpe process uses.</description>
    </item>
    
    <item>
      <title>WordPress - add meta tags: author, description, keywords, etc</title>
      <link>https://timor.site/2014/03/wordpress-add-meta-tags-author-description-keywords-etc/</link>
      <pubDate>Thu, 27 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2014/03/wordpress-add-meta-tags-author-description-keywords-etc/</guid>
      <description>After reading some SEO stuff I wanted to add some meta tags to my WordPress blog. I found this site: codex.wordpress.org/Meta_Tags_in_WordPress.
So WordPress thinks that it&amp;rsquo;s not necessary to have this meta tags any more&amp;hellip; But I want it! 😃 Next funny thing is how they suggest to add meta tags: copy header.php - what about theme updates?
I prefer to use functions.php file - just create it in your courrent theme directory with such content:</description>
    </item>
    
    <item>
      <title>Mediawiki - recover admin rights</title>
      <link>https://timor.site/2014/03/mediawiki-recover-admin-rights/</link>
      <pubDate>Tue, 25 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2014/03/mediawiki-recover-admin-rights/</guid>
      <description>Let say you have MediaWiki installation but you lost admin credentials. If you have other account or if you could create one without any rights we&amp;rsquo;re in home 😉
We have few options to do this.
Reset admin password We have to connect to database and use this SQL:
UPDATE `user` SET user_password = CONCAT( SUBSTRING(user_password, 1, 3), SUBSTRING(MD5(user_name), 1, 8), &amp;#39;:&amp;#39;, MD5(CONCAT(SUBSTRING(MD5(user_name), 1, 8), &amp;#39;-&amp;#39;, MD5(&amp;#39;new password&amp;#39;)))) WHERE user_name = &amp;#39;Admin&amp;#39;; Just replace Admin with your username and new password with your password.</description>
    </item>
    
    <item>
      <title>Checking memcached status</title>
      <link>https://timor.site/2014/03/checking-memcached-status/</link>
      <pubDate>Fri, 21 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2014/03/checking-memcached-status/</guid>
      <description>I need to check memory usage of memcached server so I used:
echo stats | nc 127.0.0.1 11211 STAT pid 2743 STAT uptime 263 STAT time 1395438951 STAT version 1.4.13 STAT pointer_size 64 STAT rusage_user 0.482926 STAT rusage_system 2.675593 STAT curr_items 8667 STAT total_items 10742 STAT bytes 23802513 STAT curr_connections 296 STAT total_connections 399 STAT connection_structures 297 STAT cmd_flush 0 STAT cmd_get 52578 STAT cmd_set 10792 STAT get_hits 28692 STAT get_misses 23886 STAT evictions 0 STAT bytes_read 35984361 STAT bytes_written 192647437 STAT limit_maxbytes 536870912 STAT threads 2 STAT accepting_conns 1 STAT listen_disabled_num 0 STAT replication MASTER STAT repcached_qi_free 8189 STAT repcached_wdata 0 STAT repcached_wsize 1026048 END For me, bytes value was important but you could find more about all statistics here.</description>
    </item>
    
    <item>
      <title>Postfix - automatically drop outbound mail</title>
      <link>https://timor.site/2014/03/postfix-automatically-drop-outbound-mail/</link>
      <pubDate>Tue, 18 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2014/03/postfix-automatically-drop-outbound-mail/</guid>
      <description>I have development server with postfix - I wanted to allow outbound traffic to one domain but cut off all the rest. I definitely do not want that test mail or any debug info goes to service users.
I have to add something like that to /etc/postfix/transport:
allowed.domain.com : * discard: Then run:
postmap /etc/postfix/transport At end, add these to /etc/postfix/main.cf:
transport_maps = hash:/etc/postfix/transport Reload postfix:
postfix reload Test if it works:</description>
    </item>
    
    <item>
      <title>Ansible - ssh pipelining</title>
      <link>https://timor.site/2014/03/ansible-ssh-pipelining/</link>
      <pubDate>Tue, 04 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2014/03/ansible-ssh-pipelining/</guid>
      <description>In recent Ansible update to 1.5 version there is really nice feature ssh pipelining. This option is serious alternative to accelerated mode.
Just add to you config file (ex. ~/.ansible.cfg):
[ssh_connection] pipelining=True Now run any playbook - you will see the difference 😄
Source (and extended info about):
http://blog.ansibleworks.com/2014/01/15/ssh-connection-upgrades-coming-in-ansible-1-5/</description>
    </item>
    
    <item>
      <title>Chrusty, faworki</title>
      <link>https://timor.site/2014/02/chrusty-faworki/</link>
      <pubDate>Wed, 26 Feb 2014 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2014/02/chrusty-faworki/</guid>
      <description>To najlepszy przepis na chrusty jaki znam - wychodzą bardzo kruche i delikatne.
Składniki 4 zółtka, 4 łyżki wina białego lub czerwonego, 4 łyżki mąki. Sposób przygotowania Wszystkie składniki wymieszać i wyrobić. Ciasto powinno być mniej wiecej takie jak na pierogi. Bić pałką/wałkiem, składać na pół i tak kilka razy przez ok 5 minut. Potem ciasto rozwałkować bardzo cieniutko i wykrawać chrusty, małe bo mocno rosną. Następnie wrzucać na rozgrzany olej/smalec.</description>
    </item>
    
    <item>
      <title>Comparing two lists in bash</title>
      <link>https://timor.site/2014/02/comparing-two-lists-in-bash/</link>
      <pubDate>Tue, 18 Feb 2014 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2014/02/comparing-two-lists-in-bash/</guid>
      <description>I had quite simple task - compare two lists of hosts and check if hosts from first one are also on the second one. I started with diff:
diff -u biglist.txt hosts_to_check.txt | grep -E &amp;#34;^\+&amp;#34; It was fine but output needs some filtering to get what I want.
I&amp;rsquo;ve found another example with grep:
grep -Fxv -f biglist.txt hosts_to_check.txt | sort -n This will search for all lines in hosts_to_check.</description>
    </item>
    
    <item>
      <title>Change default WSUS port from 8530 to 80 on Windows Server 2012</title>
      <link>https://timor.site/2014/01/change-default-wsus-port-from-8530-to-80-on-windows-server-2012/</link>
      <pubDate>Fri, 24 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2014/01/change-default-wsus-port-from-8530-to-80-on-windows-server-2012/</guid>
      <description>After WSUS installing on Windows Server 2012 I discovered that it&amp;rsquo;s running on port 8530, different than on older version of Windows (it was using port 80 from beginning). But what&amp;rsquo;s more interesting it was running ONLY on IPv6 interface! Switching binding configuration in IIS doesn&amp;rsquo;t help.
I could stand switching port - it&amp;rsquo;s nothing hard with GPO, but IPv6 only configuration was not acceptable.
After googling for some time I found one command that solved my problems by switching WSUS to older behavior and run it on port 80 (on default website).</description>
    </item>
    
    <item>
      <title>Debian - Upgrade MySQL to MariaDB</title>
      <link>https://timor.site/2014/01/debian-upgrade-mysql-to-mariadb/</link>
      <pubDate>Fri, 24 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2014/01/debian-upgrade-mysql-to-mariadb/</guid>
      <description>After reading some good opinions about MariaDB I wanted to give it a try. Upgrade looks quite straight forward but I found some issues a little tricky.
Installation Add repo and key:
cat &amp;gt; /etc/apt/sources.list &amp;lt;&amp;lt;SRC deb http://mirrors.supportex.net/mariadb/repo/5.5/debian wheezy main deb-src http://mirrors.supportex.net/mariadb/repo/5.5/debian wheezy main SRC (find more repositories here)
Now install MariaDB:
sudo apt-get update sudo apt-get install mariadb-server It could be better to install mariadb-server-5.5 and mariadb-client-5.5 package instead, because of this error.</description>
    </item>
    
    <item>
      <title>Nginx - enabling SPDY with freeware certificate</title>
      <link>https://timor.site/2014/01/nginx-enabling-spdy-with-freeware-certificate/</link>
      <pubDate>Fri, 24 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2014/01/nginx-enabling-spdy-with-freeware-certificate/</guid>
      <description>I was thinking about allowing access to my website using SPDY protocol for better performance and security (and for fun of course 😃 ). But SPDY have one disadvantage - you need SSL certificate signed by known authority that will verfiy in common browsers. So you can&amp;rsquo;t use self signed certificates because everyone will see a warning entering your site. Certs are quite expensive so I started searching for free one and to my surprise I found such!</description>
    </item>
    
    <item>
      <title>Searching for better code editor</title>
      <link>https://timor.site/2014/01/searching-for-better-code-editor/</link>
      <pubDate>Fri, 24 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2014/01/searching-for-better-code-editor/</guid>
      <description>I&amp;rsquo;ve been using different code editors for different purposes. Gedit was fine for small scripts but not for bigger projects. It lacks intelligent code completion (function/class names, etc.). I was searching for convenient editor for Python, Perl, Ruby with support for frameworks like Django, Rails, etc. I know Sublime Text - but it&amp;rsquo;s paid. There is LimeText - open source clone, but it&amp;rsquo;s not ready to be used on daily basics.</description>
    </item>
    
    <item>
      <title>Manage Windows 8.1 and Windows Server 2012 R2 in WSUS 3.0</title>
      <link>https://timor.site/2014/01/manage-windows-8-1-and-windows-server-2012-r2-in-wsus-3-0/</link>
      <pubDate>Thu, 16 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2014/01/manage-windows-8-1-and-windows-server-2012-r2-in-wsus-3-0/</guid>
      <description>After connecting few computers with Windows 8.1 to domain we found that these computers are not recognized or recognized as Windows 6.3 (which is true) on WSUS 3.0 running on Windows Server 2008. The bad thing was that they can&amp;rsquo;t properly report to WSUS and get updates from it.
I found that there are two updates that have to be installed (but they&amp;rsquo;re not working without additional steps):
http://support.microsoft.com/kb/2720211 http://support.microsoft.com/kb/2734608 After installation of second update there are two additional steps that have to be performed to get WSUS working:</description>
    </item>
    
    <item>
      <title>Regenerate thumbnails in Shotwell 0.15 (for last month)</title>
      <link>https://timor.site/2014/01/regenerate-thumbnails-in-shotwell-for-last-month/</link>
      <pubDate>Wed, 08 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2014/01/regenerate-thumbnails-in-shotwell-for-last-month/</guid>
      <description>I love Shotwell for it&amp;rsquo;s simplicity and easy export to Piwigo. After Christmas I added new photos to my library but after that I made some modifications to them (red eye reduction, etc&amp;hellip;). Because Shotwell generate thumbnails only on import, all my modifications were not visible on preview.
I&amp;rsquo;ve started searching how to regenerate thumbs and found this info. There were two issues with this method:
this howto was for old version (with old paths) and only for 128px thumbs I definitely don&amp;rsquo;t want to regenerate thumbnails for 40k photos!</description>
    </item>
    
    <item>
      <title>Loop unlooping in Javascript</title>
      <link>https://timor.site/2014/01/loop-unlooping-in-javascript/</link>
      <pubDate>Tue, 07 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2014/01/loop-unlooping-in-javascript/</guid>
      <description>Few days ago I&amp;rsquo;ve read a book ‘Even Faster Web Sites‘ about websites optimisation and I found one thing usefuluseful, not only on websites. There was a small tip about looploop unlooping. I want to quote them for later use.
First - with switch statement var iterations = Math.ceil(values.length / 8); var startAt = values.length % 8; var i = 0; do { switch(startAt) { case 0: process(values[i++]); case 7: process(values[i++]); case 6: process(values[i++]); case 5: process(values[i++]); case 4: process(values[i++]); case 3: process(values[i++]); case 2: process(values[i++]); case 1: process(values[i++]); } startAt = 0; } while(--iterations &amp;gt; 0); Second - without switch var iterations = Math.</description>
    </item>
    
    <item>
      <title>Tracking users by nickname on WordPress using Google Analytics</title>
      <link>https://timor.site/2014/01/tracking-users-by-nickname-on-wordpress-using-google-analytics/</link>
      <pubDate>Tue, 07 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2014/01/tracking-users-by-nickname-on-wordpress-using-google-analytics/</guid>
      <description>Some time ago I write article about tracking nicknames of users (from comments) on a WordPress blog with Piwik. This time I&amp;rsquo;m doing same but for Google Analytics.
I&amp;rsquo;m using Google Analytics plugin for WordPress so I&amp;rsquo;ve edited googleanalytics.php file to add some additional code for user tracking:
&amp;lt;script type=&amp;#34;text/javascript&amp;#34;&amp;gt; var i,x,y,ARRcookies=document.cookie.split(&amp;#34;;&amp;#34;); var comment_author = &amp;#34;&amp;#34;; for (i=0;i&amp;lt;ARRcookies.length;i++) { x=ARRcookies[i].substr(0,ARRcookies[i].indexOf(&amp;#34;=&amp;#34;)); y=ARRcookies[i].substr(ARRcookies[i].indexOf(&amp;#34;=&amp;#34;)+1); x=x.replace(/^\s+|\s+$/g,&amp;#34;&amp;#34;); if (x.indexOf(&amp;#34;comment_author&amp;#34;) != -1 &amp;amp;&amp;amp; x.indexOf(&amp;#34;comment_author_email&amp;#34;) == -1 &amp;amp;&amp;amp; x.</description>
    </item>
    
    <item>
      <title>Apache - precompressing static files with gzip</title>
      <link>https://timor.site/2013/12/apache-precompressing-static-files-with-gzip/</link>
      <pubDate>Fri, 27 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/12/apache-precompressing-static-files-with-gzip/</guid>
      <description>Some time ago I&amp;rsquo;ve show how to precompress js and css file with gzip to be available for Nginx&amp;rsquo;s mod_gzip. In default configuration Apache don&amp;rsquo;t have such module but similar functionality could be achieved with few custom rewirtes.
Basically we will start with these rewrites to serve gzipped CSS/JS files if they exist and the client accepts gzip compression:
RewriteEngine on RewriteCond %{HTTP:Accept-encoding} gzip RewriteCond %{REQUEST_FILENAME}\.gz -s RewriteRule ^(.*)\.(js|css)$ $1\.$2\.gz [QSA] Then we need to setup proper content types for such compressed files - I know how to do this in two ways:</description>
    </item>
    
    <item>
      <title>Android: Xposed &#43; AppOps - reclaim control over installed applications permissions</title>
      <link>https://timor.site/2013/12/android-xposed-appops-reclaim-control-over-installed-applications-permissions/</link>
      <pubDate>Tue, 17 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/12/android-xposed-appops-reclaim-control-over-installed-applications-permissions/</guid>
      <description>I&amp;rsquo;m happy owner of Galaxy Nexus 7 and lately I updated my tablet to Android 4.4 Kitkat. One of features I most expected was ability to block some permissions of some applications. Such setting was available in 4.4 version but was removed in latest 4.4.2 - Google didn&amp;rsquo;t explain it exactly why. I don&amp;rsquo;t like when for ex. game need: camera or GPS access - for what I asked?
But there is new app so called App Ops that unhides build-in interface allowing edit of application permissions.</description>
    </item>
    
    <item>
      <title>Generate ECDSA key with OpenSSL</title>
      <link>https://timor.site/2013/12/generate-ecdsa-key-with-openssl/</link>
      <pubDate>Tue, 17 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/12/generate-ecdsa-key-with-openssl/</guid>
      <description>After the last NSA scandal I&amp;rsquo;ve found some time to read some texts about PFS and ECDSA keys lately. I always used RSA keys but wanted to give a try to ECDSA so I wanted to give it a try (test performance, etc). Here is how I&amp;rsquo;ve done it.
Firstly find your favorite curve. A short tip about bit length and complexity could be found here. From it you will now that using 256 bit ECDSA key should be enough for next 10-20 years.</description>
    </item>
    
    <item>
      <title>Delete audio track from mkv file</title>
      <link>https://timor.site/2013/12/delete-audio-track-from-mkv-file/</link>
      <pubDate>Mon, 16 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/12/delete-audio-track-from-mkv-file/</guid>
      <description>Lately I tried to remove some streams from MKV file - I wanted: video, audio in my language and no subtitles. I achieved it with mkvtoolnix utils.
Firstly I have to identify streams in file:
$ mkvmerge -i input_file.mkv File &amp;#39;test.mkv&amp;#39;: container: Matroska Track ID 0: video (V_MPEG4/ISO/AVC) Track ID 1: audio (A_DTS) Track ID 2: audio (A_AC3) Track ID 3: audio (A_DTS) Track ID 4: audio (A_AC3) Track ID 5: subtitles (S_TEXT/UTF8) Track ID 6: subtitles (S_TEXT/UTF8) Chapters: 16 entries You could use more verbose tool mkvinfo for that purpose too.</description>
    </item>
    
    <item>
      <title>Preparing video files for streaming on website in MP4 and WEBM format</title>
      <link>https://timor.site/2013/12/preparing-video-files-for-streaming-on-website-in-mp4-and-webm-format/</link>
      <pubDate>Mon, 16 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/12/preparing-video-files-for-streaming-on-website-in-mp4-and-webm-format/</guid>
      <description>Some time ago I prepared a PC that was responsible for batch encoding of movies to formats suitable for web players (such as. Video.js, JW Player, Flowplayer, etc.)
I used HandBrake for conversion to MP4 format (becase this soft was the fastest one) and ffmpeg (aka avconv in new version) for two pass encoding to WEBM.
Below are commands used by me for that conversion:
MP4 HandBrakeCLI -e x264 -q 20.</description>
    </item>
    
    <item>
      <title>Running Apache with mod_spdy and PHP-FPM</title>
      <link>https://timor.site/2013/12/running-apache-with-mod_spdy-and-php-fpm/</link>
      <pubDate>Mon, 16 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/12/running-apache-with-mod_spdy-and-php-fpm/</guid>
      <description>SPDY is new protocol proposed by Google as an alternative for HTTP(S). Currently Chrome and Firefox browsers are using it as default if available on server. It is faster in most cases by few to several percent. The side effect of using mod_spdy is that it&amp;rsquo;s working well only with thread safe Apache&amp;rsquo;s modules. PHP module for Apache is not thread safe so we need to use PHP as CGI or FastCGI service.</description>
    </item>
    
    <item>
      <title>Re-adding failed drive in mdadm</title>
      <link>https://timor.site/2013/12/re-adding-failed-drive-in-mdadm/</link>
      <pubDate>Thu, 12 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/12/re-adding-failed-drive-in-mdadm/</guid>
      <description>Yesterday I have problem with fglrx witch cause ugly system reset. After that, one of my drives was marked as failed in RAID5 array. Hotspare was automatically used to rebuild array. But this hotspare is the oldest and slowest drive I&amp;rsquo;ve got&amp;hellip;
After rebuild I&amp;rsquo;ve tested failed drive and it was fine - no bad block, no any other issue - so I wanted it running back in array.
What I do:</description>
    </item>
    
    <item>
      <title>Ansible - Dynamicaly update /etc/hosts files on target servers</title>
      <link>https://timor.site/2013/12/ansible-dynamicaly-update-etc-hosts-files-on-target-servers/</link>
      <pubDate>Wed, 11 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/12/ansible-dynamicaly-update-etc-hosts-files-on-target-servers/</guid>
      <description>I was configuring GlusterFS on few servers using Ansible and have a need to update /etc/hosts with hostnames for easier configuration. I found this one working:
- name: Update /etc/hosts lineinfile: dest=/etc/hosts regexp=&amp;#39;.*{{item}}$&amp;#39; line=&amp;#39;{{hostvars.{{item}}.ansible_default_ipv4.address}} {{item}}&amp;#39; state=present with_items: &amp;#39;{{groups.somegroup}}&amp;#39; Source: http://xmeblog.blogspot.com/2013/06/ansible-dynamicaly-update-etchosts.html</description>
    </item>
    
    <item>
      <title>Reset user password in your own Ghost Blog</title>
      <link>https://timor.site/2013/11/reset-user-password-in-your-own-ghost-blog/</link>
      <pubDate>Thu, 28 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/11/reset-user-password-in-your-own-ghost-blog/</guid>
      <description>I&amp;rsquo;ve started testing new Ghost blogging platform for a while on a virtual machine before I take decision about switching to it (or maybe won&amp;rsquo;t)&amp;hellip; After few days, I wanted to go forward with more testing and stuck on &amp;ldquo;e-mail and password&amp;rdquo; login prompt 😃
I&amp;rsquo;ve started looking into files and found ghost_dir/content/data/ghost-dev.db SQLite database. It can be opened like that:
sqlite3 content/data/ghost-dev.db Then you could see whats your mail (and other info):</description>
    </item>
    
    <item>
      <title>Inodes on XFS</title>
      <link>https://timor.site/2013/11/inodes-on-xfs/</link>
      <pubDate>Wed, 27 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/11/inodes-on-xfs/</guid>
      <description>It&amp;rsquo;s quite rare to have problems with XFS and inodes exhaustion. Mostly because XFS doesn&amp;rsquo;t have inode limit in a manner known from other filesystems - it&amp;rsquo;s using some percentage of whole filesystem as a limit and in most distributions it&amp;rsquo;s 25%. So it&amp;rsquo;s really huge amount of inodes. But some tools and distributions lowered limit ex. 5% or 10% and there you could have problems more often.
You could check what is you limit by issuing xfs_info with drive and searching for imaxpct value:</description>
    </item>
    
    <item>
      <title>Kill with SIGSTOP and SIGCONT</title>
      <link>https://timor.site/2013/11/kill-with-sigstop-and-sigcont/</link>
      <pubDate>Thu, 21 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/11/kill-with-sigstop-and-sigcont/</guid>
      <description>I&amp;rsquo;ve bought a NAS and customized it a little. But there was one thing which make my nights sleepless. NAS was seeking disks every 5~10 seconds - these was really irritating - especially when it was silent in room. I found that part of firmware was indexing or logging something so I wanted it dead! kill -9 was unsuccessful - process restarted after a while&amp;hellip;. wrrr&amp;hellip;
I googled a little and found another signal I could use SIGSTOP, which will freeze process until I send SIGCONT to it - that was exactly what I need (because I normally use NFS/Samba and don&amp;rsquo;t need nothing more running on this device).</description>
    </item>
    
    <item>
      <title>My new toy - Iomega StorCenter ix2-200 Cloud Edition</title>
      <link>https://timor.site/2013/11/my-new-toy-iomega-storcenter-ix2-200-cloud-edition/</link>
      <pubDate>Tue, 19 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/11/my-new-toy-iomega-storcenter-ix2-200-cloud-edition/</guid>
      <description>I&amp;rsquo;ve just bought new toy - Iomega StorCenter ix2-200 Cloud Edition. I have to play with few options before I could start using it. First thing - Firmware upgrade.
Firmware upgrade I&amp;rsquo;ve started searching for latest firmware for ix2-200 Cloud and found that I have to register on Lenovo site to get firmware&amp;hellip; I don&amp;rsquo;t like such sites where they force me to give all private data, but after few clicks on &amp;ldquo;Recommended articles&amp;rdquo; on that site I landed here:</description>
    </item>
    
    <item>
      <title>Reenable web interface on Polycom VBP 5300 ST from CLI</title>
      <link>https://timor.site/2013/11/reenable-web-interface-on-polycom-vbp-5300-st-from-cli/</link>
      <pubDate>Mon, 18 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/11/reenable-web-interface-on-polycom-vbp-5300-st-from-cli/</guid>
      <description>After some configuration changes I&amp;rsquo;ve stuck with VBP not listening nor on HTTP, nor on SSH port. Last resort was to use CLI to reenable HTTP access. Connect with parameters:
Baud rate: 9600 Parity: none Bits: 8 Stopbits: 1 Flow control: none Then in login prompt you have to use login credentials (yes - they&amp;rsquo;re the same on every box (WTF?)):
User: - root Pass: - @#$%^&amp;amp;*!() Password is shift + 2345678190 - there is 1 before 9!</description>
    </item>
    
    <item>
      <title>Changing language of articles on my blog to English</title>
      <link>https://timor.site/2013/11/changing-language-of-articles-on-my-blog-to-english/</link>
      <pubDate>Fri, 15 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/11/changing-language-of-articles-on-my-blog-to-english/</guid>
      <description>I&amp;rsquo;ve crated this blog to get feedback from other IT guys about what I&amp;rsquo;m doing wrong (or not good enough). But this idea failed&amp;hellip;
I have only few comments on my blog (and about thousand and a half spams per month) - so, no feedback in my national language at all.
Switching to English should make my audience bigger and I hope to have more attention thanks to that. This will be also a good practice of my English skill.</description>
    </item>
    
    <item>
      <title>GearmanManager: wygodne zarządzanie workerami</title>
      <link>https://timor.site/2013/11/gearmanmanager-wygodne-zarzadzanie-workerami/</link>
      <pubDate>Wed, 13 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/11/gearmanmanager-wygodne-zarzadzanie-workerami/</guid>
      <description>Niedawno zainteresowałem się usługą Gearman i jedynej rzeczy której mi brakowało to jakiegoś łatwego mechanizmu zarządzającego workerami. Ale jak zwykle okazało się że inni mieli już ten problem i odpowiednie narzędzie istnieje - mowa o GearmanManagerze.
Instalacja GearmanManagera Aby zainstalować GeramanManagera na serwerze gdzie już mamy Gearmana trzeba wykonać kilka kroków (wcześniej powinniśmy też zainstalować moduł gearmana do php&amp;rsquo;a):
apt-get install git -y git clone https://github.com/brianlmoon/GearmanManager.git cd GearmanManager/install chmod +x install.</description>
    </item>
    
    <item>
      <title>Debian - zablokowanie aktualizacji pakietu</title>
      <link>https://timor.site/2013/11/debian-zablokowanie-aktualizacji-pakietu/</link>
      <pubDate>Tue, 05 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/11/debian-zablokowanie-aktualizacji-pakietu/</guid>
      <description>W teorii nie powinno się blokować aktualizacji pakietów bo łatają dziury itd&amp;hellip;. Ale! Zdarzyły mi się ostatnio dwie sytuacje, które do tego mnie zmusiły:
aktualizacja hudsona kończyła się błędem przy starcie usługi, aktualizacja domU Xen skończyła się problemem z kompatybilnością mechanizmu udev w systemie i jądrze (hypervisor miał starsze jądro niż spodziewało się DomU). W takich sytuacjach bardzo przydaje się możliwość zablokowania aktualizacji jednej &amp;ldquo;psującej&amp;rdquo; paczki na pewien okres czasu by nie opóźniać innych aktualizacji a sobie dać czas na rozpracowanie problemu.</description>
    </item>
    
    <item>
      <title>Instalacja gearman-job-server 1.0.6 na Debianie Wheezy</title>
      <link>https://timor.site/2013/10/instalacja-gearman-job-server-1-0-6-na-debianie-wheezy/</link>
      <pubDate>Tue, 29 Oct 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/10/instalacja-gearman-job-server-1-0-6-na-debianie-wheezy/</guid>
      <description>Ostatnio trafiłem na ciekawą usługę, która pozwala oddelegować długo trwające zadania z usługi webowej. Mowa o Gearman&amp;rsquo;ie. Usługa jest o tyle ciekawa że nie narzuca ani języka dla klienta (większość popularnych ma gotowe biblioteki), ani język dla skryptów w tej usłudze nie jest narzucany. Można tę usługę wykorzystać jako most pomiędzy PHP a np. Javą/Pythonem lub do zlecenia zadań z serwera na Linux&amp;rsquo;ie do wykonania na serwerze Windowsowym (bo np. narzędzia dostępne są tylko dla Windowsa).</description>
    </item>
    
    <item>
      <title>Uruchamianie aplikacji .NET jako 32-bitowej w 64-bitowym systemie</title>
      <link>https://timor.site/2013/10/uruchamiania-aplikacji-net-jako-32-bitowej-w-64-bitowym-systemie/</link>
      <pubDate>Tue, 29 Oct 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/10/uruchamiania-aplikacji-net-jako-32-bitowej-w-64-bitowym-systemie/</guid>
      <description>Kolejna zabawna sytuacja - pewna aplikacja dotNET&amp;rsquo;owa działała dziwnie na 64-bitowym systemie, a tymczasem na 32-bitowej maszynie ta sama aplikacja działała bez problemów. Jedyna różnica to inne wersje klientów ODBC na tych systemach, które po kilku testach okazały się być przyczyną całego zła.
Pojawił się pomysł by odpalić aplikacje na 64 bitowym systemie ale w trybie 32 bit - poniżej krótkie HOWTO jak to osiągnąć:
potrzebujemy narzędzia corflags.exe które pozwoli oznaczyć nam binarkę jako 32-bitową, do pobrania tutaj a instrukcja jej użycia tutaj.</description>
    </item>
    
    <item>
      <title>Certyfikaty nazwaSSL na własnym serwerze</title>
      <link>https://timor.site/2013/10/certyfikaty-nazwassl-na-wlasnym-serwerze/</link>
      <pubDate>Tue, 22 Oct 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/10/certyfikaty-nazwassl-na-wlasnym-serwerze/</guid>
      <description>Od jakiegoś czasu można kupić w NetArcie certyfikaty SSL, a niedawno zrobili na nie promocję - 15zł za pierwszy rok (za certyfikat na jedną stronkę). Tzw. tanie i dobre. Po wyrobieniu certyfikatu i zapisaniu z panelu klienta mam pliczki: stonka.crt i netart_rootca.crt, które wrzucamy do Apachego, powiedzmy tak:
SSLCertificateFile /etc/ssl/certs/stonka.crt SSLCertificateKeyFile /etc/ssl/private/priv.key SSLCACertificateFile /etc/ssl/certs/netart_rootca.crt Certyfikat działa w Chromie ale nie weryfikuje się w Firefoxie i Internet Explorerze. FF wyświetla błąd: sec_error_unknown_issuer - co oznacza brak certyfikatu wystawcy gdzieś w łańcuchu certyfikatów.</description>
    </item>
    
    <item>
      <title>Postfix: ciekawy problem z smtpd_delay_reject i permit_sasl_authenticated</title>
      <link>https://timor.site/2013/10/postfix-ciekawy-problem-z-smtpd_delay_reject-i-permit_sasl_authenticated/</link>
      <pubDate>Tue, 08 Oct 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/10/postfix-ciekawy-problem-z-smtpd_delay_reject-i-permit_sasl_authenticated/</guid>
      <description>Trafił mi się ostatnio ciekawy problem - otóż standardowo przed końcem roku poprawiałem filtry antyspamowe i optymalizowałem konfigurację Postfix&amp;rsquo;a. Chciałem zmienić domyślną wartość smtpd_delay_reject=yes na smtpd_delay_reject=no by odrzucać spamerów najwcześniej jak to możliwe. I ciekawe kuku, które sobie zrobiłem polegało na tym że sam nie mogłem wysyłać poczty po logowaniu SSL&amp;rsquo;em&amp;hellip;
Dostawałem przy tym bardzo wymowną odpowiedź:
Oct 8 16:30:39 tyr postfix/smtpd[21039]: NOQUEUE: reject: CONNECT from unknown[67.x.x.x]: 554 5.7.1 &amp;lt;unknown [67.</description>
    </item>
    
    <item>
      <title>Instalacja Python’a na Windowsie</title>
      <link>https://timor.site/2013/09/instalacja-pythona-na-windowsie/</link>
      <pubDate>Wed, 25 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/09/instalacja-pythona-na-windowsie/</guid>
      <description>Pomimo że Python dużo częściej wykorzystywany jest w środowiskach UNIX&amp;rsquo;owcy/Linux&amp;rsquo;owych to znajdzie się kilka fajnych zastosowań dla tego języka na Windowsie. Możliwości na instalację jest kilka, a najprostsza to wykorzystanie instalatora ActiveState. Wersja ta ma w sobie wszystko co potrzebne:
rozszerzenia dla API Windows menadżera pakietów PyPM dokumentację Niestety jakiś czas temu zmieniły się zasady licencjonowania w ActiveState i aktualne wersje dla zastosowań produkcyjnych wymagają zakupu licencji (1000$/rok - aż chce się zacytować z Dnia Świra: czizys k&amp;hellip;wa&amp;hellip;).</description>
    </item>
    
    <item>
      <title>Sprawdzanie zainstalowanej wersji Django</title>
      <link>https://timor.site/2013/09/sprawdzanie-zainstalowanej-wersji-django/</link>
      <pubDate>Mon, 16 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/09/sprawdzanie-zainstalowanej-wersji-django/</guid>
      <description>Ten one liner załatwia sprawę:
python -c &amp;#39;import django; print &amp;#34;.&amp;#34;.join([str(s) for s in django.VERSION]);&amp;#39; </description>
    </item>
    
    <item>
      <title>Spammer screwed up</title>
      <link>https://timor.site/2013/09/spammer-screwed-up/</link>
      <pubDate>Sun, 15 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/09/spammer-screwed-up/</guid>
      <description>I&amp;rsquo;ve just received a comment on my blog with text attached below. It looks like spam message template. I think it could be easily used for creation of banning rules, etc. Use it in a way that will make this dumbass spammer look even more stupid ;-)
{ {I have|I’ve} been {surfing|browsing} online more than {three|3|2|4} hours today, yet I never found any interesting article like yours. {It’s|It is} pretty worth enough for me.</description>
    </item>
    
    <item>
      <title>Raspberry Pi: pierwsze kroki</title>
      <link>https://timor.site/2013/09/raspberry-pi-pierwsze-kroki/</link>
      <pubDate>Fri, 13 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/09/raspberry-pi-pierwsze-kroki/</guid>
      <description>Wyprzeć się nie mogę że gadżety działające na Linuksie po prostu mnie kręcą, więc tylko kwestią czasu było aż Pi zawita na moim biurku. Zakupiłem więc model B w drugiej wersji, obudowę z możliwością mocowania VESA, kabelek HDMI, ładowarka z mojej myszy pasowała idealnie (5.05V i 1A) i na początek karta SD klasa 10 4GB.
Szukając różnych systemów (a może ROM&amp;rsquo;ów) natrafiłem na oficjalną stronę: http://www.raspberrypi.org/downloads
Na początek wystarczy a sprawdzając na stronach projektów okazało się że wersje na tej stronie są całkiem aktualne.</description>
    </item>
    
    <item>
      <title>Nginx - przydatne rewrite’y i różne sztuczki</title>
      <link>https://timor.site/2013/09/nginx-przydatne-rewritey-i-rozne-sztuczki/</link>
      <pubDate>Mon, 09 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/09/nginx-przydatne-rewritey-i-rozne-sztuczki/</guid>
      <description>Polubiłem Nginx&amp;rsquo;a i wykorzystuję go na coraz więcej sposobów. Kilka rzeczy udało mi się całkiem fajnie w nim skonfigurować i postanowiłem zebrać te przykłady by następnym razem gdy postanowię do nich sięgnąć nie musieć wertować konfigów po serwerach 😃
Słowo wstępu Niektóre rewrite&amp;rsquo;y kończą się znakiem ? - czemu?
Otóż Nginx próbuje automatycznie dodawać parametry na końcu przepisanego adresu. Jeśli jednak wykorzystamy zmienną $request_uri to ona sama w sobie zawiera już parametry zapytania (czyli to co w URI znajduje się po znaku ?</description>
    </item>
    
    <item>
      <title>tor: generowanie milszej nazwy dla hidden service</title>
      <link>https://timor.site/2013/09/tor-generowanie-milszej-nazwy-dla-hidden-service/</link>
      <pubDate>Mon, 09 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/09/tor-generowanie-milszej-nazwy-dla-hidden-service/</guid>
      <description>Chcąc pobawić się tor&amp;rsquo;em postanowiłem udostępnić jedna z moich stron z wykorzystaniem mechanizmu hidden service. Nie spodobał mi się jedynie sposób generowania nazw, które były mało opisowe - ale najwidoczniej nie mnie jednemu, bo szybko namierzyłem Shallot, który generuje kolejne nazwy aż trafi na pasującą do zadanego regexp&amp;rsquo;a.</description>
    </item>
    
    <item>
      <title>DFS - sprawdzanie statusu replikacji</title>
      <link>https://timor.site/2013/09/dfs-sprawdzanie-statusu-replikacji/</link>
      <pubDate>Wed, 04 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/09/dfs-sprawdzanie-statusu-replikacji/</guid>
      <description>Ostatnio zbyt dużo grzebię przy &amp;ldquo;windach&amp;rdquo; - ale cóż, czasem trzeba. Ostatnio ustawiałem DFS&amp;rsquo;a z replikacją dla dwóch sporych zasobów i jedna z rzeczy, o którą się rozbiłem to brak jakiegokolwiek podglądu tej synchronizacji z GUI. Ale znalazłem jedno polecenie, które działa w shellu (choć to się chyba batch tutaj nazywa) od Windows Server 2008 R2:
dfsrdiag ReplicationState /member:nazwaservera Polecenie co prawda nie podaje postępu procentowego ale można zobaczyć &amp;ldquo;czy coś jeszcze się synchronizuje&amp;rdquo; i czy nie ma żadnych błędów.</description>
    </item>
    
    <item>
      <title>Root’owanie Androida 4.3 na Google Nexus 7 po aktualizacji do JWR66Y</title>
      <link>https://timor.site/2013/09/rootowanie-androida-4-3-na-google-nexus-7-po-aktualizacji-do-jwr66y/</link>
      <pubDate>Wed, 04 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/09/rootowanie-androida-4-3-na-google-nexus-7-po-aktualizacji-do-jwr66y/</guid>
      <description>Ostatnio aktualizowałem swojego Nexusa do 4.3 i było miło tylko mi roota i recovery wystrzeliło&amp;hellip; No ale żaden problem - chwila googlania, kilka poleceń i mam recovery i roota. Dzisiaj wrzuciłem niedużą aktualizację, która łata kilka bugów i znów po root&amp;rsquo;cie ;/
Zapisze sobie więc instrukcję by kolejnym razem już nie googlać 😃
P.S. Wiem co robię ryzykując uceglenie swojego urządzenia - u mnie ta instrukcja działa ale nie mogę tego zagwarantować każdemu - dlatego jeśli już się zdecydujesz to ROBISZ TO NA WŁASNĄ ODPOWIEDZIALNOŚĆ!</description>
    </item>
    
    <item>
      <title>Kopiowanie wolumenów LVM z dd i netcat</title>
      <link>https://timor.site/2013/09/kopiowanie-wolumenow-lvm-z-dd-i-netcat/</link>
      <pubDate>Mon, 02 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/09/kopiowanie-wolumenow-lvm-z-dd-i-netcat/</guid>
      <description>Niedawno chciałem skopiować maszynę wirtualną z jednego hypervisora na innego. Były to 3 wolumeny LVM o rozmiarach od 50 do 100GB. Dawno temu zrobiłem sobie skrypty do backupu - jeden kompresuje wolumeny LVM - a drugi pozwala odtworzyć z dekompresja na drugim serwerze. Tyle że przy tak dużej maszynce będzie to trwało masakrycznie długo - fajnie byłoby móc równocześnie kopiować i odtwarzać (live)&amp;hellip;
I wtedy przypomniało mi się narzędzie netcat - zrobiłem snapshoty wolumenów i mogłem zaczynać.</description>
    </item>
    
    <item>
      <title>GPO: Instalacja GIMP’a 2.8</title>
      <link>https://timor.site/2013/08/gpo-instalacja-gimpa-2-8/</link>
      <pubDate>Tue, 06 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/08/gpo-instalacja-gimpa-2-8/</guid>
      <description>Raz na jakiś czas trzeba coś niestandardowego wrzucić do instalacji w Active Directory a że nie wszystkie aplikacje mają dostępne paczki MSI to trzeba się nieco natrudzić.
Poniżej wrzucam skrypt, który instaluje GIMP&amp;rsquo;a 2.8 z domyślnego instalatora (wersja InnoSetup) przy okazji odinstalowując wcześniejsze wersje zainstalowane ręcznie.
Zapisujemy poniższy kod jako np. gimp-install.cmd
@echo off REM Installs GIMP cls echo ---------------------------------------------------- echo . echo . echo . Installing/Updating GIMP - Please Wait echo .</description>
    </item>
    
    <item>
      <title>logrotate: kompresja logów xz</title>
      <link>https://timor.site/2013/07/logrotate-kompresja-logow-xz/</link>
      <pubDate>Mon, 29 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/07/logrotate-kompresja-logow-xz/</guid>
      <description>Narzędzia xz-utils dostępne w nowszych systemach korzystają z mocniejszych algorytmów kompresji (jakaś odmiana LZMA, coś w stylu 7zip&amp;rsquo;a) przy zachowaniu kompatybilności składni poleceń z gzip&amp;rsquo;em/bzip&amp;rsquo;em - da się je zatem łatwo zintegrować w obecnych systemach. Ja chciałem wykorzystać xz do kompresji logów, które bywają przydatne ale przez większość czasy tylko zajmują miejsce :simple_smile:
W /etc/logrotate.conf dopisujemy:
compresscmd /usr/bin/xz uncompresscmd /usr/bin/unxz compressext .xz compressoptions -9T2 compressoptions można nie ustawiać bo domyślnie ma wartość -9 (czyli kompresuj na maxa), mój dodatek (czyli -T2) użyje dwóch wątków procesora gdy już ten mechanizm zostanie zimplementowany (bo na razie nie jest) :simple_smile:</description>
    </item>
    
    <item>
      <title>Bezstratna konwersja MKV z DTS do AC3 lub AAC</title>
      <link>https://timor.site/2013/07/bezstratna-konwersja-mkv-z-dts-do-ac3-lub-aac/</link>
      <pubDate>Wed, 17 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/07/bezstratna-konwersja-mkv-z-dts-do-ac3-lub-aac/</guid>
      <description>Na jednym z urządzeń miałem problem z odtworzeniem plików (głównie MKV) z dźwiękiem zakodowanym w DTS. Pomijając że np. na tablecie 6-cio kanały DTS jest mi &amp;ldquo;niezbędny inaczej&amp;rdquo; to konwertując go do AAC stereo plik jest po prostu sporo mniejszy. Oczywiście nie zamierzam transkodować ścieżki video i na moje potrzeby mogłem sobie odpuścić zmianę częstotliwości próbkowania.
Najprościej wykorzystać pakiet ffmpeg (po nowemu avconv) lub mencoder (choć ten miewał niegdyś problem z poprawnym zapisywaniem wynikowych plików mkv, więc potrzebny jest dodatkowo mkvmerge z pakietu mkvtoolnix).</description>
    </item>
    
    <item>
      <title>Dodawanie urządzeń SCSI/FC bez restartu serwera</title>
      <link>https://timor.site/2013/07/dodawanie-urzadzen-scsifc-bez-restartu-serwera/</link>
      <pubDate>Wed, 17 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/07/dodawanie-urzadzen-scsifc-bez-restartu-serwera/</guid>
      <description>Raz na jakiś czas gdy grzebię przy maciorach muszę &amp;ldquo;odkryć&amp;rdquo; nowy volumen FC (lub rzadziej SCSI), który właśnie utworzyłem a restart serwera nie wchodzi w rachubę (zresztą na części systemów nic on nie da).
By to zrobić są dwie możliwości:
Ręczne wydanie poleceń odkrywających volumeny (na jajkach od 2.6.x) Sprawdzamy jakie mamy karty:
ls /sys/class/fc_host/ (wypisze się coś w stylu: host1, host2)
Wydajemy do wybranej przez nas karty żądanie wykonania LIP (to się chyba tłumaczy jako loopback initialization) co skutkuje przeskanowaniem szyny FC:</description>
    </item>
    
    <item>
      <title>Debian - Instalacja Bittorrent Sync (btsync)</title>
      <link>https://timor.site/2013/07/debian-instalacja-bittorrent-sync-btsync/</link>
      <pubDate>Tue, 16 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/07/debian-instalacja-bittorrent-sync-btsync/</guid>
      <description>Bardzo spodobała mi się nowa aplikacja do zdalnej synchronizacji folderów z wykorzystaniem P2P. Ja wykorzystałem ją do automatycznych backupów archiwum zdjęć - zebrało mi się tego już prawie 130GB! Każde narzędzie, które chce np. je kompresować i raz na czas robić FULL backup jest skazane na porażkę - a fotek przybywa.
Na początek pobieramy interesującą nas wersję:
wget http://btsync.s3-website-us-east-1.amazonaws.com/btsync_i386.tar.gz wget http://btsync.s3-website-us-east-1.amazonaws.com/btsync_x64.tar.gz Oraz paczkę ze skryptami dla Debiana:
wget http://www.yeasoft.com/downloads/various/btsync-linux-deploy.tar.gz Ja wyciągam z niej skrypt /etc/init.</description>
    </item>
    
    <item>
      <title>Tworzenie patch’y z poleceniami diff i patch</title>
      <link>https://timor.site/2013/04/tworzenie-patchy-z-poleceniami-diff-i-patch/</link>
      <pubDate>Mon, 01 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/04/tworzenie-patchy-z-poleceniami-diff-i-patch/</guid>
      <description>Jest kilka powodów dla których tworzenie patchy jest przydatne - jeśli tu jesteś to pewnie masz jakiś własny&amp;hellip;
Tworzenie patch&amp;rsquo;a diff -crB old new &amp;gt; from-old-to-new.patch W powyższym poleceniu założyłem że old i new to katalogi z wieloma podkatalogami i plikami - stąd opcja -r. -c dodaje kilka linijek &amp;ldquo;kontekstu&amp;rdquo; przez co łatwiej rozeznać się w patch&amp;rsquo;u. Opcja -B ignoruje puste linie, których patchowanie mnie nie interesuje.
Patchowanie Na początek zawsze warto wywołać polecenie z opcją -dry-run by zobaczyć czy patch wykona się poprawnie:</description>
    </item>
    
    <item>
      <title>Rozsynchronizowane serwery NTP</title>
      <link>https://timor.site/2013/03/rozsynchronizowane-serwery-ntp/</link>
      <pubDate>Sun, 31 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/03/rozsynchronizowane-serwery-ntp/</guid>
      <description>Miałem ostatnio zabawną sytuację gdy kilka serwerów z zainstalowanym NTPD miało rozjazdy rzędu kilkunastu sekund. Wyszło na to że moje serwery synchronizowały się z różnymi zewnętrznymi serwerami NTP pomiędzy, którymi były rozjazdy i te rozjazdy synchronizowały się na moich serwerach. Jeden &amp;ldquo;z moich&amp;rdquo; ustanowiłem głównym a wszystkie inne przekierowałem na niego (komentując wszystkie inne serwery NTP w konfiguracji). Wymusiłem synchronizację:
ntp -q Sprawdziłem jak duży jest offset i jitter (powinny być bardzo małe):</description>
    </item>
    
    <item>
      <title>Fortigate - VPN IPSec PSK XAuth z Android’a 4.x</title>
      <link>https://timor.site/2013/03/fortigate-vpn-ipsec-psk-xauth-z-androida-4-x/</link>
      <pubDate>Sat, 30 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/03/fortigate-vpn-ipsec-psk-xauth-z-androida-4-x/</guid>
      <description>Do niedawna na moim telefonie VPN&amp;rsquo;ami były: PPTP lub L2TP - oba niespecjalnie mi się podobały. Ale od wersji 4-tej pojawiły się dwa nowe tryby: IPSec Xauth PSK i IPSec Xauth RSA. W pierwszym autoryzacja wykorzystuje login i hasło, w drugim certyfikaty.
Tryb IPSec Xauth PSK jest bardzo wygodny bo łatwo można połączyć go z zewnętrznymi mechanizmami uwierzytelniającymi np. LDAP, Active Directory, itp.
Pokażę jak skonfigurować swojego Fortigate&amp;rsquo;a by umożliwić połączenie z telefonów i tabletów na Androidzie 4.</description>
    </item>
    
    <item>
      <title>Nginx - hide server version and name in Server header and error pages</title>
      <link>https://timor.site/2013/01/nginx-hide-server-version-and-name-in-server-header-and-error-pages/</link>
      <pubDate>Thu, 24 Jan 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/01/nginx-hide-server-version-and-name-in-server-header-and-error-pages/</guid>
      <description>On Debian you have to install nginx-extras package (because it have built in headers_more module). Then you need two options (best in global configuration /etc/nginx/nginx.conf file, http part):
server_tokens off; more_set_headers &amp;#39;Server: BadAss&amp;#39;; And it&amp;rsquo;s good to setup non standard error pages on every site (500 and 404 at minimum):
error_page 403 404 http://mysite.com/areyoulost; error_page 502 503 504 /500.html; </description>
    </item>
    
    <item>
      <title>PHP - max_input_vars</title>
      <link>https://timor.site/2013/01/php-max_input_vars/</link>
      <pubDate>Tue, 22 Jan 2013 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2013/01/php-max_input_vars/</guid>
      <description>W PHP 5.3 pojawiła się nowa zmienna: max_input_vars, która limituje ilość pól możliwych do przesłania przez formularz, obcinając nadmiarowe. Pozwala to zapobiec atakom DoS na tablice hashujące (przynajmniej w tym jednym miejscu). Domyślna wartość tej zmiennej to 1000 i kreatywnym programistom udaje się tą wartość bez problemu osiągnąć 😃
Warte odnotowania jest to że mając suhosin&amp;rsquo;a trzeba pamiętać o jeszcze dwóch innych zmiennych:
max_input_vars = 3000 suhosin.post.max_vars = 3000 suhosin.request.max_vars = 3000 Zmienne można zmienić od razu w /etc/php5/apache2/php.</description>
    </item>
    
    <item>
      <title>Linux - naprawianie bad sectorów</title>
      <link>https://timor.site/2012/12/linux-naprawianie-bad-sectorow/</link>
      <pubDate>Thu, 27 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/12/linux-naprawianie-bad-sectorow/</guid>
      <description>Dyski się zużywają i w końcu wcześniej czy później pojawiają się na nich bad sectory. Jeden z moich dysków ciut się posypał a że służy wyłącznie do backupów to mogę z tym żyć. Ale z drugiej strony jeżeli już będę musiał sięgnąć do backupów to chcę mieć pewność że coś odzyskam, dlatego postanowiłem zrobić kilka testów. Nawet jeśli nie naprawi to sektorów to przynajmniej zostaną zaznaczone jako uszkodzone i realokowane.</description>
    </item>
    
    <item>
      <title>Piwik: śledzenie asynchroniczne &#43; logowanie ksywy komentującego w WordPress’ie</title>
      <link>https://timor.site/2012/12/piwik-sledzenie-asynchroniczne-logowanie-ksywy-komentujacego-w-wordpressie/</link>
      <pubDate>Fri, 21 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/12/piwik-sledzenie-asynchroniczne-logowanie-ksywy-komentujacego-w-wordpressie/</guid>
      <description>Korzystam z instancji Piwik&amp;rsquo;a do monitorowania odwiedzin na stronie i postanowiłem pokombinować czy da się w ten sposób monitorować wejścia konkretnych osób na bazie wpisanego w polu komentarza loginu/ksywki. Jak zacząłem grzebać to przy okazji zmieniłem też sposób ładowania skryptów Piwika na asynchroniczny.
A leci to mniej więcej tak:
&amp;lt;script type=&amp;#34;text/javascript&amp;#34;&amp;gt; var i,x,y,ARRcookies=document.cookie.split(&amp;#34;;&amp;#34;); var comment_author = &amp;#34;&amp;#34;; for (i=0;i&amp;lt;ARRcookies.length;i++) { x=ARRcookies[i].substr(0,ARRcookies[i].indexOf(&amp;#34;=&amp;#34;)); y=ARRcookies[i].substr(ARRcookies[i].indexOf(&amp;#34;=&amp;#34;)+1); x=x.replace(/^\s+|\s+$/g,&amp;#34;&amp;#34;); if (x.indexOf(&amp;#34;comment_author&amp;#34;) != -1 &amp;amp;&amp;amp; x.indexOf(&amp;#34;comment_author_email&amp;#34;) == -1 &amp;amp;&amp;amp; x.</description>
    </item>
    
    <item>
      <title>Jak dokuczać spamerom</title>
      <link>https://timor.site/2012/12/jak-dokuczac-spamerom/</link>
      <pubDate>Tue, 18 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/12/jak-dokuczac-spamerom/</guid>
      <description>Dawno, dawno temu&amp;hellip; Za górami, za lasami&amp;hellip; czytałem sobie tekst Lemat&amp;rsquo;a o dokuczaniu spamerom i pomyślałem że sam też tak mogę i nawet chcę więc popełniłem skrypcik, który dla losowych słów generował maile. Skrypcik działał z dwa lata na mojej poprzedniej stronie i nie raz zdarzyło się tam jakiejś mendzie zapętlić. Jakoś nie miałem czasu od razu, a później zapomniałem wrzucić go na nową stronie i tak zostało - na pewien czas.</description>
    </item>
    
    <item>
      <title>Nginx - kompresowanie plików dla gzip_static</title>
      <link>https://timor.site/2012/12/nginx-kompresowanie-plikow-dla-gzip_static/</link>
      <pubDate>Mon, 17 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/12/nginx-kompresowanie-plikow-dla-gzip_static/</guid>
      <description>Ruski serwer WWW ma przydatną funkcję serwowania wersji plików skompresowanych gzip&amp;rsquo;em - przez co możemy plik skompresować raz i będzie on serwowany klientom obsługującym kompresję HTTP ale już bez każdorazowego kompresowania go. Jest to bardzo przydatne na stronach z dużym ruchem gdzie można w ten sposób zaoszczędzić takty CPU na właściwą obsługę połączeń a nie kompresję. Drugie miejsce gdzie może to być przydatne to VPS&amp;rsquo;y i &amp;ldquo;cienkie&amp;rdquo; serwery, które na kompresji przy większym obciążeniu spędzają zbyt dużo czasu i daje się to odczuć w działaniu strony.</description>
    </item>
    
    <item>
      <title>Apache: mod_authnz_ldap z Active Directory</title>
      <link>https://timor.site/2012/12/apache-mod_authnz_ldap-z-active-directory/</link>
      <pubDate>Fri, 14 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/12/apache-mod_authnz_ldap-z-active-directory/</guid>
      <description>Gdy już się dorobi systemu Active Directory wygodnie jest wykorzystać jego bazę użytkowników do autoryzacji w różnych miejscach, np. do pewnych &amp;ldquo;tajnych i tajniejszych&amp;rdquo; stron w Apache. Najprościej można to zrobić z wykorzystaniem LDAP.
Warto sprawdzić czy i jak możemy dostać się do kontrolerów. Gdy już mamy wszystkie potrzebne parametry konfigurujemy Apachego - na początek aktywujemy moduły:
a2enmod ldap a2enmod authnz_ldap Teraz możemy edytujemy globalny plik konfiguracyjny mod_ldap&amp;rsquo;a by ustawić nieco cache&amp;rsquo;y (bardzo przydatne).</description>
    </item>
    
    <item>
      <title>Python - wysyłanie maili w unicode</title>
      <link>https://timor.site/2012/12/python-wysylanie-maili-w-unicode/</link>
      <pubDate>Mon, 10 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/12/python-wysylanie-maili-w-unicode/</guid>
      <description>Chciałem wysłać z Python&amp;rsquo;a maila z krzakami tab by ładnie się wyświetlały i okazało się to całkiem nietrywialne.
Na szczęście googiel podpowiedział mi doskonałego gotowca, którego zamierzam zapisać by mi nie zginął:
#!/usr/bin/env python # -*- coding: utf-8 -*- import smtplib from email.mime.text import MIMEText from email.Header import Header from email.Utils import parseaddr, formataddr def send_email(sender, recipient, subject, body): &amp;#34;&amp;#34;&amp;#34;Send an email. All arguments should be Unicode strings (plain ASCII works as well).</description>
    </item>
    
    <item>
      <title>ldapsearch w Active Directory</title>
      <link>https://timor.site/2012/12/ldapsearch-w-active-directory/</link>
      <pubDate>Wed, 05 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/12/ldapsearch-w-active-directory/</guid>
      <description>Można lubieć AD, można go nie lubieć&amp;hellip; Ale jak już się ma to warto czasem zintegrować go z tym&amp;hellip; i tamtym&amp;hellip; Od strony Linuksa najwygodniej można to osiągnąć przez LDAP. A żeby to dobrze zrobić trzeba najpierw przetestować czy aby wszystko działa jak byśmy sobie tego życzyli. I tutaj bardzo przydatne jest narzędzie ldapsearch.
Do odpytywania LDAP&amp;rsquo;a potrzebujemy jeden pakiecik, który zawiera kilka narzędzi do jego obsługi:
apt-get install ldap-utils Teraz możemy próbować przeszukiwać katalog np.</description>
    </item>
    
    <item>
      <title>Ciastka z kleiku ryżowego</title>
      <link>https://timor.site/2012/11/ciastka-z-kleiku-ryzowego/</link>
      <pubDate>Tue, 20 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/11/ciastka-z-kleiku-ryzowego/</guid>
      <description>Składniki 1 paczka bezsmakowego kleiku ryżowego (190~170 g), 2 jajka, 1 kostka miękkiego masła (250 g), 1 płaska łyżeczka proszku do pieczenia, pół szklanki cukru, cukier waniliowy (16 g) (niekoniecznie), 8 czubatych łyżek wiórków kokosowych, dżem do wypełnienia ciastek (opcjonalnie - ja lubię je również bez dżemu). Sposób przygotowania Wszystkie składniki połączyć razem i wyrobić (najlepiej się ugniata ręką). Formować kulki wielkości małego orzecha włoskiego, układać na blaszce wyłożonej papierem do pieczenia w niewielkich odległościach (trochę urosną).</description>
    </item>
    
    <item>
      <title>Ciasto z dynią</title>
      <link>https://timor.site/2012/11/ciasto-z-dynia/</link>
      <pubDate>Mon, 12 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/11/ciasto-z-dynia/</guid>
      <description>Składniki 2 szklanki miąższu dyni (startego lub zmiksowanego), 2 szklanki mąki, 0,75 szklanki cukru, 3 jajka, 5 łyżeczek cynamonu, 16 g cukru wanilinowego, 0,75 szklanki oleju, łyżeczka sody oczyszczonej, garść orzechów włoskich. Sposób przygotowania Ubijamy białka z cukrem. Do ubitej piany dodajemy żółtka i kolejne składniki: mąkę, olej, cukier wanilinowy, sodę i cynamon. Całość miksujemy jeszcze przez chwilę, a następnie dodajemy posiekany lub starty i odsączony (można np. mocno ścisnąć w dłoniach) miąższ dyni oraz drobno pokrojone orzechy włoskie i jeszcze chwilę mieszamy.</description>
    </item>
    
    <item>
      <title>Automatically compact CouchDB databases in version 0.11.x</title>
      <link>https://timor.site/2012/11/automatically-compact-couchdb-databases-in-0-11-x/</link>
      <pubDate>Thu, 08 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/11/automatically-compact-couchdb-databases-in-0-11-x/</guid>
      <description>CouchDB databases on version 0.11.x swell very fast. They should be compacted daily for best performance and space usage. Here is my script that could be run in cron and will compact all databases:
#!/bin/bash IP=&amp;#34;10.0.0.121&amp;#34; DBS=`curl -sS -X GET http://$IP:5984/_all_dbs | sed -r &amp;#34;s/([,\&amp;#34;[])|(\])+/ /g&amp;#34;` for d in $DBS; do curl -H &amp;#34;Content-Type: application/json&amp;#34; -X POST http://$IP:5984/$d/_compact done More informations about compacting could be found here (also for version 1.</description>
    </item>
    
    <item>
      <title>LVM na RAID5 i dysku z sektorami 4KB</title>
      <link>https://timor.site/2012/11/lvm-na-raid5-i-dysku-z-sektorami-4kb/</link>
      <pubDate>Wed, 07 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/11/lvm-na-raid5-i-dysku-z-sektorami-4kb/</guid>
      <description>Po zakupie nowych dysków zamierzam utworzyć zdegradowaną macierz RAID5 z dwóch dysków (na trzecim na razie znajdują się dane), potem utworzyć wolumen LVM, sformatować go, przekopiować dane z pojedynczego dysku na macierz i dołączyć trzeci dysk do macierzy odbudowując parzystość. Zadanie będzie o tyle ciekawe że dysk ma 4KB sektory i trzeb będzie dbać o wyrównanie zasobu do rozmiaru sektora, a w przypadku LVM&amp;rsquo;a wyrównanie do chunk&amp;rsquo;a z macierzy.
Prawidłowe wyrównanie partycji Kupując nowy dysk (o pojemności od 500GB w górę), mamy spore szanse że trafimy na sztukę, która wykorzystuje 4KB sektory do alokacji danych.</description>
    </item>
    
    <item>
      <title>Instalacja drukarki i skanera Brother DCP-130C na Ubuntu 12.04</title>
      <link>https://timor.site/2012/11/instalacja-drukarki-i-skanera-brother-dcp-130c-na-ubuntu-12-04/</link>
      <pubDate>Sun, 04 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/11/instalacja-drukarki-i-skanera-brother-dcp-130c-na-ubuntu-12-04/</guid>
      <description>Po każdej aktualizacji Ubuntu mam trochę zabawy by pozbierać do kupy skaner i drukarkę z mojego urządzenia wielofunkcyjnego Brother DCP-130C. Wybrałem je bo był to jedyny producent, który deklarował wsparcie dla Linux&amp;rsquo;a&amp;hellip; choć z perspektywy czasu nie jestem pewien czy otrzymałem to czego się spodziewałem&amp;hellip; Co prawda zamieszczają instrukcje i aktualizują drivery ale jeszcze ani raz nie zdarzyło mi się by po aktualizacji systemu postępowanie według tych instrukcji zadziałało bez dodatkowej pomocy.</description>
    </item>
    
    <item>
      <title>Prosty MTA z heirloom-mailx i ssmtp</title>
      <link>https://timor.site/2012/11/prosty-mta-z-heirloom-mailx-i-ssmtp/</link>
      <pubDate>Wed, 31 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/11/prosty-mta-z-heirloom-mailx-i-ssmtp/</guid>
      <description>Czasami potrzebny jest nam serwer pocztowy, który przyśle informacje dla root&amp;rsquo;a (np. monity smartd, mdadm, sypnięte crony itp) ale równocześnie nie chcemy stawiać pełnego serwera typu postfix/exim. Warto w tym celu wykorzystać zestaw heirloom-mailx + ssmtp. hairloom-mailx jest prostym shellowym klientem SMTP - przy okazji linkuje polecenie mail (przydatne w skryptach). ssmtp pełni funkcję serwera SMTP ale nie działa jako demon - proces uruchamia się gdy jest potrzebny i znika po wysłaniu maili.</description>
    </item>
    
    <item>
      <title>Nautilus - ukrywanie lost&#43;found</title>
      <link>https://timor.site/2012/10/nautilus-ukrywanie-lostfound/</link>
      <pubDate>Tue, 30 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/10/nautilus-ukrywanie-lostfound/</guid>
      <description>Lubię mieć porządek w folderach i jedna rzecz, która nie daje mi spokoju w systemach plików ext to widoczność folderu lost+found - niby można go skasować i powinien się odtworzyć (choć podobno odtworzenie w czasie fsck&amp;rsquo;a może spowodować utratę danych - trochę to dziwne i nie znalazłem źródła no ale powiedzmy że nie chcę go usuwać). Chciałem go ukryć (choćby w Nautilusie) by mnie nie drażnił. Oczywiście opcja z &amp;ldquo;.&amp;rdquo; na początku odpada, ale na szczęście Nautilus wykorzystuje pewien hack, który umożliwia ukrycie dowolnego pliku/folderu.</description>
    </item>
    
    <item>
      <title>Rolada kokosowo-czekoladowa na zimno</title>
      <link>https://timor.site/2012/10/rolada-kokosowo-czekoladowa-na-zimno/</link>
      <pubDate>Mon, 22 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/10/rolada-kokosowo-czekoladowa-na-zimno/</guid>
      <description>Składniki 1 kostka masła, 1 żółtko, 6 łyżek cukru pudru, 1 szklanka mleka, 10 dkg wiórek kokosowych, 1 kieliszek wódki (ale z dwoma jest ostrzejsze), 3 łyżki kakao, 37 dkg herbatników kakaowych (doskonale spisują się dwie paczki maślanych herbatników kakaowych). Masa kakaowa Herbatniki dokładnie rozwałkować, dodać kakao i wymieszać. Zagotować pół szklanki mleka i gorącym zalać herbatniki. Całość wymieszać na jednolitą masę. W drugim pojemniku rozmiksować pół kostki masła i 3 łyżki cukru pudru - po chwili dodać żółtko i wódkę.</description>
    </item>
    
    <item>
      <title>Utrzymanie przy życiu sypiących się usług na serwerach Windows</title>
      <link>https://timor.site/2012/10/utrzymanie-przy-zyciu-sypiacych-sie-uslug-na-serwerach-windows/</link>
      <pubDate>Mon, 22 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/10/utrzymanie-przy-zyciu-sypiacych-sie-uslug-na-serwerach-windows/</guid>
      <description>Zdarzyło mi się kilka usług działających na serwerach Windows, które zwyczajnie sypały się i to tak brzydko że systemowe ustawienia by restartowały się po padzie nie wystarczały. Usługa działała np. 3 godziny by potem się położyć, albo nigdy nie wstawała po starcie systemu - po prostu jakaś masakra. Zgłoszenia do producenta często wyglądały tak że w jego testowym środowisku błędu nie udaje się powtórzyć (i nic dziwnego bo nie sądzę by z ich konfiguracji korzystali rzeczywiści użytkownicy).</description>
    </item>
    
    <item>
      <title>Piwik - alternatywa dla Google Analytics</title>
      <link>https://timor.site/2012/09/piwik-alternatywa-dla-google-analytics/</link>
      <pubDate>Wed, 26 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/09/piwik-alternatywa-dla-google-analytics/</guid>
      <description>Jeśli szukamy statystyk dla strony internetowej i ze względu na jej zawartość (np. sklep, coś ze zwiększonym naciskiem na poufność etc..) nie potrafimy zaufaj wujkowi Googlowi to warto przyglądnąć się Piwikowi.
Jest to system statystyk aspirujący do bycia Open Source&amp;rsquo;ową alternatywą dla Google Analytics. Aspirujący (a nie będący) z tego względu że Google przechodząc na domyślny HTTPS (SPDY) dla zalogowanych użytkowników uniemożliwił śledzenie stron z których pochodzą odwiedziny (tzw. refferals) - tym prostym sposobem tylko GA jest w stanie dostarczyć pełnych informacji o wszystkich użytkownikach.</description>
    </item>
    
    <item>
      <title>mod_rewrite - wymuszenie małych liter w adresie URL</title>
      <link>https://timor.site/2012/09/mod_rewrite-wymuszenie-malych-liter-w-adresie-url/</link>
      <pubDate>Tue, 25 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/09/mod_rewrite-wymuszenie-malych-liter-w-adresie-url/</guid>
      <description>Co prawda adresy URL pozwalają na stosowanie zarówno dużych jak i małych liter ale różne systemy mogą je różnie obsługiwać i może się trafić sytuacja, w której nie zechcemy by np. duże litery w ogóle pojawiały się w adresach URL. Doskonały przykład to mój niedawny wpis: Apache: ograniczenie dostępu dla zalogowanych użytkowników z mod_rewrite i mod_auth_basic.
Zachodzi tam sytuacja, w której katalog użytkownika jest jego loginem małymi literami (bądź dużymi - jak kto woli), a użytkownik wpisując login może użyć zarówno małych jak i dużych liter i tutaj zaczyna się jazda.</description>
    </item>
    
    <item>
      <title>Aktualizacja Debian Squeeze do Wheezy</title>
      <link>https://timor.site/2012/09/aktualizacja-debian-squeeze-do-wheezy/</link>
      <pubDate>Mon, 24 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/09/aktualizacja-debian-squeeze-do-wheezy/</guid>
      <description>Obecnie dostępna jest już beta 2 Debiana Wheezy i utrzymywane są aktualizacje bezpieczeństwa więc powolutku można na testowych maszynach sprawdzać co i jak się zmieniło.
Ponieważ do finalnej wersji pewnie sporo się jeszcze zmieni to postaram się z czasem aktualizować ten post by zawierał bieżące informacje.
W razie wątpliwości patrz tutaj: http://wiki.debian.org/DebianTesting
Robimy backup Aktualizujemy źródła wskazywały na paczki gałęzi testing (poniższe polecenie nadpisze Twoje obecne repozytoria): cat &amp;gt; /etc/apt/sources.list &amp;lt;&amp;lt;SRC deb http://ftp.</description>
    </item>
    
    <item>
      <title>GPO: Windows 7 - postęp przetwarzania polityk przy starcie systemu</title>
      <link>https://timor.site/2012/09/gpo-windows-7-postep-przetwarzania-polityk-przy-starcie-systemu/</link>
      <pubDate>Thu, 20 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/09/gpo-windows-7-postep-przetwarzania-polityk-przy-starcie-systemu/</guid>
      <description>Dziś TIP z przeciwnego obozu - oprócz linuksowych systemów administruję również paroma serwerami windowsowymi i tutaj również (a czasem nawet bardziej) uda mi się znaleźć coś wartego zapamiętania.
Jedna z najbardziej charakterystycznych rzeczy na komputerach przyłączonych do domeny Windows to wyświetlanie &amp;ldquo;różnych dziwnych rzeczy&amp;rdquo; przy starcie systemu. Zarówno na Windowsie 2000 jak i na XP&amp;rsquo;ku na małym okienku przewijają informacje o aktualizacji polityk, instalacji oprogramowania itp&amp;hellip;
Zachowanie to zmieniło się na Vistach i 7-kach, które są nieco mniej rozmowne i wyświetlają jedynie komunikat typu &amp;ldquo;Trwa uruchamianie systemu&amp;hellip;&amp;rdquo; i tyla&amp;hellip; Załóżmy że wrzucimy do instalacji kilka paczek i jeszcze zmienimy kilka polityk i przez to komputer na tym napisie zatrzyma się na 5~10 minut - co zrobi użyszkodnik po 3 minutach?</description>
    </item>
    
    <item>
      <title>Sprawdzanie nieaktywnych linków na stronie</title>
      <link>https://timor.site/2012/09/sprawdzanie-nieaktywnych-linkow-na-stronie/</link>
      <pubDate>Tue, 18 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/09/sprawdzanie-nieaktywnych-linkow-na-stronie/</guid>
      <description>Gdy administruje się dużymi stronami internetowymi raz na czas np. po większych zmianach w konfiguracji zachodzi potrzeba sprawdzenia czy na stronie nie ma stron prowadzących donikąd. O ile w małych serwisach można samemu szybko przeklikać się przez stronkę to dla starych rozrośniętych serwisów nie jest to takie proste.
Jest kilka narzędzi których można użyć do testowania linków na stronach - każde z nich ma swoje zalety i wady, postaram się je przybliżyć.</description>
    </item>
    
    <item>
      <title>Generator kodów paskowych dla napędów taśmowych LTO</title>
      <link>https://timor.site/2012/09/generator-kodow-paskowych-dla-napedow-tasmowych-lto/</link>
      <pubDate>Tue, 11 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/09/generator-kodow-paskowych-dla-napedow-tasmowych-lto/</guid>
      <description>Jeśli posiadasz napęd taśmowy LTO do archiwizacji/backupu danych to wiesz że bardzo ważne jest opisywanie taśm szczególnie gdy trzeba coś odzyskać. Jeżeli masz szczęście to posiadasz nie pojedynczy napęd a autoloader obsługujący wiele taśm i wiesz że najlepiej gdy taśmy są opisane kodami paskowymi które autoloader potrafi rozpoznać. Dzięki temu nie ma potrzeby odczytywania nr. seryjnego z taśmy tylko szybciutko skanerem kodów. Tasiemki można kupować już z kodami ale tańsze są te bez kodów&amp;hellip; i tu pytanie - czy da się tanio zdobyć etykiety?</description>
    </item>
    
    <item>
      <title>Listowanie zasobów NFS</title>
      <link>https://timor.site/2012/09/listowanie-zasobow-nfs/</link>
      <pubDate>Mon, 10 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/09/listowanie-zasobow-nfs/</guid>
      <description>Szkoda że polecenia do obsługi NFS&amp;rsquo;a nie zaczynają się od nfs* - łatwiej byłoby mi je zapamiętać. A jednym z takich, zapominanych najczęściej jest listowanie zasobów, szczególnie przydatne gdy korzysta się z NFS&amp;rsquo;a na jakimś NAS&amp;rsquo;ie (którego magiczny soft nie pokazuje gdzie i co eksportuje):
showmount -e 192.168.1.10 Export list for 192.168.1.10: /mnt/pools/A/A0/Music * /mnt/pools/A/A0/Movies * /mnt/pools/A/A0/Backups * /mnt/pools/A/A0/Pictures * /mnt/pools/A/A0/Documents * Teraz możemy zamontować zasób:
mount 192.168.1.10:/mnt/pools/A/A0/Music /mnt/music </description>
    </item>
    
    <item>
      <title>Apache: ograniczenie dostępu dla zalogowanych użytkowników z mod_rewrite i mod_auth_basic</title>
      <link>https://timor.site/2012/09/apache-ograniczenie-dostepu-dla-zalogowanych-uzytkownikow-z-mod_rewrite-i-mod_auth_basic/</link>
      <pubDate>Sun, 09 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/09/apache-ograniczenie-dostepu-dla-zalogowanych-uzytkownikow-z-mod_rewrite-i-mod_auth_basic/</guid>
      <description>Niedawno trafiłem na ciekawy problem w mod_rewrite - by przekierowywać użytkowników logujących się jednym z modułów mod_auth_basic do dedykowanych im katalogów, równocześnie blokując dostęp do katalogów innych użytkowników. Nie brzmi to jakoś strasznie ale problem okazał się być całkiem nietrywialnym. Teoretyczne rozwiązanie sprowadzało się do wyszukania loginu użytkownika ze ścieżki URI i porównania z nazwą użytkownika ze zmiennej %{REMOTE_USER} - jeśli wartości się różnią to Forbidden. Ale szybko okazało się że w RewriteCond zmienne z dopasowań można podstawiać tylko w pierwszym parametrze i że o ile można RewriteCond&amp;rsquo;y połączyć wyrażeniami logicznymi typu AND/OR to nie ma możliwości porównania czy dopasowania z kolejnych RewriteCond&amp;rsquo;ów są identyczne.</description>
    </item>
    
    <item>
      <title>unicode-rxvt - moje ustawienia</title>
      <link>https://timor.site/2012/09/unicode-rxvt-moje-ustawienia/</link>
      <pubDate>Sun, 09 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/09/unicode-rxvt-moje-ustawienia/</guid>
      <description>Wybór dobrego X-terminala to w życiu admina prawie jak wybór żony&amp;hellip; spędza się wspólnie dużo czasu i miło gdy estetycznie wygląda, robi to co chcemy, itd&amp;hellip; 😉
Nie lubię gnome-terminal&#39;a bo domyślnie binduje F10 co wnerwia mnie w midnight commanderze, stąd szukałem i szukałem i jak dotychczas najbardziej podpasował mi unicode-rxvt. Można uruchamiać go po prostu jako urxvt lub uruchomić demona urxvtd po zalogowaniu i potem odpalać tylko klienta urxvtc. Druga metoda skutkuje natychmiastowym startem terminala, wiec gdy podbinduję go sobie pod F12 mam terminal zawsze pod ręką w mniej niż sekundę.</description>
    </item>
    
    <item>
      <title>Wymuszenie fsck po restarcie</title>
      <link>https://timor.site/2012/09/wymuszenie-fsck-po-restarcie/</link>
      <pubDate>Sat, 08 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/09/wymuszenie-fsck-po-restarcie/</guid>
      <description>Jeżeli chcemy by po ponownym uruchomieniu w czasie startu zostały sprawdzone wszystkie dyski narzędziem to można to osiągnąć na dwa sposoby. Zawsze gdy tego potrzebuję zastanawiam się tylko jaki plik trzeba było utworzyć&amp;hellip; forcefsck, fsck, fsckforce&amp;hellip; więc notuję 😉
Utworzenie pliku /forcefsck Pierwsza metoda polega na utworzeniu pliku forcefsck w głównym katalog, robimy to poniższym poleceniem:
sudo touch /forcefsck Polecenie shutdown Druga metoda wykorzystuje parametr -F polecenia shutdown ale nie działa na wszystkich dystrybucjach (w takiej sytuacji patrz pierwsza metoda):</description>
    </item>
    
    <item>
      <title>Moje ulubione aplikacje na Android’a</title>
      <link>https://timor.site/2012/09/moje-ulubione-aplikacje-na-androida/</link>
      <pubDate>Fri, 07 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/09/moje-ulubione-aplikacje-na-androida/</guid>
      <description>Znajomi co jakiś czas pytają mnie: jak nazywa się ta aplikacja, którą masz na telefonie do&amp;hellip;? Z jakiego programu do poczty korzystasz na tel&amp;hellip;? itd&amp;hellip;
Pytacie - więc macie 😃
DGT GTD Bardzo przydatna lista TODO. Stworzona z myślą o metodzie Getting Things Done i bardzo ułatwia pamiętanie u różnych zadaniach. Posiada też bardzo wygodny widżet, na którym możemy podglądnąć nasze najbliższe zadania.
Opera Mini Wbudowana przeglądarka jest niezła, ale Opera Mini kompresuje mocno strony wykorzystując pośredniczące serwery proxy co znacznie obniża koszty transmisji danych.</description>
    </item>
    
    <item>
      <title>Montowanie partycji z obrazu dysku</title>
      <link>https://timor.site/2012/09/montowanie-partycji-z-obrazu-dysku/</link>
      <pubDate>Thu, 06 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/09/montowanie-partycji-z-obrazu-dysku/</guid>
      <description>Jedną z rzeczy, które podobają mi się w maszynach wirtualnych Xen jest możliwość zrobienia backupu całego obrazu i szybkie odzyskanie już w trakcie ciężkiej awarii. Gdy dodatkowo korzysta się z LVM&amp;rsquo;a to można na chwilę wyłączyć DomU, utworzyć snapshot jego dysków, uruchomić DomU i w trakcie działania robić spójny backup ze snapshot&amp;rsquo;a. Dzięki takiemu mechanizmowi serwer jest niedostępny przez kilkanaście sekund, a backup spójny jakby został wykonany przy całkowicie wyłączonej maszynie.</description>
    </item>
    
    <item>
      <title>Przeszukiwanie plików danego typu pod kątem tekstu</title>
      <link>https://timor.site/2012/08/przeszukiwanie-plikow-danego-typu-pod-katem-tekstu/</link>
      <pubDate>Fri, 31 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/08/przeszukiwanie-plikow-danego-typu-pod-katem-tekstu/</guid>
      <description>Kiedyś poproszono mnie o przeszukanie wszystkich plików php na serwerze webowym po kątem wywołania pewnej funkcji. Oczywiste wydało mi się użycie rekurencyjnie grep&amp;rsquo;a, więc:
grep -R &amp;#34;JAKAS_FUNKCJA&amp;#34; /var/www/*.php Ale szybko okazało się że grep dopasowuje maskę *.php również do katalogów, więc nie przeszukiwał katalogów które nie kończyły się na .php ehhh&amp;hellip;..
Drugie podejście okazało się trafniejsze - najpierw poleceniem find wyszukuję wszystkie pliki php, a dopiero później grepuję (wypisując nazwę pliku i numer linii):</description>
    </item>
    
    <item>
      <title>Nginx - konfiguracja pod WordPress’a</title>
      <link>https://timor.site/2012/06/nginx-konfiguracja-pod-wordpressa/</link>
      <pubDate>Fri, 29 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/06/nginx-konfiguracja-pod-wordpressa/</guid>
      <description>To raczej nie jest podstawowy konfig i próżno szukać go na stronie WordPress&amp;rsquo;a, więc odradzam tę zabawę jeśli nie zna się zbyt dobrze nginx&amp;rsquo;a.
Ponieważ serwerek, na którym działa stronka to sprzęcik z Atomem 330 i mocy na CPU zbyt wiele nie ma to popularne pluginy (np. W3 Total Cache) potencjalnie zwiększające wydajność tak na prawdę zmulały stronkę jeszcze bardziej. Pluginów sprawdziłem kilka i każdorazowo efekt był podobny - stronka działała wolniej niż bez ich pomocy.</description>
    </item>
    
    <item>
      <title>Xen - Podstawowe polecenia</title>
      <link>https://timor.site/2012/06/xen-podstawowe-polecenia/</link>
      <pubDate>Tue, 19 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/06/xen-podstawowe-polecenia/</guid>
      <description>Pisałem już HOWTO o konfiguracji Xen&amp;rsquo;a ale nie opisałem jak się bawić wirtualkami gdy Xen&amp;rsquo;a już mamy. To nadrabiam.
Tworzenie i usuwanie maszyn wirtualnych Do tworzenia/niszczenia DomU wykorzystuję pakiet xen-tools dostarczający m.in. dwa narzędzia:
xen-create - dla którego przygotowałem dość skomplikowaną konfigurację przy okazji wcześniejszego posta: Instalacja i konfiguracja DomU. Przykład użycia: xen-create --hostname example-domu --ip 10.0.0.77 \ --gateway 10.0.0.1 --broadcast 10.0.0.255 --netmask 255.255.255.0 \ --bridge br10 --vcpus 2 --memory=2G xen-delete-image - narzędzie do kasowania wirtualnych maszyn.</description>
    </item>
    
    <item>
      <title>Nginx - ustawienie domyślnego vhosta</title>
      <link>https://timor.site/2012/06/nginx-ustawienie-domyslnego-vhosta/</link>
      <pubDate>Mon, 18 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/06/nginx-ustawienie-domyslnego-vhosta/</guid>
      <description>Ustawienie domyślnego vhosta w nginx&amp;rsquo;ie jest ładnie opisane w dokumentacji i początkowo wydawało się dobrze działać ale gdy wykorzystałem tą konfigurację na serwerze z wieloma adresami IP i nasłuchiwaniem na porcie 80 (bez podania IP) to zachowywało się to dość dziwnie (przeważnie nie ładowało tej strony którą chciałem). Od teraz tworzę konfigurację domyślnego vhosta dla każdego z dostępnych adresów IP. Powiem szczerze że nie miałem czasu na głębsze zbadanie tego zachowania i wykorzystałem rozwiązanie, które działało w każdym przypadku czyli po jednym konfigu na IP + przekierowanie na ogólną stronę.</description>
    </item>
    
    <item>
      <title>Xen - Konfiguracja interfejsu sieciowego Dom0 jako brdige’a dla VLAN’ów</title>
      <link>https://timor.site/2012/06/xen-konfiguracja-interfejsu-sieciowego-dom0-jako-brdigea-dla-roznych-vlanow/</link>
      <pubDate>Mon, 18 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/06/xen-konfiguracja-interfejsu-sieciowego-dom0-jako-brdigea-dla-roznych-vlanow/</guid>
      <description>VLAN&amp;rsquo;y są prostą metodą na separację sieci. Gdy mamy wiele sieci może zajść potrzeba by poszczególne DomU miały dostęp do różnych VLAN&amp;rsquo;ów (czasem nawet wielu równocześnie). Jeżeli serwer z Dom0 posiada minimum giga-bitową kartę sieciową (a najlepiej kilka) to powinniśmy być w stanie z godziwą jakością udostępnić systemom DomU różne VLAN&amp;rsquo;y z interfejsów gospodarza.
Zaprezentowane poniżej skrypty zapożyczyłem z tej strony: http://renial.net/weblog/2007/02/27/xen-vlan
Na początek musimy zainstalować pakiet vlan:
apt-get install vlan Później w pliku /etc/xen/xend-config.</description>
    </item>
    
    <item>
      <title>Apache - reverse proxy z cache’owaniem</title>
      <link>https://timor.site/2012/06/apache-reverse-proxy-z-cacheowaniem/</link>
      <pubDate>Sun, 17 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/06/apache-reverse-proxy-z-cacheowaniem/</guid>
      <description>Ostatnio trafiłem na ciekawy problem, który wielokrotnie rozwiązywałem w nginx&amp;rsquo;ie ale tym razem musiałem zrobić to w Apache. Pewna stronka działa sobie na HTTPS&amp;rsquo;ie i chciałem by wszystkie powiązane z nią pliki były serwowane z jej adresu szyfrowanym połączeniem by nie pojawiały się w przeglądarce monity że &amp;ldquo;część ruchu nie jest szyfrowana&amp;rdquo;. Tyle że część potrzebnych plików była już obecnie serwowana na innym serwerze (w innej domenie) poprzez HTTP.
Mogłem albo skopiować te pliki i wykombinować jakiś mechanizm synchronizujący albo wykorzystać proxy + cache.</description>
    </item>
    
    <item>
      <title>CouchDB - Instalacja i wstępna konfiguracja</title>
      <link>https://timor.site/2012/06/couchdb-instalacja-i-wstepna-konfiguracja/</link>
      <pubDate>Fri, 08 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/06/couchdb-instalacja-i-wstepna-konfiguracja/</guid>
      <description>Gdy tworzymy pierwszą aplikację webową, która umożliwia upload plików przeważnie lądują one lokalnie w pewniej lokalizacji. Gdy druga aplikacja potrzebuje dostępu do tych plików wystarczy podać ścieżkę. Problemy zaczynają się gdy aplikacji jest kilka i rozmieszczonych na kilku serwerach. Można korzystać z sieciowych systemów plików ale to często nie jest zbyt wygodne - ciężko odpowiednio ustawić uprawnienia by pewne aplikacje miały dostęp do zapisu plików a inne nie, trzeba skonfigurować dany katalog w kilku miejscach w konfiguracji serwera WWW aby serwować pliki itp&amp;hellip;</description>
    </item>
    
    <item>
      <title>Dynamiczna zmiana rozmiaru partycji EXT4 na LVM’ie</title>
      <link>https://timor.site/2012/06/dynamiczna-zmiana-rozmiaru-partycji-ext4-na-lvmie/</link>
      <pubDate>Fri, 08 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/06/dynamiczna-zmiana-rozmiaru-partycji-ext4-na-lvmie/</guid>
      <description>Używam LVM&amp;rsquo;a zarówno na desktopie jak i wielu serwerach bo bardzo podoba mi się możliwość powiększenia akurat tej partycji, na której brakuje miejsca. O ile pamiętam jak powiększyć partycję XFS (xfs_growfs /punkt/montowania) to zawsze mam problem jak to zrobić na EXT3/4, więc notuję.
Powiększenie wolumenu LVM (np. o 10 gigabajtów):
lvextend -L+10G /dev/vggroup/vol Zwiększenie rozmiaru systemu plików do nowego rozmiaru wolumenu:
resize2fs /dev/vggroup/vol Powyższe polecenie można wykonać na zamontowanym zasobie - online.</description>
    </item>
    
    <item>
      <title>Nginx - mój domyślny config</title>
      <link>https://timor.site/2012/06/nginx-moj-domyslny-config/</link>
      <pubDate>Fri, 08 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/06/nginx-moj-domyslny-config/</guid>
      <description>W tym poście nie rozpiszę się zbytnio - wrzucam tylko config od którego zaczynam konfigurację nginx&amp;rsquo;a.
user www-data; worker_processes 4; pid /var/run/nginx.pid; events { worker_connections 1024; ## zaakceptuj tak dużo połączeń jak to możliwe multi_accept on; ## epoll jest preferowany na jajkach od 2.6 ## http://www.kegel.com/c10k.html#nb.epoll use epoll; } http { include /etc/nginx/mime.types; default_type application/octet-stream; access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; ## opcje TCP sendfile on; tcp_nopush on; tcp_nodelay on; ## maksymalny rozmiar zapytnia client_max_body_size 10m; ## timeout&amp;#39;y client_body_timeout 60; client_header_timeout 60; keepalive_timeout 10; send_timeout 60; ## kompresja gzip on; gzip_static on; gzip_vary on; gzip_disable &amp;#34;msie6&amp;#34;; gzip_comp_level 1; gzip_proxied any; gzip_buffers 16 8k; gzip_min_length 50; gzip_types text/plain text/css application/json application/x-javascript application/javascript text/javascript application/atom+xml application/xml application/xml+rss text/xml image/x-icon text/x-js application/xhtml+xml; ## bezpieczeństwo ## security by obscurity - ukrywamy wersję nginx&amp;#39;a server_tokens off; ignore_invalid_headers on; ## resetuj zbyt długie połączenia - powinno pomóc na slowlorisa reset_timedout_connection on; ## włączenie ochrony przed clickjackingiem - uruchamiam to per vhost ## https://developer.</description>
    </item>
    
    <item>
      <title>Fortigate: Warning: SQL Logging is not enabled</title>
      <link>https://timor.site/2012/04/fortigate-warning-sql-logging-is-not-enabled/</link>
      <pubDate>Wed, 11 Apr 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/04/fortigate-warning-sql-logging-is-not-enabled/</guid>
      <description>Jeśli po aktualizacji firmware na swoim firewall&amp;rsquo;u do wersji MR3 natrafisz na komunikat Warning: SQL Logging is not enabled przy dostępie do logów to prawdopodobnie musisz zmienić źródło logów dla interfejsu gui. Poniżej polecenie CLI i możliwe opcje:
config log gui set logdevice {memory | disk | fortianalyzer} end Ja potrzebowałem ustawić tę opcję na fortianalyzer by uzyskać dostęp do moich logów.</description>
    </item>
    
    <item>
      <title>Konwersja formatu certyfikatu dla telefonów Nokia</title>
      <link>https://timor.site/2012/04/konwersja-formatu-certyfikatu-dla-telefonow-nokia/</link>
      <pubDate>Wed, 11 Apr 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/04/konwersja-formatu-certyfikatu-dla-telefonow-nokia/</guid>
      <description>Chciałem zaimportować mój certyfikat self-signed do Nokii E72 by nie krzyczała przy sprawdzaniu poczty. Potrzebowałem certyfikatu w formacie DER, a miałem w PEM - chwilę szukałem jak dokonać konwersji, więc ku pamięci zapisuję kilka gotowych poleceń:
Konwersja certyfikatu z PEM na DER openssl x509 -in in.crt -inform PEM -out out.crt -outform DER Konwersja certyfikatu z DER na PEM openssl x509 -in in.crt -inform DER -out out.crt -outform DER Konwersja klucza z formatu PEM na DER openssl rsa -in in.</description>
    </item>
    
    <item>
      <title>Ponowne wygenerowanie kluczy serwera OpenSSH</title>
      <link>https://timor.site/2012/02/ponowne-wygenerowanie-kluczy-serwera-openssh/</link>
      <pubDate>Mon, 27 Feb 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/02/ponowne-wygenerowanie-kluczy-serwera-openssh/</guid>
      <description>Czasami odpalam klona jakiegoś systemu by później po drobnych zmianach uczynić go osobnym bytem. Jednym z kroków po odtworzeniu systemu jest wygenerowanie nowego zestawu kluczy dla serwera OpenSSH (by mój klient ssh nie siał warning&amp;rsquo;ami). Można to wykonać tak:
Najpierw kasujemy obecne klucze:
rm /etc/ssh/ssh_host_* Teraz generujemy nowe:
dpkg-reconfigure openssh-server I na koniec restartujemy usługę by załadować nowy zestaw kluczy (nie powinno to zerwać obecnej sesji, ale dla pewności lepiej zadanie odpalić w screen&amp;rsquo;ie):</description>
    </item>
    
    <item>
      <title>Xen - ustawienie autostartu DomU</title>
      <link>https://timor.site/2012/02/xen-ustawienie-autostartu-domu/</link>
      <pubDate>Mon, 27 Feb 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/02/xen-ustawienie-autostartu-domu/</guid>
      <description>Aby wybrane systemy DomU startowały automatycznie po restarcie hypervisora należy podlinkować ich pliki konfiguracyjne w katalogu /etc/xen/auto po uprzednim jego utworzeniu. Przykładowo:
mkdir /etc/xen/auto ln -s /etc/xen/example.cfg /etc/xen/auto/example.cfg Od teraz DomU example będzie startować automatycznie.</description>
    </item>
    
    <item>
      <title>Xen - Włączenie Live Migration</title>
      <link>https://timor.site/2012/02/xen-wlaczenie-live-migration/</link>
      <pubDate>Sat, 25 Feb 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/02/xen-wlaczenie-live-migration/</guid>
      <description>Jeżeli zdecydowaliśmy się na systemu DomU w obrazach to możemy korzystać z live migration. By uruchomić jej obsługę, trzeba w pliku /etc/xen/xend-config.sxp odkomentować odpowiednie linie i ustawić adres IP:
(xend-relocation-server yes) (xend-relocation-port 8002) (xend-relocation-address &amp;#39;10.0.10.91&amp;#39;) Wykonywanie migracji xm migrate --live nazwa-domu nazwa.lub.ip.zdalnego.hosta </description>
    </item>
    
    <item>
      <title>Xen na Squeeze - Instalowanie i konfiguracja hostów gości (DomU)</title>
      <link>https://timor.site/2012/02/xen-na-squeeze-instalowanie-i-konfiguracja-hostow-gosci-domu/</link>
      <pubDate>Fri, 24 Feb 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/02/xen-na-squeeze-instalowanie-i-konfiguracja-hostow-gosci-domu/</guid>
      <description>Ostatnio pisałem o konfiguracji Dom0 - dzisiaj napiszę o uruchamianiu DomU.
Do instalacji DomU wykorzystuję skrypty z pakietu xen-tools, można go zainstalować poleceniem:
apt-get install xen-tools Oczywiście aby wszystko działało fajnie musimy ustawić kilka domyślnych opcji, robimy to edytując plik /etc/xen-tools/xen-tools.conf. Lecimy po kolei:
# Virtual machine disks are created as logical volumes in # volume group &amp;#39;universe&amp;#39; (hint: LVM storage is much faster # than file) lvm = universe Osobiście korzystam z LVM&amp;rsquo;a który zgodnie z hint&amp;rsquo;em jest znacznie szybszy od plików obrazów.</description>
    </item>
    
    <item>
      <title>Kaczka pieczona z żurawiną i jabłkami</title>
      <link>https://timor.site/2012/02/kaczka-pieczona-z-zurawina-i-jablkami/</link>
      <pubDate>Thu, 23 Feb 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/02/kaczka-pieczona-z-zurawina-i-jablkami/</guid>
      <description>Bardzo udany przepis - gdzieś musiałem go udokumentować by nie zginął :)
Składniki 1 duża kaczka (2-2,5 kg) 4 ząbki czosnku 1 kg jabłek (w zależności od kaczki mogą wystarczyć 3 większe sztuki) sok z cytryny do skropienia jabłek 200 g suszonej żurawiny pół butelki czerwonego wytrawnego wina rozmaryn 4 łyżki miodu cynamon kardamon sól pieprz Sposób wykonania Kaczkę nacieramy solą, pieprzem, rozmarynem oraz roztartym czosnkiem i pozostawiamy na min. 3-4 godziny w lodówce (można też przygotować ją wieczorem by była gotowa na następny dzień).</description>
    </item>
    
    <item>
      <title>Xen na Squeeze - instalacja i konfiguracja hypervisor’a</title>
      <link>https://timor.site/2012/02/xen-na-squeeze-instalacja-i-konfiguracja-hypervisora/</link>
      <pubDate>Thu, 23 Feb 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/02/xen-na-squeeze-instalacja-i-konfiguracja-hypervisora/</guid>
      <description>Po co mi to? Wiele razy miałem do czynienia z serwerami na których działało kilka/kilkanaście usług równocześnie, np. Apache (kilka stronek, webmail, phpmyadmin, itp), Postfix/Exim (poczta i żeby było fajnie to na kontach systemowych), Samba (jakieś zasoby dla pracowników), MySQL (baza dla stronek), PostgreSQL (bo jedna stronka potrzebowała), itd&amp;hellip;. Przy takiej konfiguracji pomijane są kwestie separacji usług zewnętrznych/wewnętrznych - no ale firma/instytucja mała nie ma sensu kasy na 3 kolejne serwery wydawać skoro działa&amp;hellip;.</description>
    </item>
    
    <item>
      <title>Wstępne ładowanie programów przy starcie z ureadahead</title>
      <link>https://timor.site/2012/01/wstepne-ladowanie-programow-przy-starcie-z-ureadahead/</link>
      <pubDate>Tue, 24 Jan 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/01/wstepne-ladowanie-programow-przy-starcie-z-ureadahead/</guid>
      <description>Jakiś czas temu korzystałem z preload&amp;rsquo;a który sam uczył się jakie aplikacje odpalam i te programy ładował już podczas startu - przeważnie nieco spowalnia to start systemu ale gdy już się załaduje to programy, które uruchamiam jako pierwsze startują &amp;ldquo;z kopa&amp;rdquo;. Od jakiegoś czasu popularniejszy jest instalowany domyślnie w Ubuntu ureadahead - pełni on podobną funkcję jak preload.
Można zmusić ureadahead do ponownego wygenerowania nowej listy programów wczytywanych przy starcie do cache a oto jak zrobić:</description>
    </item>
    
    <item>
      <title>Apache mod_expires konfiguracja</title>
      <link>https://timor.site/2012/01/apache-mod_expires-konfiguracja/</link>
      <pubDate>Mon, 23 Jan 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/01/apache-mod_expires-konfiguracja/</guid>
      <description>Aby umożliwić odwiedzającym nasze strony cachowanie obrazków (tak by nie musieli pobierać ich każdorazowo bo przecież nie zmieniają się aż tak często) konieczne jest ustawienie nagłówków: Cache-Control, Expires dla odpowiednich typów plików. W Apachem jest do tego dedykowany moduł - mod_expires. W Debianie dostarczany jest on bez domyślnej globalnej konfiguracji - a ja lubię gdy cacheuje mi się większość statyki. Zawsze można dostosować czas cachowania pod siebie względem określonego typu pliku, np.</description>
    </item>
    
    <item>
      <title>Długie oczekiwanie na nawiązanie połączenia ssh</title>
      <link>https://timor.site/2012/01/dlugie-oczekiwanie-na-nawiazanie-polaczenia-ssh/</link>
      <pubDate>Mon, 23 Jan 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/01/dlugie-oczekiwanie-na-nawiazanie-polaczenia-ssh/</guid>
      <description>Objaw przeważnie jest taki: łączysz się po ssh podając klucz/hasło i czekasz nawet i 10 sekund aż pojawi się prompt. Po połączeniu wszystkie polecenia działają z normalną szybkością. Brzmi znajomo? 😉
Taki objaw przeważnie jest skutkiem problemów z działaniem DNS&amp;rsquo;a po stronie klienta lub serwera. Warto sprawdzić poleceniami host/dig/nslookup po obu stronach jak dużo czasu potrzeba na rozwiązanie nazw. Najlepiej rozwiązać problem z DNS&amp;rsquo;em ustawiając szybkie serwery ale gdy nie mamy takiej możliwości to po stronie serwera można ustawić w /etc/sshd_config opcję:</description>
    </item>
    
    <item>
      <title>Sniffowanie w FortiOS</title>
      <link>https://timor.site/2012/01/sniffowanie-w-fortios/</link>
      <pubDate>Mon, 23 Jan 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/01/sniffowanie-w-fortios/</guid>
      <description>Zawsze gdy potrzebuję zesniffować coś na żywo na Fortigate&amp;rsquo;ach muszę przeszukać Knowledge Base by przypomnieć sobie wszystkie polecenia do tego potrzebne. Tym razem robię notatki 😃
Sniffowanie diagnose debug enable diagnose debug flow filter addr ip address clear clear filter daddr dest ip address dport destination port negate inverse filter port port proto protocol number saddr source ip address sport source port vd index of virtual domain # np. diagnose debug flow filter saddr 10.</description>
    </item>
    
    <item>
      <title>Upgrade Debian Lenny do Squeeze</title>
      <link>https://timor.site/2012/01/upgrade-debian-lenny-do-squeeze/</link>
      <pubDate>Fri, 13 Jan 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/01/upgrade-debian-lenny-do-squeeze/</guid>
      <description>Co jakiś czas powtarza się sytuacja, gdy muszę zaktualizować jakiś serwerek z Lennym do Squeeze&amp;rsquo;a i za każdym razem muszę googlać za odpowiednimi źródłami, które paczki najpierw, etc&amp;hellip; Więc sobie zebrałem wszystko w poniższym poście.
W razie wątpliwości patrz tutaj: http://www.debian.org/releases/squeeze/releasenotes
Zrób backup konfiguracji.
Trzeba zaktualizować źródła by wskazywały na squeeze&amp;rsquo;a (poniższe polecenie nadpisze Twoje obecne repozytoria):
cat &amp;gt; /etc/apt/sources.list &amp;lt;&amp;lt;SRC deb http://ftp.pl.debian.org/debian/ squeeze main non-free contrib deb-src http://ftp.pl.debian.org/debian/ squeeze main non-free contrib deb http://security.</description>
    </item>
    
    <item>
      <title>Skoda Fabia - Kasownie ostrzeżeń OIL i service INSP</title>
      <link>https://timor.site/2012/01/skoda-fabia-kasownie-ostrzezen-oil-i-service-insp/</link>
      <pubDate>Thu, 12 Jan 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/01/skoda-fabia-kasownie-ostrzezen-oil-i-service-insp/</guid>
      <description>Jeżeli jesteś właścicielem Skody Fabii I to wcześniej czy później Twój BAT-Mobil zgłosi któreś z ostrzeżeń serwisowych:
OIL - pojawia się przeważnie co 10 tys. km i wtedy gdy jeszcze nie trzeba wymieniać oleju w silniku 😄 service INSP - nie wiem jak często się pojawia a oznacza mniej więcej &amp;ldquo;czas wesprzeć finansowo lokalny autoryzowany serwis&amp;rdquo;. Kasowanie ostrzeżenia &amp;ldquo;OIL&amp;rdquo; Przy wyłączonym silniku wciskamy i przytrzymujemy przycisk kasowania przebiegu dziennego/pokrętło ustawiania godziny, od teraz nazywany po prostu &amp;lsquo;przyciskiem&amp;rsquo;.</description>
    </item>
    
    <item>
      <title>Mój domyślny config dla SciTE</title>
      <link>https://timor.site/2012/01/moj-domyslny-config-dla-scite/</link>
      <pubDate>Wed, 11 Jan 2012 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2012/01/moj-domyslny-config-dla-scite/</guid>
      <description>Uruchamiamy SciTE i klikamy menu Options -&amp;gt; Open User Options File, wpisujemy dane:
# domyślne korzystanie z fontów o stałej szerokości font.base=$(font.monospace) font.small=$(font.monospace) font.comment=$(font.monospace) font.text=$(font.monospace) font.text.comment=$(font.monospace) font.embedded.base=$(font.monospace) font.embedded.comment=$(font.monospace) font.vbs=$(font.monospace) # numerowanie wierszy line.margin.visible=1 line.margin.width=3+ # ikonki toolbara z tematu systemowego toolbar.usestockicons=1 # zaznaczanie blokowe rectangular.selection.modifier=8 # ustawienia wgłębień kodu indent.size=4 use.tabs=1 indent.automatic=1 Więcej opcji tutaj: http://www.scintilla.org/SciTEDoc.html
Sam pewnie jeszcze nie raz zaktualizuję ten wpis 😄</description>
    </item>
    
    <item>
      <title>Empathy - zamykanie okienka chatu przyciskiem Escape</title>
      <link>https://timor.site/2011/12/empathy-zamykanie-okienka-chatu-przyciskiem-escape/</link>
      <pubDate>Fri, 30 Dec 2011 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2011/12/empathy-zamykanie-okienka-chatu-przyciskiem-escape/</guid>
      <description>W Gajim&amp;rsquo;ie od dawna brakowało mi wygodnego przeszukiwania po liście kontaktów (takiego jakie ma się pojawić już niebawem w wersji 0.15 - z półtora roku już na to czekam&amp;hellip;). W między czasie znalazłem chwilę by pobawić się Empathy - brzydki, nie ma przeglądarki usług XMPP, ale wyszukiwanie na rosterze jest dokładnie takie jakiego szukałem (w miarę wpisywania znaków zawęża listę kontaktów by pasowały do wpisywanego wzorca).
Tyle że skróty klawiaturowe w tym programie zwyczajnie mnie rozwalają - przez lata przyzwyczaiłem się że okienka czatu można zamknąć Escape&amp;rsquo;m - a tutaj nawet nie ma opcji, która pozwalała by na taką zmianę zachowania.</description>
    </item>
    
    <item>
      <title>Automatyczne backupy w stylu snapshot z rsync’iem</title>
      <link>https://timor.site/2011/12/automatyczne-backupy-w-stylu-snapshot-z-rsynciem/</link>
      <pubDate>Thu, 29 Dec 2011 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2011/12/automatyczne-backupy-w-stylu-snapshot-z-rsynciem/</guid>
      <description>Można znaleźć wiele tutoriali jakimi narzędziami wykonywać backupy. W większości przypadków absolutnie wystarczający okaże się flexbackup. Bardziej wymagający wykorzystają BackupPC, Baculę lub Amandę. Narzędzia te pozwalają wykonać kopie pełne, różnicowe, przyrostowe - kompresując je dla zaoszczędzenia miejsca.
Wszystko fajnie - ale problemy pojawiają się przy dostępie do tych danych. Żeby odzyskać plik zmodyfikowany dzisiaj trzeba rozpakować najpierw kopię pełną, potem różnicową, przyrostową by wreszcie wyciągnąć plik z wczoraj&amp;hellip; hmm ten też jest skopany.</description>
    </item>
    
    <item>
      <title>Konfiguracja modemu USB iPlus na urządzeniach FortiGate</title>
      <link>https://timor.site/2011/12/konfiguracja-modemu-usb-iplus-na-urzadzeniach-fortigate/</link>
      <pubDate>Thu, 29 Dec 2011 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2011/12/konfiguracja-modemu-usb-iplus-na-urzadzeniach-fortigate/</guid>
      <description>Zdarzyło mi się bawić sprzętowymi Firewallami firmy Fortigate - chcąc sprawdzić działanie pewnych funkcji potrzebowałem uruchomić dwa/trzy pudełka na osobnych łączach. Pomysł polegał na próbie zmuszenia pudełek do współpracy z modemem iPlus na USB.
Drugim fajnym zastosowaniem tego triku jest możliwość wykorzystania iPlusa jako &amp;ldquo;zapasowego łącza&amp;rdquo; w przypadku awarii głównego.
Dzięki pomocy inżyniera Fortigate szybko udało mi się zebrać potrzebne do działania parametry, które należy uruchomić poprzez command line (telnet/ssh).</description>
    </item>
    
    <item>
      <title>MySQL - Proste metody optymalizacji</title>
      <link>https://timor.site/2011/12/mysql-proste-metody-optymalizacji/</link>
      <pubDate>Thu, 29 Dec 2011 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2011/12/mysql-proste-metody-optymalizacji/</guid>
      <description>Wcześniej czy później zawsze pojawia się potrzeba zoptymalizowania naszej bazy MySQL. Przedstawię kilka zmian w konfiguracji, które powinny zwiększyć wydajność w większości przypadków.
MyISAM - key_buffer_size Najprostszą optymalizacją baz/tabel z mechanizmem MyISAM jest odpowiednie dobranie bufora na cache dla kluczy i indeksów (dane nigdy nie są cachowane). Poniższe zapytanie pozwala oszacować zalecany rozmiar cache&amp;rsquo;u:
SELECT CONCAT(ROUND(KBS/POWER(1024, IF(PowerOf1024&amp;lt;0,0,IF(PowerOf1024&amp;gt;3,0,PowerOf1024)))+0.4999), SUBSTR(&amp;#39; KMG&amp;#39;,IF(PowerOf1024&amp;lt;0,0, IF(PowerOf1024&amp;gt;3,0,PowerOf1024))+1,1)) recommended_key_buffer_size FROM (SELECT LEAST(POWER(2,32),KBS1) KBS FROM (SELECT SUM(index_length) KBS1 FROM information_schema.</description>
    </item>
    
    <item>
      <title>fail2ban - regułki dla dovecot’a</title>
      <link>https://timor.site/2011/11/fail2ban-regulki-dla-dovecota/</link>
      <pubDate>Mon, 28 Nov 2011 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2011/11/fail2ban-regulki-dla-dovecota/</guid>
      <description>Domyślna konfiguracja fail2ban&amp;rsquo;a (na Debianie) nie zawiera reguł pozwalających na blokowanie prób włamań na skrzynki POP/IMAP dla dovecota (no chyba że korzystamy z saslauthd). Można szybko utworzyć własny zestaw filtrów co przedstawię poniżej.
Tworzymy plik: /etc/fail2ban/filter.d/dovecot.conf
[Definition] failregex = (?: pop3-login|imap-login): .*(?:Authentication failure|Aborted login \(auth failed|Aborted login \(tried to use disabled|Disconnected \(auth failed|Aborted login \(\d+ authentication attempts).*rip=(?P&amp;lt;host&amp;gt;\S*),.* ignoreregex = Później dopisujemy na końcu pliku: /etc/fail2ban/jail.conf
[dovecot] enabled = true filter = dovecot port = pop3,pop3s,imap,imaps logpath = /var/log/mail.</description>
    </item>
    
    <item>
      <title>X-Forwarded-For &#43; mod_rpaf - logowanie rzeczywistych adresów IP na Apache za reverse proxy</title>
      <link>https://timor.site/2011/11/x-forwarded-for-mod_rpaf-logowanie-rzeczywistych-adresow-ip-na-apache-za-reverse-proxy/</link>
      <pubDate>Mon, 28 Nov 2011 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2011/11/x-forwarded-for-mod_rpaf-logowanie-rzeczywistych-adresow-ip-na-apache-za-reverse-proxy/</guid>
      <description>Gdy już ustawimy reverse proxy przed Apache szybko można zauważyć że w logach zamiast adresów IP zdalnych użytkowników pojawia się tylko jeden adres: adres naszego proxy. Również z poziomu php&amp;rsquo;a jako adres klienta widać IP naszego proxy.
By poradzić sobie z tym problemem trzeba na serwerze reverse proxy ustawić przekazywanie informacji o oryginalnym adresie IP klienta w nagłówku X-Forwarded-For. W przypadku gdy reverse proxy działa na nginx&amp;rsquo;e wystarczy dodać taki wpis:</description>
    </item>
    
    <item>
      <title>Porównanie optymalizatorów PHP - eAccelerator, PHP APC, XCache</title>
      <link>https://timor.site/2011/11/porownanie-optymalizatorow-php-eaccelerator-php-apc-xcache/</link>
      <pubDate>Wed, 02 Nov 2011 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2011/11/porownanie-optymalizatorow-php-eaccelerator-php-apc-xcache/</guid>
      <description>Przez pewien czas korzystałem z eAcceleratora do przyspieszenia działania stron pisanych w PHP&amp;rsquo;ie ale czasem bywał niestabilny. Aktualizacje pojawiały się rzadko a od czasu do czasu miewałem problemy ze stabilnością tej wtyczki na kilku bardziej skomplikowanych aplikacjach. Zdarzało się że pomimo zmiany kodu w skrypcie php, eAccelerator serwował wciąż stary plik - konieczny był restart Apache&amp;rsquo;go by wszystko działało jak trzeba.
Zacząłem szukać alternatywy i trafiłem na dwa moduły:
APC (czyli Alternative PHP Cache), który ma być nawet domyślnie wbudowany w PHP od wersji 5.</description>
    </item>
    
    <item>
      <title>SLES 11 - instalacja Service Pack’a</title>
      <link>https://timor.site/2011/10/sles-11-instalacja-service-packa/</link>
      <pubDate>Thu, 20 Oct 2011 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2011/10/sles-11-instalacja-service-packa/</guid>
      <description>Administrowałem do tej pory głównie darmowymi distro, ale gdzieś tam ukradkiem wkradło się kilka &amp;ldquo;siusiaków&amp;rdquo; (aka SUSE Linux Enterprise Server). Żyłem w utopijnym przekonaniu że skoro się za nie płaci to powinno się z nimi łatwiej współpracować&amp;hellip; w przypadku instalacji aktualizacji (a w szczególności SP) nie było to aż takie proste.
Przywykłem w darmowych dystrybucjach że gdy pojawiała się nowszą &amp;ldquo;większa wersja&amp;rdquo; to po prostu można było jednym poleceniem zaktualizować wszystkie pakiety.</description>
    </item>
    
    <item>
      <title>Ochrona usług przed atakami brute force z fail2ban’em</title>
      <link>https://timor.site/2011/10/ochrona-uslug-przed-atakami-brute-force-z-fail2banem/</link>
      <pubDate>Mon, 03 Oct 2011 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2011/10/ochrona-uslug-przed-atakami-brute-force-z-fail2banem/</guid>
      <description>Bardzo często konfigurując usługi dostępne publicznie poświęca się sporo czasu na maksymalne zwiększenie bezpieczeństwa przez &amp;ldquo;dopieszczanie&amp;rdquo; konfiguracji (certyfikaty z mocnym szyfrowaniem, ochronę pewnych stron hasłem, dostęp do SSH tylko kluczami, itd.) ale całkowicie pomija się przygotowanie systemu aktywnie monitorującego błędne próby autoryzacji. Oczywiście nie można umniejszać wagi pierwszego z wymienionych etapów ale zdecydowanie nie powinno pomijać się też tego drugiego. Przecież każdy admin chciałby wiedzieć gdy ktoś próbuje włamać się na jego serwer (FTP, HTTP, SSH, itp.</description>
    </item>
    
    <item>
      <title>pflogsumm - statystyki poczty dla postfix’a</title>
      <link>https://timor.site/2011/09/pflogsum-statystyki-poczty-dla-postfixa/</link>
      <pubDate>Thu, 22 Sep 2011 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2011/09/pflogsum-statystyki-poczty-dla-postfixa/</guid>
      <description>Jeżeli administrujesz nawet niedużym serwerem pocztowym na pewno masz świadomość, że nie jesteś w stanie monitorować logów na bieżąco. Ciężko jest wyłapać np. problem w komunikacji z pewną domeną. Ciężko też oszacować skalę ruchu na serwerze zarówno pod kątem ilości jak i wolumenu maili. Trudno wybrać domeny, dla których warto by zrezygnować z greylistingu, itd, itp&amp;hellip;
Na szczęście dostępne jest narzędzie pflogsumm, które wygeneruje nam dość wyczerpujące statystyki z logów postfix&amp;rsquo;a.</description>
    </item>
    
    <item>
      <title>fsck.ext4 - Błąd podczas przydzielania struktury icount: Memory allocation failed</title>
      <link>https://timor.site/2011/09/fsck-ext4-blad-podczas-przydzielania-struktury-icount-memory-allocation-failed/</link>
      <pubDate>Wed, 21 Sep 2011 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2011/09/fsck-ext4-blad-podczas-przydzielania-struktury-icount-memory-allocation-failed/</guid>
      <description>Miałem ostatnio dziwną przygodę: pewien serwer do backupu gdzie ląduje dużo małych plików i dodatkowo tworzonych jest sporo hardlinków zaliczył pada. Co prawda starałem się go grzecznie położyć z pomocą Magic SysRq ale ponieważ nie wiedziałem co było przyczyną awarii fsck wydawał się wskazany.
Podczas próby uruchomienia fsck.ext4 na systemie plików o rozmiarze ok 14TB z kilkuset milionami plików po kilkudziesięciu sekundach otrzymywałem komunikat:
Błąd podczas przydzielania struktury icount: Memory allocation failed</description>
    </item>
    
    <item>
      <title>Magic SysRq - bezpieczny reset Linux’a</title>
      <link>https://timor.site/2011/09/magic-sysrq-bezpieczny-reset-linuxa/</link>
      <pubDate>Sat, 17 Sep 2011 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2011/09/magic-sysrq-bezpieczny-reset-linuxa/</guid>
      <description>Pomimo iż Linux uchodzi za stabilne środowisko to raz na jakiś czas trafi się ciężka zwiecha - z powodu przeciążenia, awarii sprzętu&amp;hellip; nieistotne&amp;hellip;
Załóżmy że licho wzięło za cel główny serwer plików lub bazę danych dla wielu, wielu stron internetowych. Dostać się po ssh nie możemy bo lecą timeout&amp;rsquo;y, a siedząc bezpośrednio przy klawiaturze konsola nie reaguje. Mimo to coś ostro daje po dyskach, więc ewentualny twardy reset to na bank utrata części plików&amp;hellip; jeśli system po nim w ogóle wstanie&amp;hellip; 😑</description>
    </item>
    
    <item>
      <title>approx - cachujące proxy dla repozytoriów Debiana</title>
      <link>https://timor.site/2011/09/approx-cachujace-proxy-dla-repozytoriow-debiana/</link>
      <pubDate>Fri, 16 Sep 2011 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2011/09/approx-cachujace-proxy-dla-repozytoriow-debiana/</guid>
      <description>Wielu administratorów gdy zaczyna swoją przygodę zarządza jedną/dwoma maszynami&amp;hellip; Po pewnym czasie jest ich już kilka&amp;hellip; W którymś momencie dostrzega się zalety wirtualizacji i na kilku maszynach fizycznych działa kilkanaście czy kilkadziesiąt maszyn wirtualnych. W takiej sytuacji pobieranie aktualizacji dla wszystkich maszyn potrafi mocno zabić łącze.
I w tym momencie zaczynamy się zastanawiać czy może nie warto byłoby zrobić własnego mirror&amp;rsquo;a paczek dla naszego ulubionego distro&amp;hellip; do prywatnego użytku&amp;hellip; synchronizowanego w nocy by nikomu nie przeszkadzać&amp;hellip; i dostępnego nawet gdy będziemy offline&amp;hellip; Zaczynamy liczyć miejsce i okazuje się że repozytorium Debiana dla architektury i386 to prawie 60GB (sic!</description>
    </item>
    
    <item>
      <title>Wymuszenie zwolnienia pamięci buforów dyskowych na Linux’ie</title>
      <link>https://timor.site/2011/09/wymuszenie-zwolnienia-pamieci-buforow-dyskowych-na-linuxie/</link>
      <pubDate>Thu, 15 Sep 2011 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2011/09/wymuszenie-zwolnienia-pamieci-buforow-dyskowych-na-linuxie/</guid>
      <description>Linux bardzo agresywnie wykorzystuje wolną pamięć RAM do buforowania danych odczytywanych z dysków (inode&amp;rsquo;ów, plików, itd&amp;hellip;). Ma to niebagatelny wpływ na zwiększenie szybkości uruchamiania programów które już raz zostały uruchomione. Jednak nie zawsze jest to pożądane zachowanie, np. testując szybkość uruchomienia/wykonywania tworzonej przez nas aplikacji - buforowanie zmienia czas ładowania aplikacji przy kolejnych uruchomieniach. Dobrze byłoby móc wymusić zwolnienie buforów by każdy start programu miał porównywalne &amp;ldquo;warunki startowe&amp;rdquo;.
Na szczęście można to zrobić w prosty sposób:</description>
    </item>
    
    <item>
      <title>Zabezpieczenie Apachego na Debianie przed slowloris’em</title>
      <link>https://timor.site/2011/09/zabezpieczenie-apachego-na-debianie-przed-slowlorisem/</link>
      <pubDate>Mon, 12 Sep 2011 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2011/09/zabezpieczenie-apachego-na-debianie-przed-slowlorisem/</guid>
      <description>Od jakiegoś czasu dostępny jest w sieci skrypt slowloris.pl pozwalający z pojedynczego komputera wykonać atak DOS na zdalny serwer WWW. Atak polega na uruchomieniu wielu równoczesnych sesji i bardzo wolnym wysyłaniu komunikatów HTTP. Atakujący udaje &amp;ldquo;klienta z wolnym łączem&amp;rdquo; równocześnie uruchamiając kolejne sesje by po pewnym czasie zająć wszystkie dostępne. Serwer WWW przestaje wtedy odpowiadać na zapytania od innych klientów. Dodatkowo na źle wyskalowanych serwerach duża liczba procesów Apachego może spowodować swapowanie i błędy braku pamięci.</description>
    </item>
    
    <item>
      <title>Sprawdzenie który proces obciąża dyski</title>
      <link>https://timor.site/2011/09/sprawdzenie-ktory-proces-obciaza-dyski/</link>
      <pubDate>Fri, 02 Sep 2011 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2011/09/sprawdzenie-ktory-proces-obciaza-dyski/</guid>
      <description>Na jednym z serwerów zauważyłem dziwny wzrost obciążenia. Tzw. LOAD od kilku dni po woli rósł. top pokazywał że dwa rdzenie CPU czekają na dane z dysku - tzw. io wait na poziomie 80~90% ale żaden proces w znaczącym stopniu nie obciążał CPU.
Jest kilka narzędzi (iostat, wmstat), które pozwalają monitorować obciążenie dysków ale ja nie szukałem informacji czy i w jakim stopniu dyski są obciążone - wiedziałem że są. Chciałem dowiedzieć się który proces generuje to obciążenie - by móc go ubić 😃</description>
    </item>
    
    <item>
      <title>JPGraph, wykresy z PHP’a</title>
      <link>https://timor.site/2011/08/jpgraph-wykresy-z-phpa/</link>
      <pubDate>Mon, 29 Aug 2011 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2011/08/jpgraph-wykresy-z-phpa/</guid>
      <description>Onego czasu próbowałem znaleźć coś co ułatwiłoby mi rysowanie prostych wykresów w PHP&amp;rsquo;ie inaczej niż z palca w GD. Kumpel polecił mi JPGraph.
JPGraph to świetna sprawa, do generowania statystyk jak chociażby na mojej stronie, ale biblioteka potrafi dużo więcej&amp;hellip;
Załóżmy, że ze stronki zbieramy do bazy takie rzeczy jak: datę, adres IP, ilość połączeń z tego adresu. Prosta tabela (przykład w Postgre SQL&amp;rsquo;u):
CREATE TABLE wizyty ( pid serial NOT NULL, &amp;#34;data&amp;#34; date NOT NULL DEFAULT (&amp;#39;now&amp;#39;::text)::date, odslony integer NOT NULL DEFAULT 1, CONSTRAINT visits_pkey PRIMARY KEY (id) ); Dane z takiej tabeli można łatwo wyciągnąć jednym select&amp;rsquo;em:</description>
    </item>
    
    <item>
      <title>Konfiguracja backportów na Debianie</title>
      <link>https://timor.site/2011/08/konfiguracja-backportow-na-debianie/</link>
      <pubDate>Mon, 29 Aug 2011 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2011/08/konfiguracja-backportow-na-debianie/</guid>
      <description>Tak się składa, że Debian ze względu na stosunkowo rzadkie wydawanie kolejnych wersji szybko staje się niezbyt świeży a dostępne w nim pakiety często nie spełaniają naszych oczekiwań. Nie ma najnowszej wersji Subversion&amp;hellip; Nie ma mod_security itd, itp&amp;hellip;
Rozwiązaniem tego problemu może być instalacja pakietów z testowej gałęzi ale można polec na zależnościach. Można też kompilować ze źródeł&amp;hellip; Tak czy siak w obu przypadkach aktualizacja i utrzymanie tak zmodyfikowanego systemu byłoby jak wrzód na zadku.</description>
    </item>
    
    <item>
      <title>Optymalizacja PHP z eAccelerator’em</title>
      <link>https://timor.site/2011/08/optymalizacja-php-z-eacceleratorem/</link>
      <pubDate>Mon, 29 Aug 2011 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2011/08/optymalizacja-php-z-eacceleratorem/</guid>
      <description>Przy okazji wykonywania kilku drobnych optymalizacji swojej stronki natknąłem się na eAccelerator&amp;rsquo;a. Ciekawy projekt, który w sposobie działania przypomina Zend Optimizer&amp;rsquo;a ale ma jedną zasadniczą zaletę - jest darmowy 😃
Niestety nie ma go w repozytoriach Debiana, więc trzeba go sobie skompilować - cały proces jest dość prosty. Zaczynamy od pobrania najświeższej paczki, obecnie jest to wersja 0.9.5.3:
Pobierz eAccelerator (ostatnio miałem problem z tym linkiem więc proponuję pogooglać)
Pobieramy i rozpakowujemy pliki:</description>
    </item>
    
    <item>
      <title>Statystyki odwiedzin dla wielu serwisów z AWStats</title>
      <link>https://timor.site/2011/08/statystyki-odwiedzin-dla-wielu-serwisow-z-awstats/</link>
      <pubDate>Mon, 29 Aug 2011 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2011/08/statystyki-odwiedzin-dla-wielu-serwisow-z-awstats/</guid>
      <description>Co prawda na swojej stronie zrobiłem kilka podstawowych statystyk i coś tam sobie loguję do bazy danych, ale gdyby się chwilę zastanowić to przecież to samo robi serwer www - wrzuca do logów każde zapytanie HTTP, kod błędu, nazwę agenta, itd. Dublowanie tych danych nie jest najbardziej optymalne.
Stąd też chwilę pogooglałem i znalazłem świetny Open Source&amp;rsquo;owy projekt: AWStats, który jest webowym analizatorem logów dla serwerów HTTP, FTP i SMTP.</description>
    </item>
    
    <item>
      <title>Certyfikaty SelfSigned</title>
      <link>https://timor.site/2011/08/certyfikaty-selfsigned/</link>
      <pubDate>Sat, 27 Aug 2011 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2011/08/certyfikaty-selfsigned/</guid>
      <description>Certyfikaty oparte o SSL stanowią obecnie podstawę bezpieczeństwa wielu usług sieciowych zaczynając od HTTP, przez POPS, IMAPS, itd&amp;hellip; Niestety zakupienie certyfikatu w organizacjach jak VeriSgin czy Thawte jest dość kosztowe, a jeżeli potrzebujemy kilka certyfikatów to często na lokalne potrzeby jest to po prostu nie opłacalne.
Postaram się przedstawić wersję &amp;ldquo;ekonomiczną&amp;rdquo; certyfikacji 😃
Generowanie Certificate Signing Request Pierwszym etapem generowania certyfikatu jest przygotowanie Certificate Signing Request, czyli czegoś w rodzaju &amp;ldquo;prośby&amp;rdquo; o certyfikat.</description>
    </item>
    
    <item>
      <title>Dynamiczne IP i RBL’e</title>
      <link>https://timor.site/2011/08/dynamiczne-ip-i-rble/</link>
      <pubDate>Sat, 27 Aug 2011 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2011/08/dynamiczne-ip-i-rble/</guid>
      <description>Mój serwer pocztowy działa od jakiegoś czasu na dynamicznym IP (dobre bo tanie&amp;hellip;) i przeważnie nie ma z tym problemów. Postarałem się jak mogłem ustawiając SPF&amp;rsquo;a i DomainKeys aby uwiarygodnić go u większych dostawców poczty.
Niestety wszystko to diabli biorą w momencie gdy wygasa mi leasse DHCP i dostaję nowe IP po jakimś spamerze/zombiaku. Wisi takie w 2-3 większych RBL&amp;rsquo;ach i o dostarczaniu poczty można zapomnieć. Miło gdy jeszcze zdalny MTA zechce odesłać zwrotkę &amp;ldquo;zróbta coś bo wisisz w RBL&amp;rsquo;u takim a takim&amp;hellip;&amp;rdquo;, ale zdecydowania niefajnie gdy wysyłasz pocztę a ona od razu leci do /dev/null rblcheck Poszperałem trochę i znalazłem fajne narzędzie aka rblcheck, które sprawdza domyślnie kilka RBL&amp;rsquo;i.</description>
    </item>
    
    <item>
      <title>Klastrowanie sesji PHP z memcached</title>
      <link>https://timor.site/2011/08/klastrowanie-sesji-php-z-memcached/</link>
      <pubDate>Sat, 27 Aug 2011 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2011/08/klastrowanie-sesji-php-z-memcached/</guid>
      <description>Klastrowanie to może zbyt dumnie powiedziane. Rozwiązanie to wyszukałem gdy chcąc skonfigurować dwa serwery apache do współpracy na rzecz jednego serwisu okazało się, że sejse trzymane są tylko przez jeden serwer a drugi nic o nich nie wie. To oczywiście nie pozwalało na prawidłowe działanie jakiegokolwiek serwisu korzystającego z sesji.
Pomysł jest taki, że zastępujemy domyśny mechanizm przechowywania sesji w plikach na dysku mechanizmem memcache. Ponieważ memcached działa jako usługa sieciowa, różne serwery mogą się odwoływać do puli memcached i odczytywać zapisane w niej dane.</description>
    </item>
    
    <item>
      <title>MySQL - dostęp zdalny na szybko</title>
      <link>https://timor.site/2011/08/mysql-na-szybko/</link>
      <pubDate>Sat, 27 Aug 2011 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2011/08/mysql-na-szybko/</guid>
      <description>Instalacja serwera MySQL na Debianie jest niezwykle prosta i sprowadza się do jednego polecenia:
sudo apt-get install mysql-server Polecenie to zainstaluje i uruchomi usługę serwerową MySQL. W czasie instalacji będziemy proszeni o podanie hasła dla root&amp;rsquo;a (które oczywiście dobrze jest zapamiętać bądź zapisać).
Tak zainstalowana baza nasłuchuje na lokalnym porcie (localhost:3306) umożliwiająć dostęp wyłącznie root&amp;rsquo;owi. Jest to bardzo bezpieczna konfiguracja&amp;hellip; Ale jeśli nie mamy zamiaru na tej samej maszynie instalować oprogramowania zarządzającego to nie zawsze jest to wygodne, tym bardziej gdy przykładowo mamy działającego phpmyadmin&amp;rsquo;a na jakimś serwerze www.</description>
    </item>
    
    <item>
      <title>Quota na katalog w XFS’ie</title>
      <link>https://timor.site/2011/08/quota-na-katalog-w-xfsie/</link>
      <pubDate>Sat, 27 Aug 2011 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2011/08/quota-na-katalog-w-xfsie/</guid>
      <description>Większość systemów plików w linuksie pozwala na ustawienie quoty na dwóch poziomach: na użytkownika lub na grupę użytkowników. W wielu przypadkach taki podział jest sensowny i wystarczający. Ale zdarzają się scenariusze, w których to za mało.
Dobrym przykładem jest serwer FTP z wirtualnymi kontami użytkowników. Czyli usługa serwera działa jako pewien nieuprzywilejowany użytkownik systemowy (przeważnie ftp) przypisany do nieuprzywilejowanej grupy (np. nogroup). Konta użytkowników serwera FTP są zdefiniowane w bazie danych lub serwerze LDAP.</description>
    </item>
    
    <item>
      <title>Włam na lokalne konto root’a</title>
      <link>https://timor.site/2011/08/wlam-na-lokalne-konto-roota/</link>
      <pubDate>Sat, 27 Aug 2011 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2011/08/wlam-na-lokalne-konto-roota/</guid>
      <description>Jeżeli tu zaglądasz pewnie zdarzyło Ci się kiedyś, że przykładowo wygrzebujesz jakiś stary serwer i nie masz pojęcia co na nim było, ani do czego służyło, czy jeszcze działa&amp;hellip; Albo jeszcze inaczej - serwer działał tak długo, że wszystkie osoby znające hasło na root&amp;rsquo;a przeszły na emeryturę lub zmarły&amp;hellip; Nieistotne 😃
Jest pewna prosta sztuczka, pozwalająca wbić się na konto root&amp;rsquo;a nie znając hasła - dając nam możliwość jego zmiany. Potrzebne dwa restarty ale za to nie trzeba korzystać z żadnychlive cd.</description>
    </item>
    
    <item>
      <title>Wysyłanie załączników poleceniem mail</title>
      <link>https://timor.site/2011/08/wysylanie-zalacznikow-poleceniem-mail/</link>
      <pubDate>Sat, 27 Aug 2011 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/2011/08/wysylanie-zalacznikow-poleceniem-mail/</guid>
      <description>Kiedyś potrzebowałem w ramach testu obciążeniowego wysłać dużo wiadomości z załącznikami. Chciałem to zrobić na szybko z shell&amp;rsquo;a i tutaj chwilę musiałem pogooglać aby znaleźć działające polecenie. To co znalazłem wygląda tak:
(echo &amp;#34;testowa wiadomosc&amp;#34;; uuencode test.zip test.zip) \ | mail -s &amp;#34;Test&amp;#34; testowy@mail.pl Wiedząc już jak wysyłać maile z załącznikami, mały mail bombing mogłem zrobić tak:
for i in `seq 1 100`; do (cat tekst.txt; uuencode test.zip test.zip) \ | mail -s &amp;#34;Test $i&amp;#34; testowy@mail.</description>
    </item>
    
    <item>
      <title>Few words about me</title>
      <link>https://timor.site/about/</link>
      <pubDate>Fri, 26 Aug 2011 00:00:00 +0000</pubDate>
      
      <guid>https://timor.site/about/</guid>
      <description>My name is Tomasz Gągor, for some people known as TiMoR.
I&amp;rsquo;m passionate day to day DevOps practitioner. I enjoy anything Linux driven, especially containerised web services. Security freak who loves to work with, managing, scaling Cloud systems.
I&amp;rsquo;m generalist, touched many, strange topic across my career. I used to speak with DBAs about advantages of one DB engine over the another and how to tune them for better performance. With Network guys, it happen to me to debug IKE proto by raw packets.</description>
    </item>
    
    
    
  </channel>
</rss>

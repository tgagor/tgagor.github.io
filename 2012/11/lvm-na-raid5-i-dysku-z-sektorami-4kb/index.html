<!doctype html><html lang=en dir=auto><head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta name=description content="Po zakupie nowych dysków zamierzam utworzyć zdegradowaną macierz RAID5 z dwóch dysków (na trzecim na razie znajdują się dane), potem utworzyć wolumen LVM, sformatować go, przekopiować dane z pojedynczego dysku na macierz i dołączyć trzeci dysk do macierzy odbudowując parzystość. Zadanie będzie o tyle ciekawe że dysk ma 4KB sektory i trzeb będzie dbać o wyrównanie zasobu do rozmiaru sektora, a w przypadku LVM&rsquo;a wyrównanie do chunk&rsquo;a z macierzy.
Prawidłowe wyrównanie partycji Kupując nowy dysk (o pojemności od 500GB w górę), mamy spore szanse że trafimy na sztukę, która wykorzystuje 4KB sektory do alokacji danych.">
<meta name=theme-color content="#c64858">
<meta property="og:title" content="LVM na RAID5 i dysku z sektorami 4KB • TiMoR">
<meta property="og:description" content="Po zakupie nowych dysków zamierzam utworzyć zdegradowaną macierz RAID5 z dwóch dysków (na trzecim na razie znajdują się dane), potem utworzyć wolumen LVM, sformatować go, przekopiować dane z pojedynczego dysku na macierz i dołączyć trzeci dysk do macierzy odbudowując parzystość. Zadanie będzie o tyle ciekawe że dysk ma 4KB sektory i trzeb będzie dbać o wyrównanie zasobu do rozmiaru sektora, a w przypadku LVM&rsquo;a wyrównanie do chunk&rsquo;a z macierzy.
Prawidłowe wyrównanie partycji Kupując nowy dysk (o pojemności od 500GB w górę), mamy spore szanse że trafimy na sztukę, która wykorzystuje 4KB sektory do alokacji danych.">
<meta property="og:url" content="https://timor.site/2012/11/lvm-na-raid5-i-dysku-z-sektorami-4kb/">
<meta property="og:site_name" content="timor's site">
<meta property="og:type" content="article"><meta property="og:image" content="https://www.gravatar.com/avatar/cfa9a17577371083824a78c303cc8ed7?s=256"><meta property="article:section" content="posts"><meta property="article:tag" content="bash"><meta property="article:tag" content="ext4"><meta property="article:tag" content="Linux"><meta property="article:tag" content="LVM"><meta property="article:tag" content="mdadm"><meta property="article:tag" content="RAID"><meta property="article:published_time" content="2012-11-07T00:00:00Z"><meta property="article:modified_time" content="2012-11-07T00:00:00Z"><meta name=twitter:card content="summary">
<meta name=generator content="Hugo 0.88.1">
<title>LVM na RAID5 i dysku z sektorami 4KB • TiMoR</title>
<link rel=canonical href=https://timor.site/2012/11/lvm-na-raid5-i-dysku-z-sektorami-4kb/>
<link rel=icon href=/favicon.ico>
<link rel=stylesheet href=/assets/css/main.ab98e12b.css><style>:root{--color-accent:#c64858}</style>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga('create','UA-88996819-1','auto'),ga('send','pageview'))</script>
<script async src=https://www.google-analytics.com/analytics.js></script>
</head>
<body class="page type-posts layout-post has-sidebar">
<div class=site><div id=sidebar class=sidebar>
<a class=screen-reader-text href=#main-menu>Skip to Main Menu</a>
<div class=container><section class="widget widget-about sep-after">
<header>
<div class=logo>
<a href=/>
<img src=/favicon.ico>
</a>
</div>
<h2 class="title site-title">
<a href=/>
timor's site
</a>
</h2>
<div class=desc>
Linux configuration, Automation, Security - Sysadmin/DevOps blog
</div>
</header>
</section>
<section class="widget widget-search sep-after">
<header>
<h4 class="title widget-title">Search</h4>
</header>
<form action=/search id=search-form class=search-form>
<label>
<span class=screen-reader-text>Search</span>
<input id=search-term class=search-term type=search name=q placeholder=Search&mldr;>
</label></form>
</section>
<section class="widget widget-sidebar_menu sep-after"><nav id=sidebar-menu class="menu sidebar-menu" aria-label="Sidebar Menu">
<div class=container>
<ul><li class=item>
<a href=/></a></li><li class=item>
<a href=/>Home</a></li><li class="item has-children">
<a href=/categories/howto/>HOWTO</a><button class=sub-menu-toggler>
<span class=screen-reader-text>expand sub menu</span>
<span class=sign></span>
</button>
<ul class=sub-menu><li class=item>
<a href=/categories/tip/>Tips</a></li></ul></li><li class=item>
<a href=/categories/off-topic/>Off-topic</a></li><li class=item>
<a href=/categories/gotowanie/>Gotowanie</a></li><li class=item>
<a href=/about/>About</a></li></ul>
</div>
</nav>
</section></div>
<div class=sidebar-overlay></div>
</div><div class=main><a class=screen-reader-text href=#content>Skip to Content</a>
<button id=sidebar-toggler class=sidebar-toggler aria-controls=sidebar>
<span class=screen-reader-text>Toggle Sidebar</span>
<span class=open><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="18" x2="21" y2="18"/></svg>
</span>
<span class=close><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><line x1="18" y1="6" x2="6" y2="18"/><line x1="6" y1="6" x2="18" y2="18"/></svg>
</span>
</button><div class=header-widgets>
<div class=container>
<style>.widget-breadcrumbs li:after{content:'\2f '}</style>
<section class="widget widget-breadcrumbs sep-after">
<nav id=breadcrumbs>
<ol><li><a href=/>Home</a></li><li><a href=/posts/>Posts</a></li><li><span>LVM na RAID5 i dysku z sektorami 4KB</span></li></ol>
</nav>
</section></div>
</div>
<header id=header class="header site-header">
<div class="container sep-after">
<div class=header-info><p class="site-title title">timor's site</p><p class="desc site-desc">Linux configuration, Automation, Security - Sysadmin/DevOps blog</p>
</div>
</div>
</header>
<main id=content>
<article lang=en class=entry>
<header class="header entry-header">
<div class="container sep-after">
<div class=header-info>
<h1 class=title>LVM na RAID5 i dysku z sektorami 4KB</h1>
</div>
<div class=entry-meta>
<span class=posted-on><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg>
<span class=screen-reader-text>Posted on </span>
<time class=entry-date datetime=2012-11-07T00:00:00Z>2012-11-07</time>
</span>
<span class=byline><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M21 21V20c0-2.76-4-5-9-5s-9 2.24-9 5v1"/><path d="M16 6.37A4 4 0 1112.63 3 4 4 0 0116 6.37z"/></svg>
<span class=screen-reader-text> by </span><a href=/authors/timor>TiMoR</a></span>
<span class=reading-time><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 15 15"/></svg>
15 mins read
</span>
</div>
</div>
</header>
<div class="container entry-content">
<p>Po zakupie nowych dysków zamierzam utworzyć zdegradowaną macierz RAID5 z dwóch dysków (na trzecim na razie znajdują się dane), potem utworzyć wolumen LVM, sformatować go, przekopiować dane z pojedynczego dysku na macierz i dołączyć  trzeci dysk do macierzy odbudowując parzystość. Zadanie będzie o tyle ciekawe że dysk ma 4KB sektory i trzeb będzie dbać o wyrównanie zasobu do rozmiaru sektora, a w przypadku LVM&rsquo;a wyrównanie do chunk&rsquo;a z macierzy.</p>
<h2 id=prawidłowe-wyrównanie-partycji>Prawidłowe wyrównanie partycji</h2>
<p>Kupując nowy dysk (o pojemności od 500GB w górę),  mamy spore szanse że trafimy na sztukę, która wykorzystuje 4KB sektory do alokacji danych. Ponieważ statystyczny rozmiar przechowywanych plików rośnie i nawet proste zdjęcie ma powyżej 1MB to wykorzystanie bloków o tym rozmiarze większym niż 512 bajtów jest jak najbardziej uzasadnione - zresztą większość systemów plików i tak wykorzystuje bloki 4~8KB. Jest tylko jedno ALE: jeżeli nie uwzględnimy tego podczas partycjonowania dysku to sektory 4KB systemu plików zamiast znajdować się w równo w odpowiadających im fizycznych 4KB sektorach dysku - mogą zachodzić na 2 sektory fizyczne - w takiej sytuacji każde odwołanie to takiego sektora w systemie plików wymaga odczytania/zapisanie dwóch sektorów fizycznych. Co prawda w dyskach stosuje się mechanizmy, które powinny zoptymalizować takie sytuacje ale jak potwierdzają benchmarki źle wyrównane partycja mogą znacznie obniżyć wydajność dysku. A jeszcze zabawniej jest jeśli kupimy dysk SSD bo w nich bardzo często fizyczne bloki są 128~512KB i żeby było zabawniej to bardzo często dyski SSD deklarują (choćby przez SMART&rsquo;a) że mają bloki 512B - SIC!</p>
<p>Jeśli mamy fart i nasz dysk raportuje rozmiar fizycznego sektora to możemy to sprawdzić tak:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>cat /sys/block/sda/queue/physical_block_size
</code></pre></div><p>U mnie to polecenie zwróciło 4096 czyli 4KB co jest zgodne z deklaracją producenta.</p>
<p>Dobre podejście do tematu wyrównania partycji zaproponował Teo Tso czyli wybranie takich parametrów głowic/sektorów na ścieżce by fdisk automatycznie wyrównywał partycje do oczekiwanej przez nas wielkości bloku. Teo proponował użycie 224 głowic i 56 sektorów - co da wyrównanie do 128KB dla wszystkich partycji z wyjątkiem pierwszej (pierwsza będzie wyrównana do 4KB o ile nie wymusimy startu z 256 sektora). Jeżeli mamy dysk z blokami 4KB lub pierwszą partycję zamierzamy wykorzystać jako np. /boot (gdzie wydajność nie ma aż takiego dużego znaczenia) to jest to ok. Ale jeśli kompatybilność z DOS&rsquo;em mamy w poważaniu to możemy w fdisku utworzyć pierwszą partycję wyrównaną do 128KB lub 1MB.</p>
<p>Przeważnie wolałem <em>cfdiska</em> od <em>fdiska</em> (bo po co się męczyć z topornym interfejsem) ale nie udało mi się skubańca zmusić by tworzył pierwszą partycję w sposób nie kompatybilny z DOS&rsquo;em. fdisk pomimo toporności po podaniu liczby głowic i sektorów w ścieżce podpowiedział mi poprawne wyrównanie partycji (a gdybyśmy posiadali starszą wersję, która nie jest tak sprytna to przynajmniej możemy podać ręcznie od którego sektora ma zaczynać się partycja).</p>
<h3 id=wyrównanie-do-128kb>Wyrównanie do 128KB</h3>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>fdisk -u -H <span style=color:#ae81ff>224</span> -S <span style=color:#ae81ff>56</span> /dev/sdX
</code></pre></div><p>Opcja -u zmienia domyślną jednostkę na sektory (mamy wtedy mniejsze liczby, które łatwiej się przelicza). Dla wyrównania do 128KB pierwsza partycja powinna się zaczynać na 256 sektorze. Do wyrównania do 4KB wystarczy zacząć na 56 sektorze (wystarczające przy części nowszych dysków twardych).</p>
<h3 id=wyrównanie-do-1mb>Wyrównanie do 1MB</h3>
<p>Jeśli jednak dysponujemy dyskiem SSD z ciężko powiedzieć jak dużym blokiem to lepiej wykorzystać wyrównanie do 1MB - zmarnujemy trochę więcej miejsca (tych parę MB jakoś przeżyjemy) ale w tym rozmiarze na pewno zmieści się każdy sektor (a może nawet <em>Erase Block</em>, który obecnie przeważnie ma 512KB choć zdarzają się sztuki z 4MB). Można to osiągnąć z ustawieniem 64 głowic i 32 sektorów na ścieżkę, robimy to tak:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>fdisk -u -H <span style=color:#ae81ff>64</span> -S <span style=color:#ae81ff>32</span> /dev/sdX
</code></pre></div><p>Pierwsza partycja powinna się zaczynać na 2048 sektorze dla wyrównania do 1MB lub 8192 sektorze jeśli chcemy zacząć od 4MB.</p>
<p>Po odpaleniu fdiska z tymi parametrami wybieramy opcję <strong>n</strong> i lecimy dalej zgodnie z podpowiedziami, np.:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>fdisk -u -H <span style=color:#ae81ff>224</span> -S <span style=color:#ae81ff>56</span> /dev/sdc
Polecenie <span style=color:#f92672>(</span>m wyświetla pomoc<span style=color:#f92672>)</span>: &lt;strong&gt;m&lt;/strong&gt;
Polecenie
 a zmiana flagi rozruchu
 b modyfikacja etykiety dysku BSD
 c zmiana flagi kompatybilności z DOS-em
 d usunięcie partycji
 l wypisanie znanych typów partycji
 m wyświetlenie tego menu
 &lt;strong&gt;n dodanie nowej partycji&lt;/strong&gt;
 o utworzenie nowej, pustej DOS-owej tablicy partycji
 p wypisanie tablicy partycji
 q zakończenie bez zapisywania zmian
 s utworzenie nowej, pustej etykiety dysku Suna
 t zmiana ID systemu partycji
 u zmiana jednostek wyświetlania/wprowadzania
 v weryfikacja tablicy partycji
 w zapis tablicy partycji na dysk i zakończenie
 x dodatkowe funkcje <span style=color:#f92672>(</span>tylko dla ekspertów<span style=color:#f92672>)</span>
Polecenie <span style=color:#f92672>(</span>m wyświetla pomoc<span style=color:#f92672>)</span>: &lt;strong&gt;n&lt;/strong&gt;
Partition type:
 p primary <span style=color:#f92672>(</span><span style=color:#ae81ff>0</span> primary, <span style=color:#ae81ff>0</span> extended, <span style=color:#ae81ff>4</span> free<span style=color:#f92672>)</span>
 e extended
Select <span style=color:#f92672>(</span>default &lt;strong&gt;p&lt;/strong&gt;<span style=color:#f92672>)</span>:
Using default response p
Numer partycji <span style=color:#f92672>(</span>1-4, domyślnie &lt;strong&gt;1&lt;/strong&gt;<span style=color:#f92672>)</span>:
Przyjęto wartość domyślną <span style=color:#ae81ff>1</span>
Pierwszy sektor <span style=color:#f92672>(</span>2048-15240575, domyślnie &lt;strong&gt;2048&lt;/strong&gt;<span style=color:#f92672>)</span>:
Przyjęto wartość domyślną <span style=color:#ae81ff>2048</span>
Ostatni sektor, +sektorów lub +rozmiar<span style=color:#f92672>{</span>K,M,G<span style=color:#f92672>}</span> <span style=color:#f92672>(</span>2048-15240575, domyślnie 15240575<span style=color:#f92672>)</span>: &lt;strong&gt;+100M&lt;/strong&gt;
Polecenie <span style=color:#f92672>(</span>m wyświetla pomoc<span style=color:#f92672>)</span>: &lt;strong&gt;p&lt;/strong&gt;
Dysk /dev/sdc: <span style=color:#ae81ff>7803</span> MB, bajtów: <span style=color:#ae81ff>7803174912</span>
głowic: 224, sektorów/ścieżkę: 56, cylindrów: 1214, w sumie sektorów: <span style=color:#ae81ff>15240576</span>
Jednostka <span style=color:#f92672>=</span> sektorów, czyli <span style=color:#ae81ff>1</span> * 512 <span style=color:#f92672>=</span> <span style=color:#ae81ff>512</span> bajtów
Rozmiar sektora <span style=color:#f92672>(</span>logiczny/fizyczny<span style=color:#f92672>)</span> w bajtach: <span style=color:#ae81ff>512</span> / <span style=color:#ae81ff>512</span>
Rozmiar we/wy <span style=color:#f92672>(</span>minimalny/optymalny<span style=color:#f92672>)</span> w bajtach: <span style=color:#ae81ff>512</span> / <span style=color:#ae81ff>512</span>
Identyfikator dysku: 0xc3072e18
Urządzenie Rozruch Początek Koniec Bloków ID System
/dev/sdc1 <span style=color:#ae81ff>2048</span> <span style=color:#ae81ff>206847</span> <span style=color:#ae81ff>102400</span> <span style=color:#ae81ff>83</span> Linux
Polecenie <span style=color:#f92672>(</span>m wyświetla pomoc<span style=color:#f92672>)</span>: &lt;strong&gt;w&lt;/strong&gt;
Tablica partycji została zmodyfikowana!
Wywoływanie ioctl<span style=color:#f92672>()</span> w celu ponownego odczytu tablicy partycji.
UWAGA: ponowny odczyt tablicy partycji zakończył się błędem 16: Urządzenie lub zasoby zajęte.
Jądro nadal używa starej tablicy. Nowa tablica będzie używana po
następnym restarcie systemu albo po uruchomieniu partprobe<span style=color:#f92672>(</span>8<span style=color:#f92672>)</span> lub kpartx<span style=color:#f92672>(</span>8<span style=color:#f92672>)</span>
Synchronizacja dysków.
</code></pre></div><h3 id=ps-po-co-w-ogóle-partycjonować---można-użyć-całych-urządzeń>P.S. Po co w ogóle partycjonować - można użyć całych urządzeń</h3>
<p>Co prawda w przypadku gdy zamierzam całe dyski poświęcić na RAID&rsquo;a mógłbym ich nie partycjonować tylko użyć całych urządzeń i zadbać tylko by mdadm poprawnie się wyrównał (co zresztą robi automatycznie do 4KB), ale obawiałem się jak względem takich dysków zachowają się inne systemy które mam zainstalowane na komputerze - nie chciałbym aby przypadkiem uznały że to jakiś uszkodzony dysk po czym zainicjowały tablicę partycji&mldr; Może to nieuzasadniona fobia ale wiem że względem partycji <em>RAID Autodetect</em> nic takiego mi się nie przytrafi 😃</p>
<h2 id=tworzenie-macierzy-raid>Tworzenie macierzy RAID</h2>
<p>Jak już utworzymy pożądane partycje na pierwszym dysku to musimy je powielić na wszystkich pozostałych dyskach, które zamierzamy włączyć do macierzy - najprościej zrobić to sfdisk&rsquo;iem:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>sfdisk -d /dev/sdX | sfdisk /dev/sdY
</code></pre></div><p>Przy czym dysk sdX to źródłowy dysk z gotowymi partycjami, a dysk sdY to każdy na którym chcemy odtworzyć partycje. Można by zrobić na to ładną pętelkę jeśli mamy więcej tych dysków ale celowo tego nie zrobię bo jak znam życie to kiedyś ktoś to skopiuje ze znakiem nowego wiersza i wrzuci do konsoli&mldr; 😀</p>
<p>Teraz tworzę zdegradowaną (z dwóch dysków) macierz RAID5&mldr; Ale na dobrą sprawę bezpieczniej byłoby utworzyć macierz RAID1 z dwóch dysków (o ile miejsca byłoby wystarczająco na przeniesienie danych) a po przeniesieniu danych na macierz dodanie trzeciego dysku i powiększenie macierzy z reshapingiem do RAID5 - postanowiłem pominąć takie rozwiązanie bo nie bałem się utraty danych, miałem dokładną kopię na innej macierzy 😃</p>
<p>Więc tworzymy macierz:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>mdadm --create /dev/md0 --level<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span> --raid-devices<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span> --chunk<span style=color:#f92672>=</span>512k /dev/sdX1 /dev/sdY1
</code></pre></div><p>Na dobrą sprawę z powyższych opcji tylko chunk nadaje się do &ldquo;dopasowania&rdquo; - ja mam zamiar utworzyć macierz z dość dużych zasobów (3x2TB) i przechowywać na niej raczej duże pliki więc 512KB wydaje mi się dobrą wartością. Gdybyśmy jednak potrzebowali większej liczby I/O dla małych pliczków to mniejsza wartość może być lepsza. Warto zrobić kilka benchmarków dla różnych wartości chunk&rsquo;a i dopasować do przewidywanego przez nas obciążenia.</p>
<p>Aby macierz była widoczne już w czasie startu systemu należy dodatkowo wykonać polecenie:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>mdadm --detail --scan &gt;&gt; /etc/mdadm/mdadm.conf
</code></pre></div><p>Warto też w pliku <em>/etc/mdadm/mdadm.conf</em> odkomentować i wpisać jakieś sensowne wartości dla HOMEHOST, MAILADDR.</p>
<p>I teraz możemy odbudować obraz initrd:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>update-initramfs -u
</code></pre></div><h3 id=optymalizacja-macierzy-raid5>Optymalizacja macierzy RAID5</h3>
<p>Sam proces tworzenia macierzy może zająć kilka/kilkanaście godzin - dlatego warto mu pomóc kilkoma zmianami.</p>
<h4 id=speed_limit_xxx>speed_limit_xxx</h4>
<p>Na pierwszy rzut - domyślne wartości dla minimalnej i maksymalnej prędkości budowania/regenerowania/odtwarzania macierzy RAID5, można je sprawdzić:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>cat /proc/sys/dev/raid/speed_limit_max
<span style=color:#ae81ff>200000</span>
cat /proc/sys/dev/raid/speed_limit_min
<span style=color:#ae81ff>1000</span>
</code></pre></div><p>Domyślnie jest to minimum 1MB/s i maksimum 200MB/s. Podbijając minimalną prędkość do 10~50MB/s można kosztem większego obciążenia systemu zmusić macierz by odbudowywała się szybciej. Osobiście uważam tą optymalizację za mało znaczącą bo cały mechanizm dość elastycznie reaguje na obciążenie systemu i jeśli nic nie robimy to prędkości odbudowy są dość wysokie. Ale można to zrobić tak:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>echo <span style=color:#ae81ff>50000</span> &gt; /proc/sys/dev/raid/speed_limit_min
</code></pre></div><p>lub tak:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>sysctl -w dev.raid.speed_limit_min<span style=color:#f92672>=</span><span style=color:#ae81ff>50000</span>
</code></pre></div><h4 id=stripe_cache_size>stripe_cache_size</h4>
<p>Ta optymalizacja pomogła mi dużo - ok. 30% wzrost wydajności macierzy (również w czasie odbudowy parzystości). Możemy sprawdzić wartość tego parametru, np. tak:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>cat /sys/block/md0/md/stripe_cache_size
</code></pre></div><p>Domyślnie jest to wartość 128 - bida z nędzą, u mnie ustawienie na 32768 (maksymalna wartość tego parametru) dało największy wzrost wydajności - ale już 8192 znacznie poprawiło wydajność.</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#66d9ef>for</span> i in <span style=color:#ae81ff>256</span> <span style=color:#ae81ff>512</span> <span style=color:#ae81ff>1024</span> <span style=color:#ae81ff>2048</span> <span style=color:#ae81ff>4096</span> <span style=color:#ae81ff>8192</span> <span style=color:#ae81ff>16384</span> 32768;
<span style=color:#66d9ef>do</span>
    echo <span style=color:#e6db74>&#34;Testowanie </span>$i<span style=color:#e6db74>&#34;</span>
    echo $i &gt; /sys/block/md0/md/stripe_cache_size
    sync
    echo <span style=color:#ae81ff>3</span> &gt; /proc/sys/vm/drop_caches
    dd <span style=color:#66d9ef>if</span><span style=color:#f92672>=</span>/dev/zero of<span style=color:#f92672>=</span>file bs<span style=color:#f92672>=</span>1M count<span style=color:#f92672>=</span><span style=color:#ae81ff>10000</span>
<span style=color:#66d9ef>done</span>

</code></pre></div><h3 id=wyłączenie-ncq-dla-wszystkich-dysków-w-macierzy>Wyłączenie NCQ dla wszystkich dysków w macierzy</h3>
<p>Wydało mi się to nieco kontrowersyjne bo NCQ powinno pomagać przy losowych odczytach/zapisach - ale zapuściłem test bonnie++ i okazało się że z włączonym NCQ czasy dostępu dla niektórych obciążeń rosną nawet dziesięciokrotnie! Warto więc sprawdzić tą opcję pod przewidywanym przez nas scenariuszem obciążenia.</p>
<p>NCQ dla poszczególnych dysków można wyłączyć np. tak:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#66d9ef>for</span> d in sdb sdc sdd
    <span style=color:#66d9ef>do</span> echo <span style=color:#ae81ff>1</span> &gt; /sys/block/$d/device/queue_depth
<span style=color:#66d9ef>done</span>
</code></pre></div><h3 id=wyłączenie-cache-dyskowych>Wyłączenie cache dyskowych</h3>
<p>Wyłączenie wbudowanej w dyski pamięci cache akurat nie zwiększa wydajności ale w przypadku awarii zasilania (lub innej gwałtownej awarii systemu) zwiększa szanse macierzy na przeżycie takiego incydentu. Obecnie większość systemów plików korzysta z opóźnienia zapisu by bardziej optymalnie zapisać dane na dysku - dlatego gdy zapisujemy dany to najpierw trafiają one do cache systemowego. Dopiero po sync&rsquo;u są przesyłane do cache dyskowego skąd dopiero po pewnym czasie trafiają na dysk. Wyłączenie pamięci cache na dyskach &ldquo;usuwa&rdquo; nam to drugie opóźnienie.</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>hdparm -W0 /dev/sd*
</code></pre></div><h3 id=zmiana-parametrów-odczytu-z-wyprzedzeniem>Zmiana parametrów odczytu z wyprzedzeniem</h3>
<p>Bardzo ważnym parametrem mającym wpływ na wydajność macierzy jest odpowiednie ustawienie odczytu z wyprzedzeniem. Obecnie ustawioną wartość możemy sprawdzić tak (wartość wyrażona jest w 512 bajtowych sektorach):</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>blockdev --getra /dev/md0
</code></pre></div><p>U mnie domyślnie było 4096 (a na innym starszym systemie tylko 1536) to może być zbyt mało dla konfiguracji RAID. Większe wartości można ustawić np. tak:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>blockdev --setra <span style=color:#ae81ff>65536</span> /dev/md0
</code></pre></div><p>A tak można wykonać sprawdzanie, która wartość będzie dla nas najbardziej optymalna:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>dd <span style=color:#66d9ef>if</span><span style=color:#f92672>=</span>/dev/zero of<span style=color:#f92672>=</span>file bs<span style=color:#f92672>=</span>1M count<span style=color:#f92672>=</span><span style=color:#ae81ff>10000</span>
<span style=color:#66d9ef>for</span> i in <span style=color:#ae81ff>1536</span> <span style=color:#ae81ff>4096</span> <span style=color:#ae81ff>8192</span> <span style=color:#ae81ff>16384</span> <span style=color:#ae81ff>32768</span> <span style=color:#ae81ff>65536</span> <span style=color:#ae81ff>131072</span> <span style=color:#ae81ff>262144</span> 524288;
<span style=color:#66d9ef>do</span>
    echo <span style=color:#e6db74>&#34;Testowanie </span>$i<span style=color:#e6db74>&#34;</span>
    blockdev --setra $i /dev/md0
    sync
    echo <span style=color:#ae81ff>3</span> &gt; /proc/sys/vm/drop_caches
    dd <span style=color:#66d9ef>if</span><span style=color:#f92672>=</span>file of<span style=color:#f92672>=</span>/dev/null bs<span style=color:#f92672>=</span>1M
<span style=color:#66d9ef>done</span>

</code></pre></div><h2 id=tworzenie-zasobu-lvm>Tworzenie zasobu LVM</h2>
<p>Mając już macierze tworzę na niej volumen LVM - najpierw przygotowanie zasobu:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>pvcreate /dev/md0
</code></pre></div><p>Jeżeli w /etc/lvm/lvm.conf mamy ustawione opcje:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>md_component_detection <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
md_chunk_alignment <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
data_alignment_detection <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
</code></pre></div><p>To LVM powinien automatycznie wykryć rozmiar chunk&rsquo;a z RAID&rsquo;a i dostosować swoje metadane, oraz początek danych tak by wszystko było prawidłowo wyrównane względem macierzy.</p>
<p>Jeśli nie mamy szczęścia (bardzo stare jajko/LVM) to będziemy musieli użyć opcji -metadatasize i/lub -dataalignment:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>pvcreate --metadatasize 500k /dev/md0
</code></pre></div><p>Teraz ciekawostka - LVM potrzebuje na 192KB na dane nagłówkowe każdego wolumenu i każdy utworzony później zasób byłby o te 192KB przesunięty, więc &mldr; trafia nasze wyrównanie do 128KB. Dlatego zmuszamy LVM&rsquo;a by zaalokował nieco więcej - tutaj 256KB. OK - ale w poleceniu jest 250 - WTF? I to aby było zabawnie jest to jak najbardziej prawidłowa wartość - nie wiem jaka w tym logika, ale by metadane zajmowały 256KB podajemy 250k, by zajmowały 512KB podajemy 500k itd&mldr;</p>
<p>Inaczej jest z opcją -dataalignment, tutaj najbardziej optymalnie należy podać rozmiar chunk&rsquo;a*ilość aktywnych dysków (dla RAID5 odejmujemy jeden) - albo minimalnie rozmiar chunka, np.:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>pvcreate --dataalignment 512K /dev/md0
</code></pre></div><p>Poprawność możemy sprawdzić poleceniem:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>pvs /dev/md0 -o+pe_start
  PV       VG     Fmt  Attr PSize PFree   1st PE
  /dev/md0 vgraid lvm2 a-   1,82t 488,89g 512,00k
</code></pre></div><p>U mnie <em>1st PE</em> zaczyna się na 512KB, więc jest OK.</p>
<p>Teraz tworzymy grupę:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>vgcreate vgraid /dev/md0
</code></pre></div><p>Polecenie vgcreate posiada parametr -s który pozwala określić do wielokrotności jakiej wartości będzie zaokrąglana wielkość wolumenu - wartość ta powinna być wielokrotnością chunk&rsquo;a z macierzy. Domyślnie ma ona wartość 4MB więc wszystko będzie ładnie wyrównane.</p>
<p>I możemy zacząć tworzyć volumeny logiczne:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>lvcreate -L1T -nsrv vgraid
</code></pre></div><h2 id=formatowanie>Formatowanie</h2>
<p>To teraz formatowanie - tutaj też czasem trzeba się wysilić by utworzony przez nas filesystem działał możliwie optymalnie na macierzy i bloku o odpowiednim rozmiarze. W przypadku filesystemu na macierzy są dwa ważne parametry: stride i stripe-width. Stride powinien odpowiadać rozmiarowi podanemu jako chunk podczas tworzenia macierzy ale wyrażonego w blokach systemu plików (domyślnie 4KB). Stripe-width powinno być ustawione na: stride * N, gdzie N to ilość aktywnych dysków w macierzy (dla RAID5 jest to ilość dysków minus 1) - przykładowo dla bloku 4KB i chunk&rsquo;a 512KB, stride powinien wynosić 128 (512/4). Z kolei stripe-width dla 3 dysków to 128*(3-1)=256. Prawidłowe dobranie tych parametrów może dać wzrost wydajności rzędu 40% (według moich testów). Teoretycznie na nowszych systemach tworzone systemy plików automatycznie powinny wykryć najbardziej optymalne wyrównanie - możemy więc spróbować puścić format bez tych parametrów i później skontrolować ich wartości poleceniem:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>tune2fs -l /dev/vgraid/srv
</code></pre></div><p>Na początek przykład dla systemu plików dla małych i średnich plików:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>mkfs.ext4 -E stride<span style=color:#f92672>=</span>128,stripe-width<span style=color:#f92672>=</span>256,resize<span style=color:#f92672>=</span>4T -m0 /dev/vgraid/srv
</code></pre></div><p>Jeden dodatkowy parametr to <em>resize</em> - pozwala on zmienić domyślne ustawienie maksymalnego rozmiaru do którego możemy powiększyć dany filesystem - domyślnie jest to wartość 1000 razy większa od początkowej wielkości - ciut przekozaczone. Może nie oszczędzi to dużo miejsca na dysku (kilkadziesiąt/kilkaset MB) ale na pewno skróci czas fsck&rsquo;a.</p>
<p>Kolejny dodatek to <em>-m0</em> które wyłącza alokację 5% przestrzeni dyskowej dla root&rsquo;a i usług systemowych - po prostu tutaj tego nie potrzebuję a 5% z 1TB to 50GB marnującego się miejsca!</p>
<p>Jeśli wiemy że będziemy przechowywać na danym zasobie tylko stosunkowo duże pliki to można użyć takich opcji:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>mkfs.ext4 -E stride<span style=color:#f92672>=</span>128,stripe-width<span style=color:#f92672>=</span>256,resize<span style=color:#f92672>=</span>4T -T largefile -m0 /dev/vgraid/srv
</code></pre></div><p>Opcja -T to wykorzystanie szablonów opcji dla tworzenia systemów plików, które można edytować i dodawać w pliku: /etc/mke2fs.conf. Szablon largefile wykorzystuje mniejszą liczbę inodów dla nowego filesystemu, jeśli zamierzamy przechowywać głównie duże pliki to zmniejszy to czas formatowania i późniejszych fsck&rsquo;ów na tym systemie plików.</p>
<h2 id=testowanie-wydajności>Testowanie wydajności</h2>
<p>Zalecałbym testowanie wydajności na kolejnych etapach przygotowania dysków i powtarzać te same benchmarki po każdej zmianie, tak więc testujemy:</p>
<ol>
<li>Na początek <strong>wszystkie</strong> dyski, z których zamierzamy zbudować RAID&rsquo;a by wykluczyć ewentualne &ldquo;padaki&rdquo;/uszkodzone kable, itp. Np. hdparm/dd na czystym dysku i dodatkowo iozone/bonnie++ na filesystemie by sprawdzić czy nie skopaliśmy wyrównania partycji.</li>
<li>Po zbudowaniu RAID&rsquo;a powtarzamy testy - na całym urządzeniu (dd) i po sformatowaniu (iozone/bonnie++) by upewnić się że RAID jest prawidłowo wyrównany (przy czym przy RAID5 możemy się spodziewać wyników przy zapisie niższych niż przy odczycie - jest to OK). Jest to też dobry moment na sprawdzenie kilku optymalizacji dla macierzy: stripe_cache_size, wyłączenie NCQ, ustawienia odczytu z wyprzedzeniem, wyłączenie cache dysków - po każdej z tych zmian ponawiamy benchmarki by upewnić się że uzyskaliśmy poprawę/lub nie.</li>
<li>Po przygotowaniu LVM&rsquo;a - ponawiamy benchmarki na volumenie by upewnić się że nie skopaliśmy wyrównania partycji/chunk&rsquo;a/itd&mldr;</li>
<li>Dopieszczamy opcje formatowania filesystemu i jego montowania (np. noatime, commit, data, itd) - i znów posiłkujemy się benchmarkami by potwierdzić że pniemy się z wydajnością w górę.</li>
</ol>
<p>Jeśli myślicie że to dużo to zalecałbym powtórzenie części benchmarków 2~3 krotnie by upewnić się że wyniki nie odbiegają znacznie od siebie. Dodatkowo powinniśmy <a title="Wymuszenie zwolnienia pamięci buforów dyskowych na Linux’ie" href=https://gagor.pl/2011/09/wymuszenie-zwolnienia-pamieci-buforow-dyskowych-na-linuxie/>czyścić przed każdym banchmarkiem cache dyskowy</a> aby mieć pewność że lepsze wyniki nie są skutkiem wczytania danych do pamięci. Z tego samego powodu jeśli uruchamiamy benchmarki to ilość zapisywanych/odczytywanych danych powinna być minimum 1,5~2 razy większa niż pamieć RAM zainstalowana w systemie by na pewnie wszystkie dane nie zmieściły się w cache&rsquo;u. Oczywiście można to zlać ale później nie ma się co dziwić że system działa wolno - a na produkcyjnej maszynie dużo trudniej zaorać całą konfiguracją i utworzyć od początku z prawidłowym wyrównaniem.</p>
<p>Zalecane jest wykorzystanie IOZone lub Bonnie++ ponieważ testują one nie tylko prosty sekwencyjny odczyt, ale również tworzenie/kasowanie plików o różnych rozmiarach i w różnej ilości - to pozwala lepiej sprawdzić opóźnienia występujące przy przewidywanych przez nas obciążeniach oraz upewnić się że cała zabawa z wyrównywaniem zasobów miała sens. Oczywiście to tylko zalecenia 😉</p>
<h3 id=hdparm>hdparm</h3>
<p>W przypadku macierzy wykorzystanie prostego hdparm&rsquo;a do testów:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>hdparm -tT /dev/md0
</code></pre></div><p>nie zwróci realnych i sensownych wyników. Pomiar jest zbyt krótki by uzyskać sensowne wyniki - lepiej wykorzystać dd z dużą ilością danych do odczytu.</p>
<h3 id=dd>dd</h3>
<p>Narzędzie jakże prymitywne a tak przydatne. Możemy nim zmierzyć sekwencyjny odczyt/zapis z/do macierzy i uzyskać bardziej realne wyniki niż hdparm&rsquo;em. Wystarczy wymusić operację na ok. dwukrotnie większej ilości danych niż ilość pamięci RAM. Dodatkowo czyścimy cache&rsquo;e przed i po mierząc całościowy czas, np. tak:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>sync; echo <span style=color:#ae81ff>3</span> &gt; /proc/sys/vm/drop_caches; time <span style=color:#f92672>(</span>dd <span style=color:#66d9ef>if</span><span style=color:#f92672>=</span>/dev/zero of<span style=color:#f92672>=</span>/mnt/test/test.img bs<span style=color:#f92672>=</span>1024K count<span style=color:#f92672>=</span><span style=color:#ae81ff>10240</span> <span style=color:#f92672>&amp;&amp;</span> sync<span style=color:#f92672>)</span>
</code></pre></div><p>Jest to szczególnie przydatne np. przy dopasowywaniu optymalnej dla nas wartości parametru stripe_cache_size, wystarczy przygotować odpowiednią pętlę:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#66d9ef>for</span> i in <span style=color:#ae81ff>128</span> <span style=color:#ae81ff>256</span> <span style=color:#ae81ff>512</span> <span style=color:#ae81ff>1024</span> <span style=color:#ae81ff>2048</span> <span style=color:#ae81ff>4096</span> <span style=color:#ae81ff>8192</span> <span style=color:#ae81ff>16384</span> 32768;
<span style=color:#66d9ef>do</span>
    echo <span style=color:#e6db74>&#34;stripe_cache_size </span>$i<span style=color:#e6db74>&#34;</span>
    echo $i &gt; /sys/block/md0/md/stripe_cache_size
    sync; echo <span style=color:#ae81ff>3</span> &gt; /proc/sys/vm/drop_caches; time <span style=color:#f92672>(</span>dd <span style=color:#66d9ef>if</span><span style=color:#f92672>=</span>/dev/zero of<span style=color:#f92672>=</span>/mnt/test/test.img bs<span style=color:#f92672>=</span>1024K count<span style=color:#f92672>=</span><span style=color:#ae81ff>10240</span> <span style=color:#f92672>&amp;&amp;</span> sync<span style=color:#f92672>)</span>
<span style=color:#66d9ef>done</span>
</code></pre></div><p>Parametr bs określa bufor wykorzystywany przy operacjach odczytu/zapisu - można go dostosować do rozmiaru chunk&rsquo;a/stripe-width/itp.. count określa jak dużo takich buforów odczytać/zapisać - w powyższym przypadku jest to 10 tys. jednomegabajtowych buforów więc łącznie 10GB.</p>
<h3 id=bonnie>bonnie++</h3>
<p>Bonnie++ wymaga nieco przygotowania ale wyniki w moim przypadku bardzo odpowiadały rzeczywistym. Co pokrótce trzeba zrobić:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>mkdir /srv/test
chown -R guest:guest /srv/test
bonnie++ -d /srv/test -s 16g -m nazwa_maszyny -f -u guest
</code></pre></div><p>Możemy dodać opcję <em>-b</em> by po każdej operacji wykonywany był <em>sync</em> - to byłoby coś podobnego do systemów bazodanowych lub pocztowych. Jeżeli chcemy zasymulować standardowe operacje na plikach to nie potrzebujemy tej opcji.</p>
<h3 id=iozone>iozone</h3>
<p>W najprostszym wykonaniu:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>iozone -a
</code></pre></div><p>Wykona to serię pomiarów na różnych rozmiarach plików, ilości powtórzeń itd. Najbardziej interesująca opcją w konfiguracji RAID jest &ldquo;Stride read&rdquo;.</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>iozone -S <span style=color:#ae81ff>8192</span> -t <span style=color:#ae81ff>1</span>
</code></pre></div><p>Parametr <em>-S</em> przekazuje rozmiar pamięci cache procesora - wykorzystywany do alokacji pamięci blokami itp (sprawdzałem czy to cokolwiek pomoże.. ale nie widziałem dużej różnicy).</p>
<p>Parametr -t 1 to benchmark przepustowości dysku a parametr cyfrowy określa liczbę równoczesnych wątków, które będą odczytywać/zapisywać - można w ten sposób zasymulować np. równoczesny streaming dla wielu źródeł, itp.</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>iozone -S <span style=color:#ae81ff>8192</span> -a -s <span style=color:#ae81ff>40960</span>
</code></pre></div><p>Tutaj parametr <em>-s</em> wskazuje na jakim rozmiarze pliku w KB ma być prowadzony benchmark - tutaj 40MB.</p>
<h2 id=podsumowanie>Podsumowanie</h2>
<p>Ogólnie zadowolony jestem że udało mi się to wszystko zebrać w jednym poście bo dotychczas miałem to zapisane w wielu różnych zakładkach i spory problem gdy potrzebowałem &ldquo;właśnie tego jednego polecenia&rdquo;. Ale niezadowolony jestem z tego że nie udało mi się ustalić całości tego postępowania dla dysków o sektorach/erase block&rsquo;ach większych niż 4 KB. Chodzi mi szczególnie o brak jasnego wyjaśnienia czy RAID5 jest prawidłowo wyrównywany bo według jednych tak właśnie jest, a według innych tak nie jest. Stąd niektórzy zalecają by stosować format metadanych dla macierzy w wersji 0.9 lub 1.0 zamiast 1.2 ale nie ma jasnych źródeł tego rozumowania. Mam nadzieję że kiedyś uda mi się to jednoznacznie rozsądzić - na pewno zaktualizuję wtedy tego posta.</p>
<h5 id=źródełka-na-których-oparłem-to-howto>Źródełka na których oparłem to HOWTO</h5>
<p><a href=http://serverfault.com/questions/390294/mdadm-raid5-too-slow-when-writing>http://serverfault.com/questions/390294/mdadm-raid5-too-slow-when-writing</a><br>
<a href=http://serverfault.com/questions/250707/why-does-mdadm-write-unusably-slow-when-mounted-synchronously>http://serverfault.com/questions/250707/why-does-mdadm-write-unusably-slow-when-mounted-synchronously</a><br>
<a href=http://serverfault.com/questions/416321/mdadm-raid-5-failed-with-2-drives-while-rebuilding>http://serverfault.com/questions/416321/mdadm-raid-5-failed-with-2-drives-while-rebuilding</a><br>
<a href=http://www.cyberciti.biz/tips/linux-raid-increase-resync-rebuild-speed.html>http://www.cyberciti.biz/tips/linux-raid-increase-resync-rebuild-speed.html</a><br>
<a href=http://askubuntu.com/questions/20852/making-stripe-cache-size-permanent>http://askubuntu.com/questions/20852/making-stripe-cache-size-permanent</a><br>
<a href=http://h3x.no/2011/07/09/tuning-ubuntu-mdadm-raid56>http://h3x.no/2011/07/09/tuning-ubuntu-mdadm-raid56</a><br>
<a href=https://raid.wiki.kernel.org/index.php/Performance>https://raid.wiki.kernel.org/index.php/Performance</a><br>
<a href=http://www.mjmwired.net/kernel/Documentation/md.txt>http://www.mjmwired.net/kernel/Documentation/md.txt</a><br>
<a href=http://wiki.hetzner.de/index.php/Partition_Alignment/en>http://wiki.hetzner.de/index.php/Partition_Alignment/en</a><br>
<a href="http://www.fhgfs.com/wiki/wikka.php?wakka=PartitionAlignment">http://www.fhgfs.com/wiki/wikka.php?wakka=PartitionAlignment</a></p>
<p>O tym że LVM na RAID5 sam się wyrównuje:<br>
<a href="http://marc.info/?l=linux-raid&m=126267824425009&w=2">http://marc.info/?l=linux-raid&m=126267824425009&w=2</a><br>
<a href=http://www.redhat.com/archives/linux-lvm/2009-September/msg00092.html>http://www.redhat.com/archives/linux-lvm/2009-September/msg00092.html</a></p>
<p>MDADM metadata format 1.2 wyrownuje sie do 4KiB:<br>
<a href=http://www.redhat.com/archives/linux-lvm/2009-September/msg00092.html>http://www.redhat.com/archives/linux-lvm/2009-September/msg00092.html</a></p>
<p>Kalkulator stride&rsquo;a<br>
<a href=http://busybox.net/~aldot/mkfs_stride.html>http://busybox.net/~aldot/mkfs_stride.html</a></p>
<p>Format raid&rsquo;a:<br>
<a href=https://raid.wiki.kernel.org/index.php/RAID_superblock_formats>https://raid.wiki.kernel.org/index.php/RAID_superblock_formats</a></p>
<p>Wyrównanie do 4kb - choć wydaje mi się że gościu robi to na czuja i ledwie mu się udało:<br>
<a href=http://blog.bigsmoke.us/2010/05/13/aligning-partitions-with-raid-and-lvm-on-drives-with-4-kb-sectors>http://blog.bigsmoke.us/2010/05/13/aligning-partitions-with-raid-and-lvm-on-drives-with-4-kb-sectors</a></p>
</div>
<footer class=entry-footer>
<div class="container sep-before"><div class=categories><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M22 19a2 2 0 01-2 2H4a2 2 0 01-2-2V5A2 2 0 014 3H9l2 3h9a2 2 0 012 2z"/></svg>
<span class=screen-reader-text>Categories: </span><a class=category href=/categories/howto/>HOWTO</a></div>
<div class=tags><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M20.59 13.41l-7.17 7.17a2 2 0 01-2.83.0L2 12V2H12l8.59 8.59a2 2 0 010 2.82z"/><line x1="7" y1="7" x2="7" y2="7"/></svg>
<span class=screen-reader-text>Tags: </span><a class=tag href=/tags/bash/>bash</a>, <a class=tag href=/tags/ext4/>ext4</a>, <a class=tag href=/tags/linux/>Linux</a>, <a class=tag href=/tags/lvm/>LVM</a>, <a class=tag href=/tags/mdadm/>mdadm</a>, <a class=tag href=/tags/raid/>RAID</a></div>
</div>
</footer>
</article>
<nav class=entry-nav>
<div class=container><div class="prev-entry sep-before">
<a href=/2012/11/instalacja-drukarki-i-skanera-brother-dcp-130c-na-ubuntu-12-04/>
<span aria-hidden=true><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><line x1="20" y1="12" x2="4" y2="12"/><polyline points="10 18 4 12 10 6"/></svg>
Previous</span>
<span class=screen-reader-text>Previous post: </span>Instalacja drukarki i skanera Brother DCP-130C na Ubuntu 12.04</a>
</div><div class="next-entry sep-before">
<a href=/2012/11/automatically-compact-couchdb-databases-in-0-11-x/>
<span class=screen-reader-text>Next post: </span>Automatically compact CouchDB databases in version 0.11.x<span aria-hidden=true>Next<svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><line x1="4" y1="12" x2="20" y2="12"/><polyline points="14 6 20 12 14 18"/></svg>
</span>
</a>
</div></div>
</nav>
<section id=comments class=comments>
<div class="container sep-before">
<div class=comments-area><div id=disqus_thread></div>
<script type=application/javascript>var disqus_config=function(){};(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return}var b=document,a=b.createElement('script');a.async=!0,a.src='//gagor-pl.disqus.com/embed.js',a.setAttribute('data-timestamp',+new Date),(b.head||b.body).appendChild(a)})()</script>
<noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript>
<a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a>
</div>
</div>
</section>
</main>
<footer id=footer class=footer>
<div class="container sep-before"><section class="widget widget-social_menu sep-after"><nav aria-label="Social Menu">
<ul><li>
<a href=https://github.com/tgagor target=_blank rel="noopener me">
<span class=screen-reader-text>Open Github account in new tab</span><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg>
</a>
</li><li>
<a href=https://linkedin.com/in/tgagor target=_blank rel="noopener me">
<span class=screen-reader-text>Open Linkedin account in new tab</span><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M16 8a6 6 0 016 6v7h-4v-7a2 2 0 00-2-2 2 2 0 00-2 2v7h-4v-7a6 6 0 016-6z"/><rect x="2" y="9" width="4" height="12"/><circle cx="4" cy="4" r="2"/></svg>
</a>
</li><li>
<a href=https://timor.site/index.xml target=_blank rel="noopener me">
<span class=screen-reader-text>Open Rss account in new tab</span><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg>
</a>
</li></ul>
</nav>
</section><div class=copyright>
<p> &copy; 2011-2021 TiMoR Licensed under <a rel=license href="https://creativecommons.org/licenses/by-sa/4.0?ref=chooser-v1" target=_blank rel="license noopener noreferrer" style=display:inline-block>CC BY-SA 4.0<img style=height:22px!important;margin-left:3px;vertical-align:text-bottom src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style=height:22px!important;margin-left:3px;vertical-align:text-bottom src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><img style=height:22px!important;margin-left:3px;vertical-align:text-bottom src="https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1"></a></p>
</div>
</div>
</footer>
</div>
</div><script>window.__assets_js_src="/assets/js/"</script>
<script src=/assets/js/main.c3bcf2df.js></script>
</body>
</html>